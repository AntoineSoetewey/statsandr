<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title> ANOVA in R - Stats and R </title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="referrer" content="no-referrer">
    <meta name="description" content="Learn how to perform an Analysis Of VAriance (ANOVA) in R to compare 3 groups or more. See also how to interpret the results and test the assumptions" />
    <meta property="og:site_name" content="Stats and R" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="/blog/anova-in-r/" />
    <meta property="og:title" content="ANOVA in R" />
    <meta property="og:image" content="/blog/2020-10-12-anova-in-r_files/anova-in-r.jpeg" />
    <meta property="og:description" content="Learn how to perform an Analysis Of VAriance (ANOVA) in R to compare 3 groups or more. See also how to interpret the results and test the assumptions" />

    <meta name="twitter:card" content="summary_large_image" />
    
    <meta name="twitter:site" content="@statsandr">
    <meta name="twitter:creator" content="@statsandr">
    
    <meta name="twitter:title" content="ANOVA in R" />
    <meta name="twitter:description" content="Learn how to perform an Analysis Of VAriance (ANOVA) in R to compare 3 groups or more. See also how to interpret the results and test the assumptions" />
    <meta name="twitter:image" content="/blog/2020-10-12-anova-in-r_files/anova-in-r.jpeg" />

    <link rel="canonical" href="/blog/anova-in-r/">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha256-aAr2Zpq8MZ+YA/D6JtRD3xtrwpEz2IqOS+pWD/7XKIw=" crossorigin="anonymous" />

    <link rel="stylesheet" href="/css/custom.css" />

    
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/styles/tomorrow.min.css" integrity="sha256-0QU8ry64q+N6YBIEF/6XF6vUeF15gbNO4tLS6ikk0FI=" crossorigin="anonymous" />
    

    

    <link rel="shortcut icon"
        href="/image/favicon.png">

    
        <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Stats and R" />
    
</head>

<body>
    
    <div class="my-4 my-md-5 header">
    <div class="container">
        <div class="row">
            <div class="col-auto offset-md-1 d-none d-md-block">
                
                    <a href="/">
                        <img class="ml-md-4 logo img-fluid d-block rounded-circle" src="/image/avatar.jpg" alt="logo">
                    </a>
                
            </div>
            <div class="col-auto align-self-center mr-auto">
                <a href="/">
                    <h1 class="name">Stats and R</h1>
                </a>

                <ul class="nav nav-primary">
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-blog" href="/blog/">
                                
                                Blog
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-tags" href="/tags/">
                                
                                Tags
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-about" href="/about/">
                                
                                About
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-newsletter" href="/subscribe/">
                                
                                Newsletter
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-contact" href="/contact/">
                                
                                Contact
                            </a>
                        </li>
                    

                    
                </ul>

            </div>
        </div>
    </div>
</div>


    <div class="content">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-sm-12 col-md-10">
                    <h1 class="mx-0 mx-md-4 blog-post-title">ANOVA in R</h1>

                    <div class="mb-md-4 meta">
                        
                            
                                <span class="author" title="Antoine Soetewey">
                                    Antoine Soetewey
                                </span>
                            
                        

                        <span class="date middot" title='Mon Oct 12 2020 00:00:00 UTC'>
                            2020-10-12
                        </span>

                        <span class="reading-time middot">
                            31 minute read
                        </span>

                        <div class="d-none d-md-inline tags">
                            <ul class="list-unstyled d-inline">
                                
                                    <li class="d-inline middot">
                                        <a href="/tags/basics">Basics</a>
                                    </li>
                                
                                    <li class="d-inline middot">
                                        <a href="/tags/hypothesis-test">Hypothesis test</a>
                                    </li>
                                
                                    <li class="d-inline middot">
                                        <a href="/tags/inferential-statistics">Inferential statistics</a>
                                    </li>
                                
                                    <li class="d-inline middot">
                                        <a href="/tags/r">R</a>
                                    </li>
                                
                                    <li class="d-inline middot">
                                        <a href="/tags/statistics">Statistics</a>
                                    </li>
                                
                            </ul>
                        </div>

                        <div class="d-none d-md-inline tags">
                            <ul class="list-unstyled d-inline">
                                
                                
                            </ul>
                        </div>
                    </div>

                    <div class="markdown">
                        
    

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#aim-and-hypotheses-of-anova">Aim and hypotheses of ANOVA</a></li>
<li><a href="#underlying-assumptions-of-anova">Underlying assumptions of ANOVA</a><ul>
<li><a href="#variable-type">Variable type</a></li>
<li><a href="#independence">Independence</a></li>
<li><a href="#normality">Normality</a></li>
<li><a href="#equality-of-variances---homogeneity">Equality of variances - homogeneity</a></li>
<li><a href="#another-method-to-test-normality-and-homogeneity">Another method to test normality and homogeneity</a></li>
</ul></li>
<li><a href="#anova">ANOVA</a><ul>
<li><a href="#preliminary-analyses">Preliminary analyses</a></li>
<li><a href="#anova-in-r">ANOVA in R</a></li>
<li><a href="#interpretations-of-anova-results">Interpretations of ANOVA results</a></li>
<li><a href="#whats-next">What’s next?</a></li>
</ul></li>
<li><a href="#post-hoc-test">Post-hoc test</a><ul>
<li><a href="#issue-of-multiple-testing">Issue of multiple testing</a></li>
<li><a href="#post-hoc-tests-in-r-and-their-interpretation">Post-hoc tests in R and their interpretation</a><ul>
<li><a href="#tukey-hsd-test">Tukey HSD test</a></li>
<li><a href="#dunnetts-test">Dunnett’s test</a></li>
</ul></li>
<li><a href="#other-p-values-adjustment-methods">Other <em>p</em>-values adjustment methods</a></li>
</ul></li>
<li><a href="#visualization-of-anova-and-post-hoc-tests-on-the-same-plot">Visualization of ANOVA and post-hoc tests on the same plot</a></li>
<li><a href="#summary">Summary</a></li>
</ul>
</div>

<p><img src="/blog/2020-10-12-anova-in-r_files/anova-in-r.jpeg" style="width:100.0%" /></p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>ANOVA (ANalysis Of VAriance) is a statistical test to determine whether two or more population means are different. In other words, it is used to <strong>compare two or more groups</strong> to see if they are significantly <strong>different</strong>.</p>
<p>In practice, however, the:</p>
<ul>
<li><a href="/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/"><strong>Student t-test</strong></a> is used to compare <strong>2 groups</strong>;</li>
<li><strong>ANOVA</strong> generalizes the t-test beyond 2 groups, so it is used to compare <strong>3 or more groups</strong>.</li>
</ul>
<p>Note that there are several versions of the ANOVA (e.g., one-way ANOVA, two-way ANOVA, mixed ANOVA, repeated measures ANOVA, etc.). In this article, we present the simplest form only—the <strong>one-way ANOVA</strong><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>—and we refer to it as ANOVA in the remaining of the article.</p>
<p>Although ANOVA is used to make inference about <a href="/blog/descriptive-statistics-by-hand/#mean">means</a> of different groups, the method is called “analysis of <em><a href="/blog/descriptive-statistics-by-hand/#variance">variance</a></em>”. It is called like this because it compares the “between” variance (the variance between the different groups) and the variance “within” (the variance within each group). If the between variance is significantly larger than the within variance, the group means are declared to be different. Otherwise, we cannot conclude one way or the other. The two variances are compared to each other by taking the ratio (<span class="math inline">\(\frac{variance_{between}}{variance_{within}}\)</span>) and then by comparing this ratio to a threshold from the Fisher <a href="/blog/a-guide-on-how-to-read-statistical-tables/">probability distribution</a> (a threshold based on a specific significance level, usually 5%).</p>
<p>This is enough theory regarding the ANOVA method for now. In the remaining of this article, we discuss about it from a more practical point of view, and in particular we will cover the following points:</p>
<ul>
<li>the aim of the ANOVA, when it should be used and the null/alternative hypothesis</li>
<li>the underlying assumptions of the ANOVA and how to check them</li>
<li>how to perform the ANOVA in R</li>
<li>how to interpret results of the ANOVA</li>
<li>understand the notion of post-hoc test and interpret the results</li>
<li>how to visualize results of ANOVA and post-hoc tests</li>
</ul>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<p>Data for the present article is the <code>penguins</code> dataset (an alternative to the well-known <code>iris</code> dataset), accessible via the <a href="https://github.com/allisonhorst/palmerpenguins" target="_blank"><code>{palmerpenguins}</code> package</a>:</p>
<pre class="r"><code># install.packages(&quot;palmerpenguins&quot;)
library(palmerpenguins)</code></pre>
<p>The dataset contains data for 344 penguins of 3 different species (Adelie, Chinstrap and Gentoo). The dataset contains 8 variables, but we focus only on the flipper length and the species for this article, so we keep only those 2 variables:</p>
<pre class="r"><code>library(tidyverse)

dat &lt;- penguins %&gt;%
  select(species, flipper_length_mm)</code></pre>
<p>(If you are unfamiliar with the pipe operator (<code>%&gt;%</code>), you can also <a href="/blog/data-manipulation-in-r/#subset-a-dataset">select variables</a> with <code>penguins[, c("species", "flipper_length_mm")]</code>. Learn more ways to select variables in the article about <a href="/blog/data-manipulation-in-r/">data manipulation</a>.)</p>
<p>Below some basic <a href="/blog/descriptive-statistics-in-r/">descriptive statistics</a> and a plot (made with the <a href="/blog/graphics-in-r-with-ggplot2/"><code>{ggplot2}</code> package</a>) of our dataset before we proceed to the goal of the ANOVA:</p>
<pre class="r"><code>summary(dat)</code></pre>
<pre><code>##       species    flipper_length_mm
##  Adelie   :152   Min.   :172.0    
##  Chinstrap: 68   1st Qu.:190.0    
##  Gentoo   :124   Median :197.0    
##                  Mean   :200.9    
##                  3rd Qu.:213.0    
##                  Max.   :231.0    
##                  NA&#39;s   :2</code></pre>
<p>Flipper length varies from 172 to 231 mm, with a mean of 200.9 mm. There are respectively 152, 68 and 124 penguins of the species Adelie, Chinstrap and Gentoo.</p>
<pre class="r"><code>library(ggplot2)

ggplot(dat) +
  aes(x = species, y = flipper_length_mm, color = species) +
  geom_jitter() +
  theme(legend.position = &quot;none&quot;)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Here, the <a href="/blog/data-types-in-r/#factor">factor</a> is the <code>species</code> variable which contains 3 modalities or groups (Adelie, Chinstrap and Gentoo).</p>
</div>
<div id="aim-and-hypotheses-of-anova" class="section level1">
<h1>Aim and hypotheses of ANOVA</h1>
<p>As mentioned in the introduction, the ANOVA is used to compare groups (in practice, 3 or more groups). More generally, it is used to:</p>
<ul>
<li>study whether measurements are similar across different modalities (also called levels or treatments in the context of ANOVA) of a <a href="/blog/variable-types-and-examples/#qualitative">categorical</a> variable</li>
<li>compare the impact of the different levels of a categorical variable on a <a href="/blog/variable-types-and-examples/#quantitative">quantitative</a> variable</li>
<li>explain a quantitative variable based on a qualitative variable</li>
</ul>
<p>In this context and as an example, we are going to use an ANOVA to help us answer the question: “<strong>Are flippers length different for the 3 species of penguins?</strong>”.</p>
<p>The null and alternative hypothesis of an ANOVA are:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\mu_{Adelie} = \mu_{Chinstrap} = \mu_{Gentoo}\)</span> (<span class="math inline">\(\Rightarrow\)</span> the 3 species are equal in terms of flipper length)</li>
<li><span class="math inline">\(H_1\)</span>: <em>at least</em> one mean is different (<span class="math inline">\(\Rightarrow\)</span> at least one species is different from the other 2 species in terms of flipper length)</li>
</ul>
<p>Be careful that the alternative hypothesis is <strong><em>not</em></strong> that all means are different. The opposite of all means being equal (<span class="math inline">\(H_0\)</span>) is that <em>at least</em> one mean is different from the others (<span class="math inline">\(H_1\)</span>). In this sense, if the null hypothesis is rejected, it means that at least one species is different from the other 2, but not necessarily that all 3 species are different from each other. It could be that flipper length for the species Adelie is different than for the species Chinstrap and Gentoo, but flipper length is similar between Chinstrap and Gentoo. Other types of test (known as post-hoc tests and covered in this <a href="/blog/anova-in-r/#post-hoc-test">section</a>) must be performed to test whether all 3 species differ.</p>
</div>
<div id="underlying-assumptions-of-anova" class="section level1">
<h1>Underlying assumptions of ANOVA</h1>
<p>As for many <a href="/tags/inferential-statistics/">statistical tests</a>, there are some assumptions that need to be met in order to be able to interpret the results. When one or several assumptions are not met, although it is technically possible to perform these tests, it would be incorrect to interpret the results and trust the conclusions.</p>
<p>Below are the assumptions of the ANOVA, how to test them and which other tests exist if an assumption is not met:</p>
<ul>
<li><strong>Variable type</strong>: ANOVA requires a mix of one <a href="/blog/variable-types-and-examples/#continuous">continuous quantitative</a> dependent variable (which corresponds to the measurements to which the question relates) and one <a href="/blog/variable-types-and-examples/#qualitative">qualitative</a> independent variable (with at least 2 levels which will determine the groups to compare).</li>
<li><strong>Independence</strong>: the data, collected from a representative and randomly selected portion of the total <a href="/blog/what-is-the-difference-between-population-and-sample/">population</a>, should be independent. The assumption of independence is most often verified based on the design of the experiment and on the good control of experimental conditions rather than via a formal test. If you are still unsure about independence based on the experiment design, ask yourself if one observation is related to another (if one observation has an impact on another) within each group or between the groups themselves. If not, it is most likely that you have independent <a href="/blog/what-is-the-difference-between-population-and-sample/">samples</a>. If observations between samples (forming the different groups to be compared) are dependent (for example, if three measurements have been collected on the <strong>same individuals</strong> as it is often the case in medical studies when measuring a metric (i) before, (ii) during and (iii) after a treatment), the repeated measures ANOVA should be preferred in order to take into account the dependency between the samples.</li>
<li><strong>Normality</strong>: Residuals<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> should follow approximately a <a href="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/"><strong>normal distribution</strong></a>. The normality assumption can be tested visually thanks to a <a href="/blog/descriptive-statistics-in-r/#histogram">histogram</a> and a <a href="/blog/descriptive-statistics-in-r/#qq-plot">QQ-plot</a>, and/or formally via a <a href="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/#normality-test">normality test</a> such as the Shapiro-Wilk or Kolmogorov-Smirnov test. If, even after a transformation of your data (e.g., logarithmic transformation, square root, Box-Cox, etc.), the residuals still do not follow approximately a normal distribution, the Kruskal-Wallis test can be applied (<code>kruskal.test(variable ~ group, data = dat</code> in R). This non-parametric test, robust to non normal distributions, has the same goal than the ANOVA—compare 3 or more groups—but it uses sample medians instead of sample means to compare groups.</li>
<li><strong>Equality of variances</strong>: the variances of the different groups should be equal in the populations (an assumption called homogeneity of the variances, or even sometimes referred as homoscedasticity, as opposed to heteroscedasticity if variances are different across groups). This assumption can be tested graphically (by comparing the dispersion in a <a href="/blog/descriptive-statistics-in-r/#boxplot">boxplot</a> or <a href="/blog/descriptive-statistics-in-r/#dotplot">dotplot</a> for instance), or more formally via the Levene’s test (<code>leveneTest(variable ~ group)</code> from the <code>{car}</code> package) or Bartlett’s test, among others. If the hypothesis of equal variances is rejected, another version of the ANOVA can be used: the Welch test (<code>oneway.test(variable ~ group, var.equal = FALSE)</code>). Note that the Welch test does not require homogeneity of the variances, but the distributions should still follow approximately a normal distribution. Note that the Kruskal-Wallis test does not require the assumptions of normality nor homoscedasticity of the variances.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></li>
</ul>
<p>Choosing the appropriate test depending on whether assumptions are met may be confusing so here is a brief summary:</p>
<ol style="list-style-type: decimal">
<li>Check that your observations are independent.</li>
<li>If they are independent, test the normality of residuals:
<ul>
<li>If normality is assumed, test the homogeneity of the variances:
<ul>
<li>If variances are equal, use <strong>ANOVA</strong>.</li>
<li>If variances are not equal, use the <strong>Welch test</strong>.</li>
</ul></li>
<li>If normality is not assumed, use the <strong>Kruskal-Wallis test</strong>.</li>
</ul></li>
</ol>
<p>Now that we have seen the underlying assumptions of the ANOVA, we review them specifically for our dataset before applying the appropriate version of the test.</p>
<div id="variable-type" class="section level2">
<h2>Variable type</h2>
<p>The dependent variable <code>flipper_length_mm</code> is a <a href="/blog/variable-types-and-examples/#quantitative">quantitative</a> variable and the independent variable <code>species</code> is a <a href="/blog/variable-types-and-examples/#qualitative">qualitative</a> one (with 3 levels corresponding to the 3 species). So we have a mix of the two types of variable and this assumption is met.</p>
</div>
<div id="independence" class="section level2">
<h2>Independence</h2>
<p>Independence of the observations is assumed as data have been collected from a randomly selected portion of the population and measurements within and between the 3 samples are not related.</p>
<p>The independence assumption is most often verified based on the design of the experiment and on the good control of experimental conditions, as it is the case here. If you really want to test it more formally, you can, however, test it via a statistical test—the Durbin-Watson test (in R: <code>durbinWatsonTest(res_lm)</code> where <code>res_lm</code> is a linear model). The null hypothesis of this test specifies an autocorrelation coefficient = 0, while the alternative hypothesis specifies an autocorrelation coefficient <span class="math inline">\(\ne\)</span> 0.</p>
</div>
<div id="normality" class="section level2">
<h2>Normality</h2>
<p>Remember that <a href="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/">normality</a> of residuals can be tested visually via a <a href="/blog/descriptive-statistics-in-r/#histogram">histogram</a> and a <a href="/blog/descriptive-statistics-in-r/#qq-plot">QQ-plot</a>, and/or formally via a <a href="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/#normality-test">normality test</a> (Shapiro-Wilk test for instance).</p>
<p>Before checking the normality assumption, we first need to compute the ANOVA (more on that in this <a href="/blog/anova-in-r/#anova-in-r">section</a>). We then save the results in <code>res_aov</code> :</p>
<pre class="r"><code>res_aov &lt;- aov(flipper_length_mm ~ species,
  data = dat
)</code></pre>
<p>We can now check normality visually:</p>
<pre class="r"><code>par(mfrow = c(1, 2)) # combine plots

# histogram
hist(res_aov$residuals)

# QQ-plot
library(car)
qqPlot(res_aov$residuals,
  id = FALSE # id = FALSE to remove point identification
)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>From the histogram and QQ-plot above, we can already see that the normality assumption seems to be met. Indeed, the histogram roughly form a bell curve, indicating that the residuals follow a normal distribution. Furthermore, points in the QQ-plots roughly follow the straight line and most of them are within the confidence bands, also indicating that residuals follow approximately a normal distribution.</p>
<p>Some researchers stop here and assume that normality is met, while others also test the assumption via a formal statistical test. It is your choice to test it (i) only visually, (ii) only via a normality test, or (iii) both visually AND via a normality test. Bear in mind, however, the two following points:</p>
<ol style="list-style-type: decimal">
<li>ANOVA is quite robust to small deviations from normality. This means that it is not an issue (from the perspective of the interpretation of the ANOVA results) if a small number of points deviates slightly from the normality,</li>
<li>normality tests are sometimes quite conservative, meaning that the null hypothesis of normality may be rejected due to a limited deviation from normality. This is especially the case with large samples as power of the test increases with the sample size.</li>
</ol>
<p>In practice, I tend to prefer the (i) visual approach only, but again, this is a matter of personal choice and also depends on the context of the analysis.</p>
<p>Still for the sake of illustration, we also now test the normality assumption via a normality test. You can use the Shapiro-Wilk test or the Kolmogorov-Smirnov test, among others. Remember that the null and alternative hypothesis are:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: data come from a normal distribution</li>
<li><span class="math inline">\(H_1\)</span>: data do <strong><em>not</em></strong> come from a normal distribution</li>
</ul>
<p>In R, we can test normality of the residuals with the Shapiro-Wilk test thanks to the <code>shapiro.test()</code> function:</p>
<pre class="r"><code>shapiro.test(res_aov$residuals)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  res_aov$residuals
## W = 0.99452, p-value = 0.2609</code></pre>
<p><em>P</em>-value of the Shapiro-Wilk test on the residuals is larger than the usual significance level of <span class="math inline">\(\alpha = 5\%\)</span>, so we do not reject the hypothesis that residuals follow a normal distribution (<em>p</em>-value = 0.261).</p>
<p>This result is in line with the visual approach. In our case, the normality assumption is thus met both visually and formally.</p>
<p><em>Side note: Remind that the p-value is the <a href="/blog/the-9-concepts-and-formulas-in-probability-that-every-data-scientist-should-know/">probability</a> of having observations as extreme as the ones we have observed in the sample(s) given that the null hypothesis is true. If the p-value <span class="math inline">\(&lt; \alpha\)</span> (indicating that it is not likely to observe the data we have in the sample given that the null hypothesis is true), the null hypothesis is rejected, otherwise the null hypothesis is not rejected. See more about <a href="/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/#a-note-on-p-value-and-significance-level-alpha">p-value and significance level</a> if you are unfamiliar with those important statistical concepts.</em></p>
<p>Remember that if the normality assumption was not reached, some transformation(s) would need to be applied on the raw data in the hope that residuals would better fit a normal distribution, or you would need to use the non-parametric version of the ANOVA—the Kruskal-Wallis test.</p>
<p>As pointed out by a reader (see comments at the very end of the article), the normality assumption can also be tested on the “raw” data (i.e., the observations) instead of the residuals. However, if you test the normality assumption on the raw data, it must be tested for <em>each group separately</em> as the ANOVA requires normality in <em>each group</em>.</p>
<p>Testing normality on all residuals or on the observations per group is equivalent, and will give similar results. Indeed, saying “The distribution of Y within each group is normally distributed” is the same as saying “The residuals are normally distributed”.</p>
<p>Remember that residuals are the distance between the actual value of Y and the mean value of Y for a specific value of X, so the grouping variable is induced in the computation of the residuals.</p>
<p>So in summary, in ANOVA you actually have two options for testing normality:</p>
<ol style="list-style-type: decimal">
<li>Checking normality separately for each group on the “raw” data (Y values)</li>
<li>Checking normality on all residuals (but not per group)</li>
</ol>
<p>In practice, you will see that it is often easier to just use the residuals and check them all together, especially if you have many groups or few observations per group.</p>
<p>If you are still not convinced: remember that an ANOVA is a special case of a linear model. Suppose your independent variable is a <a href="/blog/variable-types-and-examples/#continuous">continuous variable</a> (instead of a <a href="/blog/variable-types-and-examples/#qualitative">categorical variable</a>), the only option you have left is to check normality on the residuals, which is precisely what is done for testing normality in linear regression models.</p>
</div>
<div id="equality-of-variances---homogeneity" class="section level2">
<h2>Equality of variances - homogeneity</h2>
<p>Assuming residuals follow a normal distribution, it is now time to check whether the variances are equal across species or not. The result will have an impact on whether we use the ANOVA or the Welch test.</p>
<p>This can again be verified visually—via a <a href="/blog/descriptive-statistics-in-r/#boxplot">boxplot</a> or <a href="/blog/descriptive-statistics-in-r/#dotplot">dotplot</a>—or more formally via a statistical test (Levene’s test, among others).</p>
<p>Visually, we have:</p>
<pre class="r"><code># Boxplot
boxplot(flipper_length_mm ~ species,
  data = dat
)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Dotplot
library(&quot;lattice&quot;)

dotplot(flipper_length_mm ~ species,
  data = dat
)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-8-2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Both the boxplot and the dotplot show a similar variance for the different species. In the boxplot, this can be seen by the fact that the boxes and the whiskers have a comparable size for all species. There are a couple of <a href="/blog/outliers-detection-in-r/">outliers</a> as shown by the points outside the whiskers, but this does not change the fact that the <a href="/blog/descriptive-statistics-by-hand/#dispersion">dispersion</a> is more or less the same between the different species.</p>
<p>In the dotplot, this can be seen by the fact that points for all 3 species have more or less the same <a href="/blog/descriptive-statistics-in-r/#range">range</a>, a sign of the dispersion and thus the <a href="/blog/descriptive-statistics-by-hand/#variance">variance</a> being similar.</p>
<p>Like the normality assumption, if you feel that the visual approach is not sufficient, you can formally test for equality of the variances with a Levene’s or Bartlett’s test. Notice that the Levene’s test is less sensitive to departures from normal distribution than the Bartlett’s test.</p>
<p>The null and alternative hypothesis for both tests are:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: variances are equal</li>
<li><span class="math inline">\(H_1\)</span>: at least one variance is different</li>
</ul>
<p>In R, the Levene’s test can be performed thanks to the <code>leveneTest()</code> function from the <code>{car}</code> package:</p>
<pre class="r"><code># Levene&#39;s test
library(car)

leveneTest(flipper_length_mm ~ species,
  data = dat
)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##        Df F value Pr(&gt;F)
## group   2  0.3306 0.7188
##       339</code></pre>
<p>The <em>p</em>-value being larger than the significance level of 0.05, we do not reject the null hypothesis, so we cannot reject the hypothesis that variances are equal between species (<em>p</em>-value = 0.719).</p>
<p>This result is also in line with the visual approach, so the homogeneity of variances is met both visually and formally.</p>
</div>
<div id="another-method-to-test-normality-and-homogeneity" class="section level2">
<h2>Another method to test normality and homogeneity</h2>
<p>For your information, it is also possible to test the homogeneity of the variances and the normality of the residuals visually (and both at the same time) via the <code>plot()</code> function:</p>
<pre class="r"><code>par(mfrow = c(1, 2)) # combine plots

# 1. Homogeneity of variances
plot(res_aov, which = 1)

# 2. Normality
plot(res_aov, which = 2)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Plot on the left hand side shows that there is no evident relationships between residuals and fitted values (the mean of each group), so homogeneity of variances is assumed. If homogeneity of variances was violated, the red line would not be flat.</p>
<p>Plot on the right hand side shows that residuals follow approximately a normal distribution, so normality is assumed. If normality was violated, points would consistently deviate from the dotted line.</p>
</div>
</div>
<div id="anova" class="section level1">
<h1>ANOVA</h1>
<p>We showed that all assumptions of the ANOVA are met. We can thus proceed to the implementation of the ANOVA in R, but first, let’s do some preliminary analyses to better understand the research question.</p>
<div id="preliminary-analyses" class="section level2">
<h2>Preliminary analyses</h2>
<p>A good practice before actually performing the ANOVA in R is to <strong>visualize the data</strong> in relation to the research question. The best way to do so is to draw and compare boxplots of the quantitative variable <code>flipper_length_mm</code> for each species.</p>
<p>This can be done with the <code>boxplot()</code> function in base R (same code than the visual check of equal variances):</p>
<pre class="r"><code>boxplot(flipper_length_mm ~ species,
  data = dat
)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-11-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Or with the <a href="/blog/graphics-in-r-with-ggplot2/"><code>{ggplot2}</code> package</a>:</p>
<pre class="r"><code>library(ggplot2)

ggplot(dat) +
  aes(x = species, y = flipper_length_mm) +
  geom_boxplot()</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-12-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The boxplots above show that, at least for our sample, penguins of the species <code>Gentoo</code> seem to have the biggest flipper, and <code>Adelie</code> species the smallest flipper.</p>
<p>Besides a boxplot for each species, it is also a good practice to compute some <a href="/blog/descriptive-statistics-in-r/"><strong>descriptive statistics</strong></a> such as the <a href="/blog/descriptive-statistics-in-r/#mean">mean</a> and <a href="/blog/descriptive-statistics-in-r/#standard-deviation-and-variance">standard deviation</a> by species. This can be done, for instance, with the <code>aggregate()</code> function:</p>
<pre class="r"><code>aggregate(flipper_length_mm ~ species,
  data = dat,
  function(x) round(c(mean = mean(x), sd = sd(x)), 2)
)</code></pre>
<pre><code>##     species flipper_length_mm.mean flipper_length_mm.sd
## 1    Adelie                 189.95                 6.54
## 2 Chinstrap                 195.82                 7.13
## 3    Gentoo                 217.19                 6.48</code></pre>
<p>or with the <code>summarise()</code> and <code>group_by()</code> functions from the <code>{dplyr}</code> package:</p>
<pre class="r"><code>library(dplyr)

group_by(dat, species) %&gt;%
  summarise(
    mean = mean(flipper_length_mm, na.rm = TRUE),
    sd = sd(flipper_length_mm, na.rm = TRUE)
  )</code></pre>
<pre><code>## # A tibble: 3 x 3
##   species    mean    sd
##   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1 Adelie     190.  6.54
## 2 Chinstrap  196.  7.13
## 3 Gentoo     217.  6.48</code></pre>
<p>Mean is also the lowest for <code>Adelie</code> and highest for <code>Gentoo</code>. Boxplots and descriptive statistics are, however, not enough to conclude that flippers are significantly different in the 3 populations of penguins.</p>
</div>
<div id="anova-in-r" class="section level2">
<h2>ANOVA in R</h2>
<p>As you guessed by now, only the ANOVA can help us to make inference about the population given the sample at hand, and help us to answer the initial research question “Are flippers length different for the 3 species of penguins?”.</p>
<p>ANOVA in R can be done in several ways, of which two are presented below:</p>
<ol style="list-style-type: decimal">
<li>With the <code>oneway.test()</code> function:</li>
</ol>
<pre class="r"><code># 1st method:
oneway.test(flipper_length_mm ~ species,
  data = dat,
  var.equal = TRUE # assuming equal variances
)</code></pre>
<pre><code>## 
##  One-way analysis of means
## 
## data:  flipper_length_mm and species
## F = 594.8, num df = 2, denom df = 339, p-value &lt; 2.2e-16</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>With the <code>summary()</code> and <code>aov()</code> functions:</li>
</ol>
<pre class="r"><code># 2nd method:
res_aov &lt;- aov(flipper_length_mm ~ species,
  data = dat
)

summary(res_aov)</code></pre>
<pre><code>##              Df Sum Sq Mean Sq F value Pr(&gt;F)    
## species       2  52473   26237   594.8 &lt;2e-16 ***
## Residuals   339  14953      44                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 2 observations deleted due to missingness</code></pre>
<p>As you can see from the two outputs above, the test statistic (<code>F =</code> in the first method and <code>F value</code> in the second one) and the <em>p</em>-value (<code>p-value</code> in the first method and <code>Pr(&gt;F)</code> in the second one) are exactly the same for both methods, which means that in case of equal variances, results and conclusions will be unchanged.</p>
<p>The advantage of the first method is that it is easy to switch from the ANOVA (used when variances are equal) to the Welch test (used when variances are <strong>un</strong>equal). This can be done by replacing <code>var.equal = TRUE</code> by <code>var.equal = FALSE</code>, as presented below:</p>
<pre class="r"><code>oneway.test(flipper_length_mm ~ species,
  data = dat,
  var.equal = FALSE # assuming unequal variances
)</code></pre>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  flipper_length_mm and species
## F = 614.01, num df = 2.00, denom df = 172.76, p-value &lt; 2.2e-16</code></pre>
<p>The advantage of the second method, however, is that:</p>
<ul>
<li>the full ANOVA table (with degrees of freedom, mean squares, etc.) is printed, which may be of interest in some (theoritical) cases</li>
<li>results of the ANOVA (<code>res_aov</code>) can be saved for later use (especially useful for <a href="/blog/anova-in-r/#post-hoc-test">post-hoc tests</a>)</li>
</ul>
</div>
<div id="interpretations-of-anova-results" class="section level2">
<h2>Interpretations of ANOVA results</h2>
<p>Given that the <em>p</em>-value is smaller than 0.05, we reject the null hypothesis, so we reject the hypothesis that all means are equal. Therefore, we can conclude that <strong>at least one species is different than the others in terms of flippers length</strong> (<em>p</em>-value &lt; 2.2e-16).</p>
<p>(<em>For the sake of illustration</em>, if the <em>p</em>-value was larger than 0.05: we cannot reject the null hypothesis that all means are equal, so we cannot reject the hypothesis that the 3 considered species of penguins are equal in terms of flippers length.)</p>
</div>
<div id="whats-next" class="section level2">
<h2>What’s next?</h2>
<p>If the <strong>null hypothesis is not rejected</strong> (<em>p</em>-value <span class="math inline">\(\ge\)</span> 0.05), it means that we do not reject the hypothesis that all groups are equal. The ANOVA more or less stops here. Other types of analyses can be performed of course, but—given the data at hand—we could not prove that at least one group was different so we usually do not go further with the ANOVA.</p>
<p>On the contrary, if <em>and only if</em> the <strong>null hypothesis is rejected</strong> (as it is our case since the <em>p</em>-value &lt; 0.05), we proved that at least one group is different. We can decide to stop here if we are only interested to test whether all species are equal in terms of flippers length.</p>
<p>But most of the time, when we showed thanks to an ANOVA that at least one group is different, we are also interested in knowing <strong>which</strong> one(s) is(are) different. Results of an ANOVA, however, do <strong><em>NOT</em></strong> tell us which group(s) is(are) different from the others.</p>
<p>To test this, we need to use other types of test, referred as post-hoc tests (in Latin, “after this”, so after obtaining statistically significant ANOVA results) or multiple pairwise-comparison tests. This family of statistical tests is the topic of the following sections.</p>
</div>
</div>
<div id="post-hoc-test" class="section level1">
<h1>Post-hoc test</h1>
<div id="issue-of-multiple-testing" class="section level2">
<h2>Issue of multiple testing</h2>
<p>In order to see which group(s) is(are) different from the others, we need to <strong>compare groups 2 by 2</strong>. In practice, since there are 3 species, we are going to compare species 2 by 2 as follows:</p>
<ol style="list-style-type: decimal">
<li>Chinstrap versus Adelie</li>
<li>Gentoo vs. Adelie</li>
<li>Gentoo vs. Chinstrap</li>
</ol>
<p>In theory, we could compare species thanks to 3 <a href="/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/">Student’s t-tests</a> since we need to compare 2 groups and a t-test is used precisely in that case.</p>
<p>However, if several t-tests are performed, the issue of <strong>multiple testing</strong> (also referred as multiplicity) arises. In short, when several statistical tests are performed, some will have <em>p</em>-values less than <span class="math inline">\(\alpha\)</span> purely by chance, even if all null hypotheses are in fact true.</p>
<p>To demonstrate the problem, consider our case where we have 3 hypotheses to test and a desired significance level of 0.05. The probability of observing at least one significant result (at least one <em>p</em>-value &lt; 0.05) just due to chance is:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
P(\text{at least 1 signif. result}) &amp; = 1 - P(\text{no signif. results}) \\
 &amp; = 1 - (1 - 0.05)^3 \\
 &amp; = 0.142625
\end{split}
\end{equation}\]</span></p>
<p>So, with as few as 3 tests being considered, we already have a 14.26% chance of observing at least one significant result, even if all of the tests are actually not significant.</p>
<p>And as the number of groups increases, the number of comparisons increases as well, so the probability of having a significant result simply due to chance keeps increasing. For example, with 10 groups we need to make 45 comparisons and the probability of having at least one significant result by chance becomes <span class="math inline">\(1 - (1 - 0.05)^{45} = 90\%\)</span>. So it is very likely to observe a significant result just by chance when comparing 10 groups, and when we have 14 groups or more we are almost certain (99%) to have a false positive!</p>
<p>Post-hoc tests take into account that multiple tests are done and deal with the problem by adjusting <span class="math inline">\(\alpha\)</span> in some way, so that the probability of observing at least one significant result due to chance remains below our desired significance level.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
</div>
<div id="post-hoc-tests-in-r-and-their-interpretation" class="section level2">
<h2>Post-hoc tests in R and their interpretation</h2>
<p>Post-hoc tests are a family of statistical tests so there are several of them. The most often used are the <strong>Tukey HSD</strong> and <strong>Dunnett’s</strong> tests:</p>
<ul>
<li>Tukey HSD is used to compare <strong>all groups</strong> to each other (so all possible comparisons of 2 groups).</li>
<li>Dunnett is used to make comparisons with a <strong>reference group</strong>. For example, consider 2 treatment groups and one control group. If you only want to compare the 2 treatment groups with respect to the control group, and you do not want to compare the 2 treatment groups to each other, the Dunnett’s test is preferred.</li>
</ul>
<p>Note that variances are assumed to be equal for both tests. They are presented in the next sections. If variances are not equal, you can use the Games-Howell test, among others.</p>
<div id="tukey-hsd-test" class="section level3">
<h3>Tukey HSD test</h3>
<p>In our case, since there is no “reference” species and we are interested in comparing all species, we are going to use the Tukey HSD test.</p>
<p>In R, the Tukey HSD test is done as follows. This is where the <a href="/blog/anova-in-r/#anova-in-r">second method</a> to perform the ANOVA comes handy because the results (<code>res_aov</code>) are reused for the post-hoc test:</p>
<pre class="r"><code>library(multcomp)

# Tukey HSD test:
post_test &lt;- glht(res_aov,
  linfct = mcp(species = &quot;Tukey&quot;)
)

summary(post_test)</code></pre>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = flipper_length_mm ~ species, data = dat)
## 
## Linear Hypotheses:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## Chinstrap - Adelie == 0   5.8699     0.9699   6.052   &lt;1e-07 ***
## Gentoo - Adelie == 0     27.2333     0.8067  33.760   &lt;1e-07 ***
## Gentoo - Chinstrap == 0  21.3635     1.0036  21.286   &lt;1e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>In the output of the Tukey HSD test, we are interested in the table displayed after <code>Linear Hypotheses:</code>, and more precisely, in the first and last column of the table. The first column shows the comparisons which have been made; the last column (<code>Pr(&gt;|t|)</code>) shows the adjusted<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> <em>p</em>-values for each comparison (with the null hypothesis being the two groups are equal and the alternative hypothesis being the two groups are different).</p>
<p>It is these adjusted <em>p</em>-values that are used to test whether two groups are significantly different or not, and we can be confident that the entire set of comparisons collectively has an error rate of 0.05.</p>
<p>In our example, we tested:</p>
<ol style="list-style-type: decimal">
<li>Chinstrap versus Adelie (line <code>Chinstrap - Adelie == 0</code>)</li>
<li>Gentoo vs. Adelie (line <code>Gentoo - Adelie == 0</code>)</li>
<li>Gentoo vs. Chinstrap (line <code>Gentoo - Chinstrap == 0</code>)</li>
</ol>
<p>All three <em>p</em>-values are smaller than 0.05, so we reject the null hypothesis for all comparisons, which means that <strong>all species are significantly different</strong> in terms of flippers length.</p>
<p>The results of the post-hoc test can be visualized with the <code>plot()</code> function:</p>
<pre class="r"><code>par(mar = c(3, 8, 3, 3))
plot(post_test)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-19-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We see that the confidence intervals do not cross the zero line, which indicate that all groups are significantly different.</p>
<p>Note that the Tukey HSD test can also be done in R with the <code>TukeyHSD()</code> function:</p>
<pre class="r"><code>TukeyHSD(res_aov)</code></pre>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = flipper_length_mm ~ species, data = dat)
## 
## $species
##                       diff       lwr       upr p adj
## Chinstrap-Adelie  5.869887  3.586583  8.153191     0
## Gentoo-Adelie    27.233349 25.334376 29.132323     0
## Gentoo-Chinstrap 21.363462 19.000841 23.726084     0</code></pre>
<p>With this code, it is the column <code>p adj</code> (also the last column) which is of interest. Notice that the conclusions are the same than above: all species are significantly different in terms of flippers length.</p>
<p>The results can also be visualized with the <code>plot()</code> function:</p>
<pre class="r"><code>plot(TukeyHSD(res_aov))</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-21-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="dunnetts-test" class="section level3">
<h3>Dunnett’s test</h3>
<p>We have seen in this <a href="/blog/anova-in-r/#issue-of-multiple-testing">section</a> that as the number of groups increases, the number of comparisons also increases. And as the number of <strong>comparisons increases</strong>, the post-hoc analysis must lower the individual significance level even further, which leads to <strong>lower statistical power</strong> (so a difference between group means in the population is less likely to be detected).</p>
<p>One method to mitigate this and increase the statistical power is by reducing the number of comparisons. This reduction allows the post-hoc procedure to use a larger individual error rate to achieve the desired global error rate. While comparing all possible groups with a Tukey HSD test is a common approach, many studies have a control group and several treatment groups. For these studies, you may need to compare the treatment groups only to the control group, which reduces the number of comparisons.</p>
<p>Dunnett’s test does precisely this—it only compares a group taken as reference to all other groups, but it does not compare all groups to each others.</p>
<p>So to recap:</p>
<ul>
<li>the Tukey HSD test allows to compares <strong>all</strong> groups but at the cost of <strong>less power</strong></li>
<li>the Dunnett’s test allows to only make <strong>comparisons with a reference group</strong>, but with the benefit of <strong>more power</strong></li>
</ul>
<p>Now, again for the sake of illustration, consider that the species <code>Adelie</code> is the reference species and we are only interested in comparing the reference species against the other 2 species. In that scenario, we would use the Dunnett’s test.</p>
<p>In R, the Dunnett’s test is done as follows (the only difference with the code for the Tukey HSD test is in the line <code>linfct = mcp(species = "Dunnett")</code>):</p>
<pre class="r"><code>library(multcomp)

# Dunnett&#39;s test:
post_test &lt;- glht(res_aov,
  linfct = mcp(species = &quot;Dunnett&quot;)
)

summary(post_test)</code></pre>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Dunnett Contrasts
## 
## 
## Fit: aov(formula = flipper_length_mm ~ species, data = dat)
## 
## Linear Hypotheses:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## Chinstrap - Adelie == 0   5.8699     0.9699   6.052 7.59e-09 ***
## Gentoo - Adelie == 0     27.2333     0.8067  33.760  &lt; 1e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>The interpretation is the same as for the Tukey HSD test’s except that in the Dunett’s test we only compare:</p>
<ol style="list-style-type: decimal">
<li>Chinstrap versus Adelie (line <code>Chinstrap - Adelie == 0</code>)</li>
<li>Gentoo vs. Adelie (line <code>Gentoo - Adelie == 0</code>)</li>
</ol>
<p>Both <em>p</em>-values (displayed in the last column) are below 0.05, so we reject the null hypothesis for both comparisons. This means that both the <strong>species Chinstrap and Gentoo are significantly different from the reference species Adelie</strong> in terms of flippers length. (Nothing can be said about the comparison between Chinstrap and Gentoo though.)</p>
<p>Again, the results of the post-hoc test can be visualized with the <code>plot()</code> function:</p>
<pre class="r"><code>par(mar = c(3, 8, 3, 3))
plot(post_test)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-23-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We see that the confidence intervals do not cross the zero line, which indicate that both the species Gentoo and Chinstrap are significantly different from the reference species Adelie.</p>
<p>Note that in R, by default, the reference category for a <a href="/blog/data-types-in-r/#factor">factor variable</a> is the first category in alphabetical order. This is the reason that, by default, the reference species is Adelie.</p>
<p>The reference category can be changed with the <code>relevel()</code> function (or with the <a href="/blog/rstudio-addins-or-how-to-make-your-coding-life-easier/#reordering-factors"><code>{questionr}</code> addin</a>). Considering that we want Gentoo as the reference category instead of Adelie:</p>
<pre class="r"><code># Change reference category:
dat$species &lt;- relevel(dat$species, ref = &quot;Gentoo&quot;)

# Check that Gentoo is the reference category:
levels(dat$species)</code></pre>
<pre><code>## [1] &quot;Gentoo&quot;    &quot;Adelie&quot;    &quot;Chinstrap&quot;</code></pre>
<p>Gentoo now being the first category of the three, it is indeed considered as the reference level.</p>
<p>In order to perform the Dunnett’s test with the new reference we first need to rerun the ANOVA to take into account the new reference:</p>
<pre class="r"><code>res_aov2 &lt;- aov(flipper_length_mm ~ species,
  data = dat
)</code></pre>
<p>We can then run the Dunett’s test with the new results of the ANOVA:</p>
<pre class="r"><code># Dunnett&#39;s test:
post_test &lt;- glht(res_aov2,
  linfct = mcp(species = &quot;Dunnett&quot;)
)

summary(post_test)</code></pre>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Dunnett Contrasts
## 
## 
## Fit: aov(formula = flipper_length_mm ~ species, data = dat)
## 
## Linear Hypotheses:
##                         Estimate Std. Error t value Pr(&gt;|t|)    
## Adelie - Gentoo == 0    -27.2333     0.8067  -33.76   &lt;1e-10 ***
## Chinstrap - Gentoo == 0 -21.3635     1.0036  -21.29   &lt;1e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<pre class="r"><code>par(mar = c(3, 8, 3, 3))
plot(post_test)</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-26-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>From the results above we conclude that Adelie and Chinstrap species are significantly different from Gentoo species in terms of flippers length (<em>p</em>-values &lt; 1e-10).</p>
<p>Note that even if your study does not have a reference group which you can compare to the other groups, it is still often better to do multiple comparisons determined by some research questions than to do all-pairwise tests. By reducing the number of post-hoc comparisons to what is necessary only, and no more, you maximize the statistical power.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
</div>
</div>
<div id="other-p-values-adjustment-methods" class="section level2">
<h2>Other <em>p</em>-values adjustment methods</h2>
<p>For the interested readers, note that you can use other <em>p</em>-values adjustment methods by using the <code>pairwise.t.test()</code> function:</p>
<pre class="r"><code>pairwise.t.test(dat$flipper_length_mm, dat$species,
  p.adjust.method = &quot;holm&quot;
)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  dat$flipper_length_mm and dat$species 
## 
##           Gentoo  Adelie 
## Adelie    &lt; 2e-16 -      
## Chinstrap &lt; 2e-16 3.8e-09
## 
## P value adjustment method: holm</code></pre>
<p>By default, the Holm method is applied but other methods exist. See <code>?p.adjust</code> for all available options.</p>
</div>
</div>
<div id="visualization-of-anova-and-post-hoc-tests-on-the-same-plot" class="section level1">
<h1>Visualization of ANOVA and post-hoc tests on the same plot</h1>
<p>If you are interested in including results of ANOVA and post-hoc tests on the same plot (directly on the boxplots), here is a piece of code which may be of interest to you (edited by myself based on the code found in this <a href="http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/" target="_blank">article</a>):</p>
<pre class="r"><code># Edit from here
x &lt;- which(names(dat) == &quot;species&quot;) # name of grouping variable
y &lt;- which(
  names(dat) == &quot;flipper_length_mm&quot; # names of variables to test
)
method1 &lt;- &quot;anova&quot; # one of &quot;anova&quot; or &quot;kruskal.test&quot;
method2 &lt;- &quot;t.test&quot; # one of &quot;wilcox.test&quot; or &quot;t.test&quot;
my_comparisons &lt;- list(c(&quot;Chinstrap&quot;, &quot;Adelie&quot;), c(&quot;Gentoo&quot;, &quot;Adelie&quot;), c(&quot;Gentoo&quot;, &quot;Chinstrap&quot;)) # comparisons for post-hoc tests
# Edit until here


# Edit at your own risk
library(ggpubr)
for (i in y) {
  for (j in x) {
    p &lt;- ggboxplot(dat,
      x = colnames(dat[j]), y = colnames(dat[i]),
      color = colnames(dat[j]),
      legend = &quot;none&quot;,
      palette = &quot;npg&quot;,
      add = &quot;jitter&quot;
    )
    print(
      p + stat_compare_means(aes(label = paste0(..method.., &quot;, p-value = &quot;, ..p.format..)),
        method = method1, label.y = max(dat[, i], na.rm = TRUE)
      )
      + stat_compare_means(comparisons = my_comparisons, method = method2, label = &quot;p.format&quot;) # remove if p-value of ANOVA or Kruskal-Wallis test &gt;= alpha
    )
  }
}</code></pre>
<p><img src="/blog/2020-10-12-anova-in-r_files/figure-html/unnamed-chunk-28-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>As you can see on the above plot, boxplots by species are presented together with <em>p</em>-values of the ANOVA and post-hoc tests.</p>
<p>Besides the fact that it combines a visual representation and results on the same plot, this code also has the advantage that you can perform multiple ANOVA tests at once. See more information in this <a href="/blog/how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way/">article</a>.</p>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<p>In this article, we reviewed the <a href="/blog/anova-in-r/#aim-and-hypotheses-of-anova">goals and hypotheses</a> of an ANOVA, what are the <a href="/blog/anova-in-r/#underlying-assumptions-of-anova">assumptions</a> which need to be verified before being able to trust the results (namely, independence, normality and homogeneity), we then showed <a href="/blog/anova-in-r/#anova-in-r">how to do an ANOVA in R</a> and how to <a href="/blog/anova-in-r/#interpretations-of-anova-results">interpret the results</a>.</p>
<p>An article about ANOVA would not be complete without discussing about <a href="/blog/anova-in-r/#post-hoc-test">post-hoc tests</a>, and in particular, the <a href="/blog/anova-in-r/#tukey-hsd-test">Tukey HSD</a>—to compare all groups—and the <a href="/blog/anova-in-r/#dunnetts-test">Dunnett’s</a> test—to compare a reference group to all other groups.</p>
<p>Last but not least, we showed how to <a href="/blog/anova-in-r/#visualization-of-anova-and-post-hoc-tests">visualize</a> the data and the results of the ANOVA and post-hoc tests in the same plot.</p>
<p>Thanks for reading.</p>
<p>As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Note that it is called <em>one-way</em> or <em>one-factor</em> ANOVA because the means relate to the different modalities of a single independent variable, or factor.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Residuals (denoted <span class="math inline">\(\epsilon\)</span>) are the differences between the observed values of the dependent variable (<span class="math inline">\(y\)</span>) and the predicted values (<span class="math inline">\(\hat{y}\)</span>). In the context of ANOVA, residuals correspond to the differences between the observed values and the mean of all values for that group.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>As long as you use the Kruskal-Wallis test to, <em>in fine</em>, compare groups, homoscedasticity is not required. If you wish to compare medians, the Kruskal-Wallis test requires homoscedasticity. See more information about the difference in this <a href="https://influentialpoints.com/Training/Kruskal-Wallis_ANOVA_use_and_misuse.htm" target="_blank">article</a>.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Note that you could in principle apply the Bonferroni correction to all tests. For example, in the example above, with 3 tests and a global desired significance level of <span class="math inline">\(\alpha\)</span> = 0.05, we would only reject a null hypothesis if the <em>p</em>-value is less than <span class="math inline">\(\frac{0.05}{3}\)</span> = 0.0167. This method is, however, known to be quite conservative, leading to a potentially high rate of false negatives.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>The <em>p</em>-values are adjusted to keep the global significance level to the desired level.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Thanks Michael Friendly for this suggestion.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



                    </div>

<br>                    

      <div class="related">

<h3>Related articles</h3>
<ul>
	
	<li><a href="/blog/one-proportion-and-goodness-of-fit-test-in-r-and-by-hand/">One-proportion and goodness of fit test (in R and by hand)</a></li>
	
	<li><a href="/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r-test-on-one-mean/">How to perform a one sample t-test by hand and in R: test on one mean</a></li>
	
	<li><a href="/blog/wilcoxon-test-in-r-how-to-compare-2-groups-under-the-non-normality-assumption/">Wilcoxon test in R: how to compare 2 groups under the non-normality assumption</a></li>
	
	<li><a href="/blog/how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way/">How to do a t-test or ANOVA for more than one variable at once in R</a></li>
	
	<li><a href="/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/">Student&#39;s t-test in R and by hand: how to compare two groups under different scenarios</a></li>
	
</ul>
</div>
      
      
      <br>
      <h3>Liked this post?</h3> <b>Get updates</b> every time a new article is published.
      <br>
      <small><i>No spam and unsubscribe anytime.</i></small>
      

<link href="//cdn-images.mailchimp.com/embedcode/classic-10_7.css" rel="stylesheet" type="text/css">
<style type="text/css">
	#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width: 300px;}
	 
</style>
<div id="mc_embed_signup">
<form action="https://statsandr.us4.list-manage.com/subscribe/post?u=dbadb70b4f121c714d12c9fc5&amp;id=f8729988c2" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>
    <div id="mc_embed_signup_scroll">
	
<div class="mc-field-group">
	<input type="email" placeholder="Email address" value="" name="EMAIL" class="required email" id="mce-EMAIL">
</div>
<div class="mc-field-group">
	<input type="text" placeholder="First name" value="" name="FNAME" class="required" id="mce-FNAME">
</div>
	<div id="mce-responses" class="clear">
		<div class="response" id="mce-error-response" style="display:none"></div>
		<div class="response" id="mce-success-response" style="display:none"></div>
	</div>    
    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_dbadb70b4f121c714d12c9fc5_f8729988c2" tabindex="-1" value="">
    </div>
    
    <div class="clear"><input type="submit" value="Receive new posts by email" name="subscribe" id="mc-embedded-subscribe" class="button"></div>
    </div>
</form>
</div>

      
<section id="comments">
    <div class="py-3 content">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-sm-12 col-lg-8">
                    <div class="comments">
                        <script src="https://utteranc.es/client.js"
        repo="AntoineSoetewey/statsandr"
        issue-term="pathname"
        label="comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>



<style>
#share-buttons {display: inline-block; vertical-align: middle; }
#share-buttons:after {content: ""; display: block; clear: both;}
#share-buttons > div {
position: relative;
text-align: left; 
height: 36px; 
width: 32px; 
float: left; 
text-align: center;
}
#share-buttons > div > svg {height: 16px; fill: #d5d5d5; margin-top: 10px;}
#share-buttons > div:hover {cursor: pointer;}
#share-buttons > div.facebook:hover > svg {fill: #3B5998;}
#share-buttons > div.twitter:hover > svg {fill: #55ACEE;}
#share-buttons > div.linkedin:hover > svg {fill: #0077b5;}
#share-buttons > div.pinterest:hover > svg {fill: #CB2027;}
#share-buttons > div.mail:hover > svg {fill: #7D7D7D;}
#share-buttons > div.instagram:hover > svg {fill: #C73B92;}
#share-buttons > div.facebook > svg {height: 18px; margin-top: 9px;}
#share-buttons > div.twitter > svg {height: 20px; margin-top: 8px;}
#share-buttons > div.linkedin > svg {height: 19px; margin-top: 7px;}
#share-buttons > div.pinterest > svg {height: 20px; margin-top: 9px;}
#share-buttons > div.mail > svg {height: 14px; margin-top: 11px;}
</style>

<span style="color: silver;">Share on: </span><div id="share-buttons">
<div class="facebook" title="Share this on Facebook" onclick="window.open('http://www.facebook.com/share.php?u=\/blog\/anova-in-r\/');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1343 12v264h-157q-86 0-116 36t-30 108v189h293l-39 296h-254v759h-306v-759h-255v-296h255v-218q0-186 104-288.5t277-102.5q147 0 228 12z"/></svg></div>
<div class="twitter" title="Share this on Twitter" onclick="window.open('http://twitter.com/home?status=\/blog\/anova-in-r\/');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1684 408q-67 98-162 167 1 14 1 42 0 130-38 259.5t-115.5 248.5-184.5 210.5-258 146-323 54.5q-271 0-496-145 35 4 78 4 225 0 401-138-105-2-188-64.5t-114-159.5q33 5 61 5 43 0 85-11-112-23-185.5-111.5t-73.5-205.5v-4q68 38 146 41-66-44-105-115t-39-154q0-88 44-163 121 149 294.5 238.5t371.5 99.5q-8-38-8-74 0-134 94.5-228.5t228.5-94.5q140 0 236 102 109-21 205-78-37 115-142 178 93-10 186-50z"/></svg></div>
<div class="linkedin" title="Share this on Linkedin" onclick="window.open('https://www.linkedin.com/shareArticle?mini=true&url=\/blog\/anova-in-r\/&title=&summary=&source=');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M477 625v991h-330v-991h330zm21-306q1 73-50.5 122t-135.5 49h-2q-82 0-132-49t-50-122q0-74 51.5-122.5t134.5-48.5 133 48.5 51 122.5zm1166 729v568h-329v-530q0-105-40.5-164.5t-126.5-59.5q-63 0-105.5 34.5t-63.5 85.5q-11 30-11 81v553h-329q2-399 2-647t-1-296l-1-48h329v144h-2q20-32 41-56t56.5-52 87-43.5 114.5-15.5q171 0 275 113.5t104 332.5z"/></svg></div>

<div class="mail" title="Share this through Email" onclick="window.open('mailto:?&body=\/blog\/anova-in-r\/');"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1792 710v794q0 66-47 113t-113 47h-1472q-66 0-113-47t-47-113v-794q44 49 101 87 362 246 497 345 57 42 92.5 65.5t94.5 48 110 24.5h2q51 0 110-24.5t94.5-48 92.5-65.5q170-123 498-345 57-39 100-87zm0-294q0 79-49 151t-122 123q-376 261-468 325-10 7-42.5 30.5t-54 38-52 32.5-57.5 27-50 9h-2q-23 0-50-9t-57.5-27-52-32.5-54-38-42.5-30.5q-91-64-262-182.5t-205-142.5q-62-42-117-115.5t-55-136.5q0-78 41.5-130t118.5-52h1472q65 0 112.5 47t47.5 113z"/></svg></div>
</div>

                    
                        <div class="navigation">
                            <div class="row">
                                <div class="col-12 col-md-6">
                                    
                                        <div class="mx-0 mx-md-4 mt-4 text-left">
                                            <a href="/blog/7-benefits-of-sharing-your-code-in-a-data-science-blog/">« Why do I have a data science blog? 7 benefits of sharing your code</a>
                                        </div>
                                    
                                </div>
                                <div class="col-12 col-md-6">
                                    
                                        <div class="mx-0 mx-md-4 mt-4 text-right">
                                            <a href="/blog/waiting-period-cancer-survivors/">Paper: &#39;Waiting period from diagnosis for mortgage insurance issued to cancer survivors&#39; »</a>
                                        </div>
                                    
                                </div>
                            </div>
                        </div>
                    
                </div>
            </div>
        </div>
    </div>

    <div class="my-4 footer">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-sm-12 col-md-5">
                
                    <div class="mx-0 mx-md-4 text-left">
                        
                            <p>
                              <a href="/subscribe/">Newsletter</a>
                              <a href="/faq/">FAQ</a>
                              <a href="/contribute/">Contribute</a>
                              <a href="/support/">Support</a>
                              <a href="/sitemap/">Sitemap</a>
                            </p>
                            <p>
                              <a href="/">&copy; <script>document.write(new Date().getFullYear())</script> Antoine Soetewey</a><a href="/terms/">Terms</a>
                            </p>
                        
                    </div>
                
            </div>
            <div class="col-sm-12 col-md-5">
                <div class="mx-0 mx-md-4 text-right">
                  
                  
                    <a href="https://twitter.com/statsandr" target="_blank">
                        <img class="icon" src="/img/twitter.svg" alt="Twitter" title="Twitter"/>
                    </a>
                    
                    
                    
                        <a href="https://github.com/AntoineSoetewey" target="_blank">
                            <img class="icon" src="/img/github.svg" alt="GitHub" title="GitHub"/>
                        </a>
                    
                    
                    
                    <a href="https://antoinesoetewey.medium.com/" target="_blank">
                        <img class="icon" src="/img/medium-m-brands.svg" alt="Medium" title="Medium"/>
                    </a>
                    

                    

                    

                    

                    

                    

                    
                    
                    
                    <a href="/contact/">
                        <img class="icon" src="/img/envelope-solid.svg" alt="Contact" title="Contact"/>
                    </a>
                    

                    
                        <a href="/index.xml" class="mr-0">
                            <img class="icon" src="/img/rss.svg" alt="RSS" title="RSS"/>
                        </a>
                    

                    
                </div>
            </div>
        </div>
    </div>
</div>



    

    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js" integrity="sha256-sNPiigbfSkqUzMc5rgrdztLnneCMAp6W9wetJUZu9Zw=" crossorigin="anonymous"></script>
        
        <script>
            window.addEventListener('load', function() {
                hljs.initHighlighting();
            }, true);
        </script>
    

    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-86997981-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
        
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
</body>

</html>