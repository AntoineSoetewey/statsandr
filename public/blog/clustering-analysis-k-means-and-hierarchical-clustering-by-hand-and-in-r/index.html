<!doctype html>
<html lang="en-US">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title> Clustering analysis k-means and hierarchical clustering by hand and in R - Stats and R </title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="referrer" content="no-referrer">
    <meta name="description" content="A blog on statistics and R aiming at helping academics and professionals working with data to grasp important concepts in statistics and to apply them in R." />
    <meta property="og:site_name" content="Stats and R" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r/" />
    <meta property="og:title" content="Clustering analysis k-means and hierarchical clustering by hand and in R" />
    <meta property="og:image" content="/image/image.png" />
    <meta property="og:description" content="A blog on statistics and R aiming at helping academics and professionals working with data to grasp important concepts in statistics and to apply them in R." />

    <meta name="twitter:card" content="summary_large_image" />
    
    <meta name="twitter:title" content="Clustering analysis k-means and hierarchical clustering by hand and in R" />
    <meta name="twitter:description" content="A blog on statistics and R aiming at helping academics and professionals working with data to grasp important concepts in statistics and to apply them in R." />
    <meta name="twitter:image" content="/image/image.png" />

    <link rel="canonical" href="/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r/">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous" />

    <link rel="stylesheet" href="/css/custom.css" />

    
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/styles/tomorrow.min.css" integrity="sha256-0QU8ry64q+N6YBIEF/6XF6vUeF15gbNO4tLS6ikk0FI=" crossorigin="anonymous" />
    

    

    <link rel="shortcut icon"
        href="/image/favicon.png">

    
        <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Stats and R" />
    
</head>

<body>
    
    <div class="my-4 my-md-5 header">
    <div class="container">
        <div class="row">
            <div class="col-auto offset-md-1 d-none d-md-block">
                
                    <a href="/">
                        <img class="ml-md-4 logo img-fluid d-block rounded-circle" src="/image/avatar.png" alt="logo">
                    </a>
                
            </div>
            <div class="col-auto align-self-center mr-auto">
                <a href="/">
                    <h1 class="name">Stats and R</h1>
                </a>

                <ul class="nav nav-primary">
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-Posts" href="/blog/">
                                
                                Posts
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-tags" href="/tags/">
                                
                                Tags
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-about" href="/about/">
                                
                                About
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-links" href="/links/">
                                
                                Links
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="text-uppercase nav-link text-contact" href="/contact/">
                                
                                Contact
                            </a>
                        </li>
                    

                    
                </ul>

            </div>
        </div>
    </div>
</div>


    <div class="content">
        <div class="container">
            <div class="row justify-content-center">
                <div class="col-sm-12 col-md-10">
                    <h1 class="mx-0 mx-md-4 blog-post-title">Clustering analysis k-means and hierarchical clustering by hand and in R</h1>

                    <div class="mb-md-4 meta">
                        
                            
                                <span class="author" title="Antoine Soetewey">
                                    Antoine Soetewey
                                </span>
                            
                        

                        <span class="date middot" title='Wed Feb 5 2020 00:00:00 UTC'>
                            2020-02-05
                        </span>

                        <span class="reading-time middot">
                            11 minute read
                        </span>

                        <div class="d-none d-md-inline tags">
                            <ul class="list-unstyled d-inline">
                                
                                    <li class="d-inline middot">
                                        <a href="/tags/r">R</a>
                                    </li>
                                
                                    <li class="d-inline middot">
                                        <a href="/tags/statistics">Statistics</a>
                                    </li>
                                
                            </ul>
                        </div>

                        <div class="d-none d-md-inline tags">
                            <ul class="list-unstyled d-inline">
                                
                                
                            </ul>
                        </div>
                    </div>

                    <div class="markdown">
                        
    

<div id="TOC">
<ul>
<li><a href="#what-is-clustering-analysis">What is clustering analysis?</a><ul>
<li><a href="#application-1-computing-distances">Application 1: Computing distances</a></li>
</ul></li>
<li><a href="#k-means-clustering"><em>k</em>-means clustering</a><ul>
<li><a href="#application-2-k-means-clustering">Application 2: <em>k</em>-means clustering</a><ul>
<li><a href="#data">Data</a></li>
<li><a href="#kmeans-with-2-groups"><code>kmeans()</code> with 2 groups</a></li>
<li><a href="#quality-of-a-k-means-partition">Quality of a <em>k</em>-means partition</a></li>
<li><a href="#nstart-for-several-initial-centers"><code>nstart</code> for several initial centers</a></li>
<li><a href="#kmeans-with-3-groups"><code>kmeans()</code> with 3 groups</a><ul>
<li><a href="#manual-application-and-verification-in-r">Manual application and verification in R</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>

<div id="what-is-clustering-analysis" class="section level1">
<h1>What is clustering analysis?</h1>
<p>Clustering analysis is a form of exploratory data analysis in which observations are divided into different groups that share common characteristics.</p>
<p>The purpose of cluster analysis (also known as classification) is to construct groups (or classes or <em>clusters</em>) while ensuring the following property: Within a group the observations must be similar, while the differences between observations belonging to different groups must be significant.</p>
<p>There are two main types of classification:</p>
<ol style="list-style-type: decimal">
<li><em>k</em>-means clustering</li>
<li>Hierarchical clustering</li>
</ol>
<p>The first is generally used when the <strong>number of classes is fixed</strong> in advance, while the second is generally used for an <strong>unknown number of classes</strong> and helps to determine this optimal number. Both methods are illustrated below through applications by hand and in R. Note that for hierarchical clustering, only the <em>ascending</em> classification is presented in this article.</p>
<p>Clustering algorithms use the <strong>distance</strong> in order to separate observations into different groups. Therefore, before diving into the presentation of the two classification methods, a reminder exercise on how to compute distances between points is presented.</p>
<div id="application-1-computing-distances" class="section level2">
<h2>Application 1: Computing distances</h2>
<p>Let a data set containing the points <span class="math inline">\(\boldsymbol{a} = (0, 0)&#39;\)</span>, <span class="math inline">\(\boldsymbol{b} = (1, 0)&#39;\)</span> and <span class="math inline">\(\boldsymbol{c} = (5, 5)&#39;\)</span>. Compute the matrix of Euclidean distances between the points.</p>
<p>Solution:</p>
<p>The points are as follows:</p>
<pre class="r"><code># We create the points in R
a &lt;- c(0, 0)
b &lt;- c(1, 0)
c &lt;- c(5, 5)

X &lt;- rbind(a, b, c) # a, b and c are combined per row
colnames(X) &lt;- c(&quot;x&quot;, &quot;y&quot;) # rename columns

X # display the points</code></pre>
<pre><code>##   x y
## a 0 0
## b 1 0
## c 5 5</code></pre>
<p>By the Pythagorean theorem, we will remember that the distance between 2 points <span class="math inline">\((x_a, y_a)\)</span> and <span class="math inline">\((x_b, y_b)\)</span> in <span class="math inline">\(\mathbb{R}^2\)</span> is given by <span class="math inline">\(\sqrt{(x_a - x_b)^2 + (y_a - y_b)^2}\)</span>. So for instance, for the distance between the points <span class="math inline">\(\boldsymbol{b} = (1, 0)&#39;\)</span> and <span class="math inline">\(\boldsymbol{c} = (5, 5)&#39;\)</span> presented in the statement above, we have :</p>
<p><span class="math display">\[\begin{equation}
\sqrt{(x_b - x_c)^2 + (y_b - y_c)^2} = \sqrt{(1-5)^2 + (0-5)^2} = 6.403124
\end{equation}\]</span></p>
<p>The <code>dist()</code> function in R allows you to find the distance of points in a matrix or dataframe in a very simple way:</p>
<pre class="r"><code># The distance is found using the dist() function:
distance &lt;- dist(X, method = &quot;euclidean&quot;)
distance # display the distance matrix</code></pre>
<pre><code>##          a        b
## b 1.000000         
## c 7.071068 6.403124</code></pre>
<p>Note that the argument <code>method = &quot;euclidean&quot;</code> is not mandatory because the Euclidean method is the default one.</p>
<p>The distance matrix resulting from the <code>dist()</code> function gives the distance between the different points. The Euclidean distance between the points <span class="math inline">\(\boldsymbol{b}\)</span> and <span class="math inline">\(\boldsymbol{c}\)</span> is 6.403124, which corresponds to what we found above via the Pythagorean formula.</p>
<p>Now that the distance has been presented, let’s see how to perform clustering analysis with the k-means algorithm.</p>
</div>
</div>
<div id="k-means-clustering" class="section level1">
<h1><em>k</em>-means clustering</h1>
<p>The first form of classification is the method called <em><em>k</em>-means clustering</em> or the mobile center algorithm. As a reminder, this method aims at partitioning <span class="math inline">\(n\)</span> observations into <span class="math inline">\(k\)</span> clusters in which each observation belongs to the cluster with the closest average, serving as a prototype of the cluster. It is presented below.</p>
<div id="application-2-k-means-clustering" class="section level2">
<h2>Application 2: <em>k</em>-means clustering</h2>
<div id="data" class="section level3">
<h3>Data</h3>
<p>For this exercise, the <code>Eurojobs.csv</code> database available <a href="/blog/data/Eurojobs.csv">here</a> is used.</p>
<p>This database contains the percentage of the population employed in different industries in 26 European countries in 1979. It contains 10 variables:</p>
<ul>
<li><code>Country</code> - the name of the country (identifier)</li>
<li><code>Agr</code> - % of workforce employed in agriculture</li>
<li><code>Min</code> - % in mining</li>
<li><code>Man</code> - % in manufacturing</li>
<li><code>PS</code> - % in power supplies industries</li>
<li><code>Con</code> - % in construction</li>
<li><code>SI</code> - % in service industries</li>
<li><code>Fin</code> - % in finance</li>
<li><code>SPS</code> - % in social and personal services</li>
<li><code>TC</code> - % in transportation and communications</li>
</ul>
<p>We first import the dataset. See <a href="/blog/how-to-import-an-excel-file-in-rstudio">how to import data into R</a> if you need a reminder.</p>
<pre class="r"><code># Import data
Eurojobs &lt;- read.csv(file = &quot;https://www.statsandr.com/blog/data/Eurojobs.csv&quot;,
                     sep = &quot;,&quot;, dec = &quot;.&quot;, header = TRUE)
head(Eurojobs) # head() is used to display only the first 6 observations</code></pre>
<pre><code>##      Country  Agr Min  Man  PS  Con   SI Fin  SPS  TC
## 1    Belgium  3.3 0.9 27.6 0.9  8.2 19.1 6.2 26.6 7.2
## 2    Denmark  9.2 0.1 21.8 0.6  8.3 14.6 6.5 32.2 7.1
## 3     France 10.8 0.8 27.5 0.9  8.9 16.8 6.0 22.6 5.7
## 4 W. Germany  6.7 1.3 35.8 0.9  7.3 14.4 5.0 22.3 6.1
## 5    Ireland 23.2 1.0 20.7 1.3  7.5 16.8 2.8 20.8 6.1
## 6      Italy 15.9 0.6 27.6 0.5 10.0 18.1 1.6 20.1 5.7</code></pre>
<p>Note that there is a numbering before the first variable <code>Country</code>. For more clarity, we will replace this numbering by the country. To do this, we add the argument <code>row.names = 1</code> to the import function <code>read.csv()</code> to specify that the first column corresponds to the row names:</p>
<pre class="r"><code>Eurojobs &lt;- read.csv(
  file = &quot;https://www.statsandr.com/blog/data/Eurojobs.csv&quot;,
  sep = &quot;,&quot;, dec = &quot;.&quot;, header = TRUE, row.names = 1
)
Eurojobs # displays dataset</code></pre>
<pre><code>##                 Agr Min  Man  PS  Con   SI  Fin  SPS  TC
## Belgium         3.3 0.9 27.6 0.9  8.2 19.1  6.2 26.6 7.2
## Denmark         9.2 0.1 21.8 0.6  8.3 14.6  6.5 32.2 7.1
## France         10.8 0.8 27.5 0.9  8.9 16.8  6.0 22.6 5.7
## W. Germany      6.7 1.3 35.8 0.9  7.3 14.4  5.0 22.3 6.1
## Ireland        23.2 1.0 20.7 1.3  7.5 16.8  2.8 20.8 6.1
## Italy          15.9 0.6 27.6 0.5 10.0 18.1  1.6 20.1 5.7
## Luxembourg      7.7 3.1 30.8 0.8  9.2 18.5  4.6 19.2 6.2
## Netherlands     6.3 0.1 22.5 1.0  9.9 18.0  6.8 28.5 6.8
## United Kingdom  2.7 1.4 30.2 1.4  6.9 16.9  5.7 28.3 6.4
## Austria        12.7 1.1 30.2 1.4  9.0 16.8  4.9 16.8 7.0
## Finland        13.0 0.4 25.9 1.3  7.4 14.7  5.5 24.3 7.6
## Greece         41.4 0.6 17.6 0.6  8.1 11.5  2.4 11.0 6.7
## Norway          9.0 0.5 22.4 0.8  8.6 16.9  4.7 27.6 9.4
## Portugal       27.8 0.3 24.5 0.6  8.4 13.3  2.7 16.7 5.7
## Spain          22.9 0.8 28.5 0.7 11.5  9.7  8.5 11.8 5.5
## Sweden          6.1 0.4 25.9 0.8  7.2 14.4  6.0 32.4 6.8
## Switzerland     7.7 0.2 37.8 0.8  9.5 17.5  5.3 15.4 5.7
## Turkey         66.8 0.7  7.9 0.1  2.8  5.2  1.1 11.9 3.2
## Bulgaria       23.6 1.9 32.3 0.6  7.9  8.0  0.7 18.2 6.7
## Czechoslovakia 16.5 2.9 35.5 1.2  8.7  9.2  0.9 17.9 7.0
## E. Germany      4.2 2.9 41.2 1.3  7.6 11.2  1.2 22.1 8.4
## Hungary        21.7 3.1 29.6 1.9  8.2  9.4  0.9 17.2 8.0
## Poland         31.1 2.5 25.7 0.9  8.4  7.5  0.9 16.1 6.9
## Rumania        34.7 2.1 30.1 0.6  8.7  5.9  1.3 11.7 5.0
## USSR           23.7 1.4 25.8 0.6  9.2  6.1  0.5 23.6 9.3
## Yugoslavia     48.7 1.5 16.8 1.1  4.9  6.4 11.3  5.3 4.0</code></pre>
<pre class="r"><code>dim(Eurojobs) # displays the number of rows and columns</code></pre>
<pre><code>## [1] 26  9</code></pre>
<p>We now have a “clean” dataset of 26 observations and 9 variables on which we can base the classification. Note that in this case it is not necessary to standardize the data because they are all expressed in the same unit (in percentage). If this was not the case, we would have had to standardize the data via the <code>scale()</code> function (see below for an example where the data is standardized before classification). The so-called <em>k</em>-means clustering is done via the <code>kmeans()</code> function. We apply the classification with 2 classes and then 3 classes.</p>
</div>
<div id="kmeans-with-2-groups" class="section level3">
<h3><code>kmeans()</code> with 2 groups</h3>
<pre class="r"><code>model &lt;- kmeans(Eurojobs, centers = 2)

# displays the class determined by
# the model for all observations:
print(model$cluster)</code></pre>
<pre><code>##        Belgium        Denmark         France     W. Germany        Ireland 
##              2              2              2              2              1 
##          Italy     Luxembourg    Netherlands United Kingdom        Austria 
##              2              2              2              2              2 
##        Finland         Greece         Norway       Portugal          Spain 
##              2              1              2              1              1 
##         Sweden    Switzerland         Turkey       Bulgaria Czechoslovakia 
##              2              2              1              1              2 
##     E. Germany        Hungary         Poland        Rumania           USSR 
##              2              1              1              1              1 
##     Yugoslavia 
##              1</code></pre>
<p>Note that the argument <code>centers = 2</code> is used to set the number of clusters, determined in advance. In this exercise the number of clusters has been determined arbitrarily. This number of clusters should be determined according to the context and goal of your analysis. Calling <code>print(model$cluster)</code> or <code>model$cluster</code> is the same. This output specifies the group (<em>i.e.</em>, 1 or 2) to which each country belongs.</p>
</div>
<div id="quality-of-a-k-means-partition" class="section level3">
<h3>Quality of a <em>k</em>-means partition</h3>
<p>The quality of a partition is found by calculating the percentage of the <em>TSS</em> “explained” by the partition using the following formula:</p>
<p><span class="math display">\[\begin{equation}
\dfrac{\operatorname{BSS}}{\operatorname{TSS}} \times 100\%,
\end{equation}\]</span></p>
<p>where <em>BSS</em> and <em>TSS</em> stands for <em>Between Sum of Squares</em> and <em>Total Sum of Squares</em>, respectively. The higher the percentage, the better the score because it means that <em>BSS</em> is large and/or <em>WSS</em> is small.</p>
<p>Here is how you can check the quality of the partition in R:</p>
<pre class="r"><code># BSS and TSS are extracted from the model
(BSS &lt;- model$betweenss)</code></pre>
<pre><code>## [1] 4823.535</code></pre>
<pre class="r"><code>(TSS &lt;- model$totss)</code></pre>
<pre><code>## [1] 9299.59</code></pre>
<pre class="r"><code># We calculate the quality of the partition
BSS / TSS * 100</code></pre>
<pre><code>## [1] 51.86826</code></pre>
<p>The quality of the partition is 51.87%. This value has no real interpretation in absolute terms except that a higher quality means a higher explained percentage. However, it is more insightful when it is compared to the quality of other partitions (with the same number of clusters!) in order to determine the best partition among the ones considered.</p>
</div>
<div id="nstart-for-several-initial-centers" class="section level3">
<h3><code>nstart</code> for several initial centers</h3>
<p>The <em>k</em>-means algorithm uses a random set of initial points to arrive at the final classification. Due to the fact that the initial centers are randomly chosen, the same command <code>kmeans(Eurojobs, centers = 2)</code> may give slightly different results every tume , and thus slight differences in the quality of the partitions. The <code>nstart</code> argument in the <code>kmeans()</code> function allows to run the algorithm several times with different initial centers, in order to obtain a potentially better partition:</p>
<pre class="r"><code>model2 &lt;- kmeans(Eurojobs, centers = 2, nstart = 10)
100 * model2$betweenss / model2$totss</code></pre>
<pre><code>## [1] 54.2503</code></pre>
<p>Depending on the initial random choices, this new partition will be better or not compared to the first one.</p>
</div>
<div id="kmeans-with-3-groups" class="section level3">
<h3><code>kmeans()</code> with 3 groups</h3>
<pre class="r"><code>model3 &lt;- kmeans(Eurojobs, centers = 3)
BSS3 &lt;- model3$betweenss
TSS3 &lt;- model3$totss
BSS3 / TSS3 * 100</code></pre>
<pre><code>## [1] 74.59455</code></pre>
<p>It can be seen that the classification into three groups allows for a higher explained percentage and a higher quality. This will always be the case: with more classes, the partition will be finer, and the <em>BSS</em> contribution will be higher. On the other hand, the “model” will be more complex, requiring more classes. In the extreme case where <em>k = n</em> (each observation is a singleton class), we have <em>BSS = TSS</em>, but the partition has lost all interest.</p>
<p>Now that the <em>k</em>-means clustering has been detailed in R, see how to do the algorithm by hand in the following sections.</p>
<div id="manual-application-and-verification-in-r" class="section level4">
<h4>Manual application and verification in R</h4>
<p>Perform <strong>by hand</strong> the <em>k</em>-means algorithm for the points shown in the graph below, with $k = $2 and with the points $i=$5 and $i=$6 as initial centers. Then <strong>check</strong> your answer <strong>in R</strong> and give the quality of the partition.</p>
<p><img src="/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Solution in R :</p>
<pre class="r"><code>X &lt;- matrix(c(7,3,4,5,2,4,0,1,9,7,6,8),
            nrow = 6, byrow = TRUE)
X</code></pre>
<pre><code>##      [,1] [,2]
## [1,]    7    3
## [2,]    4    5
## [3,]    2    4
## [4,]    0    1
## [5,]    9    7
## [6,]    6    8</code></pre>
<pre class="r"><code># take rows 5 and 6 of the X matrix as initial centres
res.k &lt;- kmeans(X, centers = X [c(5,6), ], algorithm = &quot;Lloyd&quot;)</code></pre>
<p>The reason for adding the argument <code>algorithm = &quot;Lloyd&quot;</code> can be found in the usage of the R function <code>kmeans()</code>. In fact, there are several variants of the <em>k</em>-means algorithm. The default choice is the Hartigan &amp; Wong (1979) version, which is more sophisticated than the basic version detailed in the solution by hand. By using the original version of Lloyd (1957), we find the same solution in R and by hand. For more information, you can consult the documentation of the <code>kmeans()</code> function (via <code>?kmeans</code>) and read the articles mentioned.</p>
<pre class="r"><code># We extract the coordinates of the 2 final centres
res.k$centers</code></pre>
<pre><code>##       [,1]     [,2]
## 1 7.333333 6.000000
## 2 2.000000 3.333333</code></pre>
<pre class="r"><code># quality of the partition
100 * res.k$betweenss / res.k$totss</code></pre>
<pre><code>## [1] 60.15038</code></pre>
<p>Thanks for reading. I hope this article helped you understand the different clustering methods and to compute them by hand and in R.</p>
<p>As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by <a href="https://github.com/AntoineSoetewey/statsandr/issues" target="_blank" rel="noopener">raising an issue on GitHub</a>. For all other requests, you can contact me <a href="/contact/">here</a>.</p>
<p>Get updates every time a new article is published by <a href="/subscribe/">subscribing to this blog</a>.</p>
<p><strong>Related articles:</strong></p>
<script src="//rss.bloople.net/?url=https%3A%2F%2Fwww.statsandr.com%2Ftags%2Fr%2Findex.xml&detail=-1&limit=5&showtitle=false&type=js"></script>
</div>
</div>
</div>
</div>



                    </div>

                    
                        <div class="navigation">
                            <div class="row">
                                <div class="col-12 col-md-6">
                                    
                                        <div class="mx-0 mx-md-4 mt-4 text-left">
                                            <a href="/blog/inferential-statistics-confidence-intervals-and-hypothesis-tests-explained-in-4-easy-steps/">« Inferential statistics: confidence intervals and hypothesis tests explained in 4 easy steps</a>
                                        </div>
                                    
                                </div>
                                <div class="col-12 col-md-6">
                                    
                                </div>
                            </div>
                        </div>
                    
                </div>
            </div>
        </div>
    </div>

    <section id="comments">

      <div class="py-3 content">
            <div class="container">
                  <div class="row justify-content-center">
                        <div class="col-sm-12 col-md-10">
                              <div class="comments">
                                    <div id="disqus_thread"></div>
                              </div>
                        </div>
                  </div>
            </div>
      </div>

      <script type="text/javascript">
            (function () {
                  
                  
                  if (window.location.hostname == "localhost")
                        return;

                  var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                  var disqus_shortname = 'statsandr';
                  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
      </script>
      <noscript>
            Please enable JavaScript to view the
            <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
      </noscript>
</section>
    <div class="my-4 footer">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-sm-12 col-md-5">
                
                    <div class="mx-0 mx-md-4 text-left">
                        
                            <p>
                              <a href="/subscribe/">Subscribe</a>
                              <a href="/support/">Support</a>
                              <a href="/sitemap/">Sitemap</a>
                              <a href="/terms/">Terms</a>
                              
                              




  



<a href='https://github.com/AntoineSoetewey/statsandr/edit/master/content/blog/clustering-analysis-k-means-and-hierarchical-clustering-by-hand-and-in-r.Rmd' target="_blank">Edit this page</a>



                              
                            </p>
                            <p>
                              <a href="/">&copy; <script>document.write(new Date().getFullYear())</script> Antoine Soetewey.</a>
                            </p>
                        
                    </div>
                
            </div>
            <div class="col-sm-12 col-md-5">
                <div class="mx-0 mx-md-4 text-right">
                    
                        <a href="https://github.com/AntoineSoetewey" target="_blank">
                            <img class="icon" src="/img/github.svg" alt="GitHub" />
                        </a>
                    

                    

                    

                    

                    
                    <a href="https://www.linkedin.com/in/antoinesoetewey" target="_blank">
                        <img class="icon" src="/img/linkedin.svg" alt="LinkedIn" />
                    </a>
                    

                    

                    

                    

                    
                    
                    
                    <a href="/contact/">
                        <img class="icon" src="/img/email.svg" alt="Contact" />
                    </a>
                    

                    
                        <a href="/index.xml" class="mr-0">
                            <img class="icon" src="/img/rss.svg" alt="RSS" />
                        </a>
                    

                    
                </div>
            </div>
        </div>
    </div>
</div>



    

    
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.14.2/highlight.min.js" integrity="sha256-sNPiigbfSkqUzMc5rgrdztLnneCMAp6W9wetJUZu9Zw=" crossorigin="anonymous"></script>
        
        <script>
            window.addEventListener('load', function() {
                hljs.initHighlighting();
            }, true);
        </script>
    

    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-86997981-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
        
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
</body>

</html>
