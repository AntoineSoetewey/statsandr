<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inferential statistics on Stats and R</title>
    <link>/tags/inferential-statistics/</link>
    <description>Recent content in Inferential statistics on Stats and R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 13 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/inferential-statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>One-proportion and goodness of fit test (in R and by hand)</title>
      <link>/blog/one-proportion-and-goodness-of-fit-test-in-r-and-by-hand/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/one-proportion-and-goodness-of-fit-test-in-r-and-by-hand/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#in-r&#34;&gt;In R&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#one-proportion-test&#34;&gt;One-proportion test&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#assumption-of-prop.test-and-binom.test&#34;&gt;Assumption of &lt;code&gt;prop.test()&lt;/code&gt; and &lt;code&gt;binom.test()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#chi-square-goodness-of-fit-test&#34;&gt;Chi-square goodness of fit test&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#does-my-distribution-follow-a-given-distribution&#34;&gt;Does my distribution follow a given distribution?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#observed-frequencies&#34;&gt;Observed frequencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#expected-frequencies&#34;&gt;Expected frequencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#observed-vs.expected-frequencies&#34;&gt;Observed vs. expected frequencies&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#by-hand&#34;&gt;By hand&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#one-proportion-test-1&#34;&gt;One-proportion test&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#verification-in-r&#34;&gt;Verification in R&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#goodness-of-fit-test&#34;&gt;Goodness of fit test&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#verification-in-r-1&#34;&gt;Verification in R&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/One-proportion%20and%20goodness%20of%20fit%20test%20in%20R%20and%20by%20hand.jpeg&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In a previous article, I presented the &lt;a href=&#34;/blog/chi-square-test-of-independence-in-r/&#34;&gt;Chi-square test of independence in R&lt;/a&gt; which is used to test the independence between two &lt;a href=&#34;/blog/variable-types-and-examples/#qualitative&#34;&gt;categorical&lt;/a&gt; variables. In this article, I show how to perform, first in R and then by hand, the:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;one-proportion test (also referred as one-sample proportion test)&lt;/li&gt;
&lt;li&gt;Chi-square goodness of fit test&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The first test is used to compare an observed proportion to an expected proportion, when the qualitative variable has only &lt;strong&gt;two categories&lt;/strong&gt;. The second test is used to compare multiple observed proportions to multiple expected proportions, in a situation where the qualitative variable has &lt;strong&gt;two or more categories&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Both tests allow to test the equality of proportions between the levels of the qualitative variable or to test the equality with given proportions. These given proportions could be determined arbitrarily or based on the theoretical probabilities of a known distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;in-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;In R&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;For this section, we use the same dataset than in the article on &lt;a href=&#34;/blog/descriptive-statistics-in-r/&#34;&gt;descriptive statistics&lt;/a&gt;. It is the well-known &lt;code&gt;iris&lt;/code&gt; dataset, to which we add the variable &lt;code&gt;size&lt;/code&gt;. The variable &lt;code&gt;size&lt;/code&gt; corresponds to &lt;code&gt;small&lt;/code&gt; if the length of the petal is smaller than the median of all flowers, &lt;code&gt;big&lt;/code&gt; otherwise:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load iris dataset
dat &amp;lt;- iris

# create size variable
dat$size &amp;lt;- ifelse(dat$Sepal.Length &amp;lt; median(dat$Sepal.Length),
  &amp;quot;small&amp;quot;, &amp;quot;big&amp;quot;
)

# show first 5 observations
head(dat, n = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species  size
## 1          5.1         3.5          1.4         0.2  setosa small
## 2          4.9         3.0          1.4         0.2  setosa small
## 3          4.7         3.2          1.3         0.2  setosa small
## 4          4.6         3.1          1.5         0.2  setosa small
## 5          5.0         3.6          1.4         0.2  setosa small&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;one-proportion-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;One-proportion test&lt;/h2&gt;
&lt;p&gt;For this example, we have a sample of 150 flowers and we want to test whether the proportion of small flowers is the same than the proportion of big flowers (measured by the variable &lt;code&gt;size&lt;/code&gt;). Here are the number of flowers by size, and the corresponding proportions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# barplot
library(ggplot2)
ggplot(dat) +
  aes(x = size) +
  geom_bar(fill = &amp;quot;#0c4c8a&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# counts by size
table(dat$size)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   big small 
##    77    73&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# proportions by size, rounded to 2 decimals
round(prop.table(table(dat$size)), 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   big small 
##  0.51  0.49&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Among the 150 flowers forming our sample, 51% and 49% are big and small, respectively. To test whether the proportions are the same among both sizes, we use the &lt;code&gt;prop.test()&lt;/code&gt; function which accepts the following arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of successes&lt;/li&gt;
&lt;li&gt;number of observations/trials&lt;/li&gt;
&lt;li&gt;expected probability (the one we want to test against)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Considering (arbitrarily) that &lt;code&gt;big&lt;/code&gt; is the success, we have:&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# one-proportion test
test &amp;lt;- prop.test(
  x = 77, # number of successes
  n = 150, # total number of trials (77 + 73)
  p = 0.5
) # we test for equal proportion so prob = 0.5 in each group

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  1-sample proportions test with continuity correction
## 
## data:  77 out of 150, null probability 0.5
## X-squared = 0.06, df = 1, p-value = 0.8065
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.4307558 0.5952176
## sample estimates:
##         p 
## 0.5133333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We obtain an output with, among others, the null probability (&lt;code&gt;0.5&lt;/code&gt;), the test statistic (&lt;code&gt;X-squared = 0.06&lt;/code&gt;), the degrees of freedom (&lt;code&gt;df = 1&lt;/code&gt;), the &lt;em&gt;p&lt;/em&gt;-value (&lt;code&gt;p-value = 0.8065&lt;/code&gt;) and the alternative hypothesis (&lt;code&gt;true p is not equal to 0.5&lt;/code&gt;). The &lt;em&gt;p&lt;/em&gt;-value is 0.806 so, at the 5% significance level, we do not reject the null hypothesis that the proportions of small and big flowers are the same.&lt;/p&gt;
&lt;div id=&#34;assumption-of-prop.test-and-binom.test&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Assumption of &lt;code&gt;prop.test()&lt;/code&gt; and &lt;code&gt;binom.test()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Note that &lt;code&gt;prop.test()&lt;/code&gt; uses a normal approximation to the binomial distribution. Therefore, one assumption of this test is that the sample size is large enough (usually, &lt;em&gt;n &amp;gt; 30&lt;/em&gt;). If the sample size is small, it is recommended to use the exact binomial test.&lt;/p&gt;
&lt;p&gt;The exact binomial test can be performed with the &lt;code&gt;binom.test()&lt;/code&gt; function and accepts the same arguments as the &lt;code&gt;prop.test()&lt;/code&gt; function. For this example, suppose now that we have a sample of 12 big and 3 small flowers and we want to test whether the proportions are the same among both sizes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# barplot
barplot(c(12, 3), # observed counts
  names.arg = c(&amp;quot;big&amp;quot;, &amp;quot;small&amp;quot;), # rename labels
  ylab = &amp;quot;Frequency&amp;quot;, # y-axis label
  xlab = &amp;quot;Size&amp;quot; # x-axis label
)
abline(
  h = 15 / 2, # expected counts in each level
  lty = 2 # dashed line
) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# exact binomial test
test &amp;lt;- binom.test(
  x = 12, # counts of successes
  n = 15, # total counts (12 + 3)
  p = 0.5 # expected proportion
)

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Exact binomial test
## 
## data:  12 and 15
## number of successes = 12, number of trials = 15, p-value = 0.03516
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.5191089 0.9566880
## sample estimates:
## probability of success 
##                    0.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.035 so, at the 5% significance level, we reject the null hypothesis and we conclude that the proportions of small and big flowers are significantly different. This is equivalent than concluding that the proportion of big flowers is significantly different from 0.5 (since there are only two sizes).&lt;/p&gt;
&lt;p&gt;If you want to test that the proportion of big flowers is greater than 50%, add the &lt;code&gt;alternative = &amp;quot;greater&amp;quot;&lt;/code&gt; argument into the &lt;code&gt;binom.test()&lt;/code&gt; function:&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- binom.test(
  x = 12, # counts of successes
  n = 15, # total counts (12 + 3)
  p = 0.5, # expected proportion
  alternative = &amp;quot;greater&amp;quot; # test that prop of big flowers is &amp;gt; 0.5
)

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Exact binomial test
## 
## data:  12 and 15
## number of successes = 12, number of trials = 15, p-value = 0.01758
## alternative hypothesis: true probability of success is greater than 0.5
## 95 percent confidence interval:
##  0.5602156 1.0000000
## sample estimates:
## probability of success 
##                    0.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.018 so, at the 5% significance level, we reject the null hypothesis and we conclude that the proportion of big flowers is significantly larger than 50%.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;chi-square-goodness-of-fit-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Chi-square goodness of fit test&lt;/h2&gt;
&lt;p&gt;Suppose now that the qualitative variable has more than two levels as it is the case for the variable &lt;code&gt;Species&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# barplot
ggplot(dat) +
  aes(x = Species) +
  geom_bar(fill = &amp;quot;#0c4c8a&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# counts by Species
table(dat$Species)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     setosa versicolor  virginica 
##         50         50         50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variable &lt;code&gt;Species&lt;/code&gt; has 3 levels, with 50 observations in each level. Suppose for this example that we want to test whether the 3 species are equally common. If they were equally common, they would be equally distributed and the expected proportions would be &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{3}\)&lt;/span&gt; for each of the species.&lt;/p&gt;
&lt;p&gt;This test can be done with the &lt;code&gt;chisq.test()&lt;/code&gt; function, accepting the following arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a numeric vector representing the observed proportions&lt;/li&gt;
&lt;li&gt;a vector of probabilities (of the same length of the observed proportions) representing the expected proportions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Applied to our research question (i.e., are the 3 species equally common?), we have:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# goodness of fit test
test &amp;lt;- chisq.test(table(dat$Species), # observed proportions
  p = c(1 / 3, 1 / 3, 1 / 3) # expected proportions
)

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Chi-squared test for given probabilities
## 
## data:  table(dat$Species)
## X-squared = 0, df = 2, p-value = 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 1 so, at the 5% significance level, we do not reject the null hypothesis that the proportions are equal among all species.&lt;/p&gt;
&lt;p&gt;This was quite obvious even before doing the statistical test given that there are exactly 50 flowers of each species, so it was easy to see that the species are equally common. We however still did the test to show how it works in practice.&lt;/p&gt;
&lt;div id=&#34;does-my-distribution-follow-a-given-distribution&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Does my distribution follow a given distribution?&lt;/h3&gt;
&lt;p&gt;In the previous section, we chose the proportions ourselves. The goodness of fit test is also particularly useful to compare observed proportions with expected proportions that are based on some known distribution.&lt;/p&gt;
&lt;p&gt;Remember the hypotheses of the test:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: there is no significant difference between the observed and the expected frequencies&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: there is a significant difference between the observed and the expected frequencies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this example, suppose that we measured the number of girls in 100 families of 5 children. We want to test whether the (observed) distribution of number girls follows a binomial distribution.&lt;/p&gt;
&lt;div id=&#34;observed-frequencies&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Observed frequencies&lt;/h4&gt;
&lt;p&gt;Here is the distribution of the number of girls per family in our sample of 100 families of 5 children:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And the corresponding frequencies and relative frequencies (remember that the relative frequency is the frequency divided by the total sample size):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# counts
dat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Girls Frequency Relative_freq
## 1     0         5          0.05
## 2     1        12          0.12
## 3     2        28          0.28
## 4     3        33          0.33
## 5     4        17          0.17
## 6     5         5          0.05&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;expected-frequencies&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Expected frequencies&lt;/h4&gt;
&lt;p&gt;In order to compare the observed frequencies to a binomial distribution and see if both distributions match, we first need to determine the expected frequencies that would be obtained in case of a binomial distribution. The expected frequencies assuming a probability of 0.5 of having a girl (for each of the 5 children) are as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create expected frequencies for a binomial distribution
x &amp;lt;- 0:5
df &amp;lt;- data.frame(
  Girls = factor(x),
  Expected_relative_freq = dbinom(x, size = 5, prob = 0.5)
)
df$Expected_freq &amp;lt;- df$Expected_relative_freq * 100 # *100 since there are 100 families

# create barplot
p &amp;lt;- ggplot(df, aes(x = Girls, y = Expected_freq)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, fill = &amp;quot;#F8766D&amp;quot;) +
  xlab(&amp;quot;Number of girls per family&amp;quot;) +
  ylab(&amp;quot;Expected frequency&amp;quot;) +
  labs(title = &amp;quot;Binomial distribution Bi(x, n = 5, p = 0.5)&amp;quot;) +
  theme_minimal()
p&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# expected relative frequencies and (absolute) frequencies
df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Girls Expected_relative_freq Expected_freq
## 1     0                0.03125         3.125
## 2     1                0.15625        15.625
## 3     2                0.31250        31.250
## 4     3                0.31250        31.250
## 5     4                0.15625        15.625
## 6     5                0.03125         3.125&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;observed-vs.expected-frequencies&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Observed vs. expected frequencies&lt;/h4&gt;
&lt;p&gt;We now compare the observed frequencies to the expected frequencies to see whether the two differ significantly. If the two differ significantly, we reject the hypothesis that the number of girls per family of 5 children follows a binomial distribution. On the other hand, if the observed and expected frequencies are similar, we do not reject the hypothesis that the number of girls per family follows a binomial distribution.&lt;/p&gt;
&lt;p&gt;Visually we have:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create data
data &amp;lt;- data.frame(
  num_girls = factor(rep(c(0:5), times = 2)),
  Freq = c(dat$Freq, df$Expected_freq),
  obs_exp = c(rep(&amp;quot;observed&amp;quot;, 6), rep(&amp;quot;expected&amp;quot;, 6))
)

# create plot
ggplot() +
  geom_bar(
    data = data, aes(
      x = num_girls, y = Freq,
      fill = obs_exp
    ),
    position = &amp;quot;dodge&amp;quot;, # bar next to each other
    stat = &amp;quot;identity&amp;quot;
  ) +
  ylab(&amp;quot;Frequency&amp;quot;) +
  xlab(&amp;quot;Number of girls per family&amp;quot;) +
  theme_minimal() +
  theme(legend.title = element_blank()) # remove legend title&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the observed and expected frequencies are quite similar, so we expect that the number of girls in families of 5 children follows a binomial distribution. However, only the goodness of fit test will confirm our belief:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# goodness of fit test
test &amp;lt;- chisq.test(dat$Freq, # observed frequencies
  p = df$Expected_relative_freq # expected proportions
)

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Chi-squared test for given probabilities
## 
## data:  dat$Freq
## X-squared = 3.648, df = 5, p-value = 0.6011&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.601 so, at the 5% significance level, we do not reject the null hypothesis that the observed and expected frequencies are equal. This is equivalent than concluding that we cannot reject the hypothesis that the number of girls in families of 5 children follows a binomial distribution (since the expected frequencies were based on a binomial distribution).&lt;/p&gt;
&lt;p&gt;Note that the goodness of fit test can of course be performed with other types of distribution than the binomial one. For instance, if you want to test whether an observed distribution follows a Poisson distribution, this test can be used to compare the observed frequencies with the expected proportions that would be obtained in case of a Poisson distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;by-hand&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;By hand&lt;/h1&gt;
&lt;p&gt;Now that we showed how to perform the one-proportion and goodness of fit test in R, in this section we show how to do these tests by hand. We first illustrate the one-proportion test then the Chi-square goodness of fit test.&lt;/p&gt;
&lt;div id=&#34;one-proportion-test-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;One-proportion test&lt;/h2&gt;
&lt;p&gt;For this example, suppose that we tossed a coin 100 times and noted that it landed on heads 67 times. Following this, we want to test whether the coin is fair, that is, test whether the probability of landing on heads or tails is equal to 50%.&lt;/p&gt;
&lt;p&gt;As for many hypothesis tests, we do it through 4 easy steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;State the null and alternative hypotheses&lt;/li&gt;
&lt;li&gt;Compute the test-statistic (also known as t-stat)&lt;/li&gt;
&lt;li&gt;Find the rejection region&lt;/li&gt;
&lt;li&gt;Conclude by comparing the test-statistic with the rejection region&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In our example, the null and alternative hypotheses are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(p_0 = 0.5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(p_0 \ne 0.5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(p_0\)&lt;/span&gt; is the expected proportion of landing on heads.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The test statistic is:&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[z_{obs} = \frac{\hat{p} - p_0}{\sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}} = \frac{0.67 - 0.5}{\sqrt{\frac{0.67 \cdot (1 - 0.67)}{100}}} = 3.615\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;(See how to perform &lt;a href=&#34;/blog/a-shiny-app-for-inferential-statistics-by-hand/&#34;&gt;hypothesis tests in a Shiny app&lt;/a&gt; if you need more help in computing the test statistic.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The rejection region is found via the normal distribution table. Assuming a significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;, we have:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/Screenshot%202020-05-13%20at%2012.23.38.png&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\pm z_{\alpha/2} = \pm z_{0.025} = \pm 1.96\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We compare the test statistic (found in step 2) with the rejection region (found in step 3) and we conclude. Visually, we have:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The test statistic lies within the rejection region (i.e., the grey shaded areas). Therefore, at the 5% significance level, we reject the null hypothesis and we conclude that the proportion of heads (and thus tails) is significantly different than 50%. In other words, still at the 5% significance level, we conclude that the coin is unfair.&lt;/p&gt;
&lt;p&gt;If you prefer to compute the &lt;em&gt;p&lt;/em&gt;-value instead of comparing the t-stat and the rejection region, you can use this &lt;a href=&#34;/blog/a-guide-on-how-to-read-statistical-tables/&#34;&gt;Shiny app to easily compute &lt;em&gt;p&lt;/em&gt;-values&lt;/a&gt; for different probability distributions. After having opened the app, set the t-stat, the corresponding alternative and you will find the &lt;em&gt;p&lt;/em&gt;-value at the top of the page.&lt;/p&gt;
&lt;div id=&#34;verification-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Verification in R&lt;/h3&gt;
&lt;p&gt;Just for the sake of illustration, here is the verification of the above example in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# one-proportion test
test &amp;lt;- prop.test(
  x = 67, # number of heads
  n = 100, # number of trials
  p = 0.5 # expected probability of heads
)

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  1-sample proportions test with continuity correction
## 
## data:  67 out of 100, null probability 0.5
## X-squared = 10.89, df = 1, p-value = 0.0009668
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.5679099 0.7588442
## sample estimates:
##    p 
## 0.67&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.001 so, at the 5% significance level, we reject the null hypothesis that the proportions of heads and tails are equal, and we conclude that the coin is biased. This is the same conclusion than the one found by hand.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;goodness-of-fit-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goodness of fit test&lt;/h2&gt;
&lt;p&gt;We now illustrate the goodness of fit test by hand with the following example.&lt;/p&gt;
&lt;p&gt;Suppose that we toss a dice 100 times, we note how many times it lands on each face (1 to 6) and we test whether the dice is fair. Here are the observed counts by dice face:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## dice_face
##  1  2  3  4  5  6 
## 15 24 10 19 19 13&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a fair dice, we would expect it to land &lt;span class=&#34;math inline&#34;&gt;\(\frac{100}{6} \approx 16.67\)&lt;/span&gt; times on each face (this expected value is represented by the dashed line in the above plot). Although the observed frequencies are different than the expected value of 16.67:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##   dice_face observed_freq expected_freq
## 1         1            15         16.67
## 2         2            24         16.67
## 3         3            10         16.67
## 4         4            19         16.67
## 5         5            19         16.67
## 6         6            13         16.67&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we need to test whether they are &lt;em&gt;significantly&lt;/em&gt; different. For this, we perform the appropriate hypothesis test following the 4 easy steps mentioned above:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;State the null and alternative hypotheses&lt;/li&gt;
&lt;li&gt;Compute the test-statistic (also known as t-stat)&lt;/li&gt;
&lt;li&gt;Find the rejection region&lt;/li&gt;
&lt;li&gt;Conclude by comparing the test-statistic with the rejection region&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The null and alternative hypotheses of the goodness of fit test are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: there is no significant difference between the observed and the expected frequencies&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: there is a significant difference between the observed and the expected frequencies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The test statistic is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\chi^2 = \sum_{i = 1}^k \frac{(O_i - E_i)^2}{E_i}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(O_i\)&lt;/span&gt; is the observed frequency, &lt;span class=&#34;math inline&#34;&gt;\(E_i\)&lt;/span&gt; is the expected frequency and &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the number of categories (in our case, there are 6 categories, representing the 6 dice faces).&lt;/p&gt;
&lt;p&gt;This &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; statistic is obtained by calculating the difference between the observed number of cases and the expected number of cases in each category. This difference is squared (to avoid negative and positive differences being compensated) and divided by the expected number of cases in that category. These values are then summed for all categories, and the total is referred to as the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; statistic. Large values of this test statistic lead to the rejection of the null hypothesis, small values mean that the null hypothesis cannot be rejected.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Given our data, we have:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\chi^2 = \frac{(15 - 16.67)^2}{16.67} + \frac{(24 - 16.67)^2}{16.67} + \frac{(10 - 16.67)^2}{16.67} + \\
\frac{(19 - 16.67)^2}{16.67} + \frac{(19 - 16.67)^2}{16.67} + \frac{(13 - 16.67)^2}{16.67}  =  7.52\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Whether the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; test statistic is small or large depends on the rejection region. The rejection region is found via the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; distribution table. With a degrees of freedom equals to &lt;span class=&#34;math inline&#34;&gt;\(k - 1\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the number of categories) and assuming a significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;, we have:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/Screenshot%202020-05-13%20at%2012.20.42.png&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\chi^2_{\alpha; k-1} = \chi^2_{0.05; 5} = 11.0705\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We compare the test statistic (found in step 2) with the rejection region (found in step 3) and we conclude. Visually, we have:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-05-13-one-proportion-and-goodness-of-fit-test-in-r-and-by-hand_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The test statistic does not lie within the rejection region (i.e., the grey shaded area). Therefore, at the 5% significance level, we do not reject the null hypothesis that there is no significant difference between the observed and the expected frequencies. In other words, still at the 5% significance level, we cannot reject the hypothesis that the dice is fair.&lt;/p&gt;
&lt;p&gt;Again, you can use the &lt;a href=&#34;/blog/a-guide-on-how-to-read-statistical-tables/&#34;&gt;Shiny app&lt;/a&gt; to easily compute the &lt;em&gt;p&lt;/em&gt;-value given the test statistic if you prefer this method over the comparison between the t-stat and the rejection region.&lt;/p&gt;
&lt;div id=&#34;verification-in-r-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Verification in R&lt;/h3&gt;
&lt;p&gt;Just for the sake of illustration, here is the verification of the above example in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# goodness of fit test
test &amp;lt;- chisq.test(dat$observed_freq, # observed frequencies for each dice face
  p = rep(1 / 6, 6) # expected probabilities for each dice face
)

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Chi-squared test for given probabilities
## 
## data:  dat$observed_freq
## X-squared = 7.52, df = 5, p-value = 0.1847&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The test statistic and degrees of freedom are exactly the same than the ones found by hand. The &lt;em&gt;p&lt;/em&gt;-value is 0.185 which, still at the 5% significance level, leads to the same conclusion than by hand (i.e., failing to reject the null hypothesis).&lt;/p&gt;
&lt;p&gt;Thanks for reading. I hope this article helped you to understand and perform the one-proportion and goodness of fit test in R and by hand.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Choosing big or small as the success event gives the exact same conclusion.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Similarly, this argument can also be added to the &lt;code&gt;prop.test()&lt;/code&gt; function to test whether the observed proportion is larger than the expected proportion. Use &lt;code&gt;alternative = &amp;quot;less&amp;quot;&lt;/code&gt; if you want to test whether the observed proportion is smaller than the expected one.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;One assumption of this test is that &lt;span class=&#34;math inline&#34;&gt;\(n \cdot p \ge 5\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n \cdot (1 - p) \ge 5\)&lt;/span&gt;. The assumption is met so we can use the normal approximation to the binomial distribution.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;Source: &lt;a href=&#34;http://uregina.ca/~gingrich/ch10.pdf&#34; target=&#34;_blank&#34;&gt;http://uregina.ca/~gingrich/ch10.pdf&lt;/a&gt;.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to do a t-test or ANOVA for more than one variable at once in R and communicate the results in a better way</title>
      <link>/blog/how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way/</link>
      <pubDate>Thu, 19 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#perform-multiple-tests-at-once&#34;&gt;Perform multiple tests at once&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#concise-and-easily-interpretable-results&#34;&gt;Concise and easily interpretable results&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#t-test&#34;&gt;T-test&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#additional-p-value-adjustment-methods&#34;&gt;Additional &lt;em&gt;p&lt;/em&gt;-value adjustment methods&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#anova&#34;&gt;ANOVA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#to-go-even-further&#34;&gt;To go even further&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/How%20to%20do%20a%20t-test%20or%20ANOVA%20for%20many%20variables%20at%20once%20in%20R%20and%20communicate%20the%20results%20in%20a%20better%20way.jpeg&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;As part of my teaching assistant position in a Belgian university, students often ask me for some help in their statistical analyses for their master’s thesis.&lt;/p&gt;
&lt;p&gt;A frequent question is how to compare groups of patients in terms of several &lt;a href=&#34;/blog/variable-types-and-examples/#continuous&#34;&gt;quantitative continuous&lt;/a&gt; variables. Most of us know that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To compare two groups, a &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/&#34;&gt;Student’s t-test&lt;/a&gt; should be used&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;To compare three groups or more, an ANOVA should be performed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These two tests are quite basic and have been extensively documented online and in statistical textbooks so the difficulty is not in how to perform these tests.&lt;/p&gt;
&lt;p&gt;In the past, I used to do the analyses by following these 3 steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Draw boxplots illustrating the distributions by group (with the &lt;code&gt;boxplot()&lt;/code&gt; function or thanks to the &lt;a href=&#34;/blog/rstudio-addins-or-how-to-make-your-coding-life-easier/#esquisse&#34;&gt;&lt;code&gt;{esquisse}&lt;/code&gt; R Studio addin&lt;/a&gt; if I wanted to use the &lt;code&gt;{ggplot2}&lt;/code&gt; package)&lt;/li&gt;
&lt;li&gt;Perform a t-test or an ANOVA depending on the number of groups to compare (with the &lt;code&gt;t.test()&lt;/code&gt; and &lt;code&gt;oneway.test()&lt;/code&gt; functions for t-test and ANOVA, respectively)&lt;/li&gt;
&lt;li&gt;Repeat steps 1 and 2 for each variable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This was feasible as long as there were only a couple of variables to test. Nonetheless, most students came to me asking to perform these kind of tests not on one or two variables, but on &lt;strong&gt;multiples&lt;/strong&gt; variables. So when there were more than one variable to test, I quickly realized that I was wasting my time and that there must be a more efficient way to do the job.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Note&lt;/strong&gt;: you must be very careful with the issue of multiple testing (also referred as multiplicity) which can arise when you perform multiple t-tests. In short, when a large number of statistical tests are performed, some will have p-values less than 0.05 purely by chance, even if all null hypotheses are in fact really true. This is known as multiplicity or multiple testing. You can tackle this problem by using the Bonferroni correction, among others. The Bonferroni correction is a simple method that allows many t-tests to be made while still assuring an overall confidence level is maintained. For this, instead of using the standard threshold of &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 5\)&lt;/span&gt;% for the significance level, you can use &lt;span class=&#34;math inline&#34;&gt;\(\alpha = \frac{0.05}{m}\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; is the number of t-tests. For example, if you perform 20 t-tests with a desired &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;, the Bonferroni correction implies that you would reject the null hypothesis for each individual test when the p-value is smaller than &lt;span class=&#34;math inline&#34;&gt;\(\alpha = \frac{0.05}{20} = 0.0025\)&lt;/span&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Note also that there is no universally accepted approach for dealing with the problem of multiple comparisons. Usually, you should choose a &lt;em&gt;p&lt;/em&gt;-value adjustment measure familiar to your audience or in your field of study. The Bonferroni correction is the most common way to take this into account and is easy to implement. It is however not appropriate if you have a very large number of tests to perform (imagine you want to do 10,000 t-tests, a &lt;em&gt;p&lt;/em&gt;-value would have to be less than &lt;span class=&#34;math inline&#34;&gt;\(\frac{0.05}{10000} = 0.000005\)&lt;/span&gt; to be significant). A more powerful method is also to adjust the false discovery rate using the Benjamini-Hochberg procedure (McDonald, 2014). This article aims at presenting a way to perform multiple t-tests and ANOVA from a technical point of view (how to implement it in R). Discussion on which adjustment method to use or whether there is a more appropriate model to fit the data is beyond the scope of this article (so be sure to understand the implications if using the code for your own analyses).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;perform-multiple-tests-at-once&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Perform multiple tests at once&lt;/h1&gt;
&lt;p&gt;I thus wrote a piece of code that automated the process, by drawing boxplots and performing the tests on several variables at once. Below is the code I used, illustrating the process with the &lt;code&gt;iris&lt;/code&gt; dataset. The &lt;code&gt;Species&lt;/code&gt; variable has 3 levels, so let’s remove one, and then draw a boxplot and apply a t-test on all 4 continuous variables at once. Note that the continuous variables that we would like to test are variables 1 to 4 in the &lt;code&gt;iris&lt;/code&gt; dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- iris

# remove one level to have only two groups
dat &amp;lt;- subset(dat, Species != &amp;quot;setosa&amp;quot;)
dat$Species &amp;lt;- factor(dat$Species)

# boxplots and t-tests for the 4 variables at once
for (i in 1:4) { # variables to compare are variables 1 to 4
  boxplot(dat[, i] ~ dat$Species, # draw boxplots by group
    ylab = names(dat[i]), # rename y-axis with variable&amp;#39;s name
    xlab = &amp;quot;Species&amp;quot;
  )
  print(t.test(dat[, i] ~ dat$Species)) # print results of t-test
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  dat[, i] by dat$Species
## t = -5.6292, df = 94.025, p-value = 1.866e-07
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.8819731 -0.4220269
## sample estimates:
## mean in group versicolor  mean in group virginica 
##                    5.936                    6.588&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-1-2.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  dat[, i] by dat$Species
## t = -3.2058, df = 97.927, p-value = 0.001819
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.33028364 -0.07771636
## sample estimates:
## mean in group versicolor  mean in group virginica 
##                    2.770                    2.974&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-1-3.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  dat[, i] by dat$Species
## t = -12.604, df = 95.57, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.49549 -1.08851
## sample estimates:
## mean in group versicolor  mean in group virginica 
##                    4.260                    5.552&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-1-4.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  dat[, i] by dat$Species
## t = -14.625, df = 89.043, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.7951002 -0.6048998
## sample estimates:
## mean in group versicolor  mean in group virginica 
##                    1.326                    2.026&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, the above piece of code draws a boxplot and then prints results of the test for each continuous variable, all at once.&lt;/p&gt;
&lt;p&gt;At some point in the past, I even wrote code to:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;draw a boxplot&lt;/li&gt;
&lt;li&gt;test for the equality of variances (thanks to the Levene’s test)&lt;/li&gt;
&lt;li&gt;depending on whether the variances were equal or unequal, the appropriate test was applied: the Welch test if the variances were unequal and the Student’s t-test in the case the variances were equal (see more details about the different versions of the &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/&#34;&gt;t-test for two samples&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;apply steps 1 to 3 for all continuous variables at once&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I had a similar code for ANOVA in case I needed to compare more than two groups.&lt;/p&gt;
&lt;p&gt;The code was doing the job relatively well. Indeed, thanks to this code I was able to test several variables in an automated way in the sense that it compared groups for all variables at once.&lt;/p&gt;
&lt;p&gt;The only thing I had to change from one project to another is that I needed to modify the name of the grouping variable and the numbering of the continuous variables to test (&lt;code&gt;Species&lt;/code&gt; and &lt;code&gt;1:4&lt;/code&gt; in the above code).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;concise-and-easily-interpretable-results&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Concise and easily interpretable results&lt;/h1&gt;
&lt;div id=&#34;t-test&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;T-test&lt;/h2&gt;
&lt;p&gt;Although it was working quite well and applicable to different projects with only minor changes, I was still unsatisfied with another point.&lt;/p&gt;
&lt;p&gt;Someone who is proficient in statistics and R can read and interpret the output of a t-test without any difficulty. However, as you may have noticed with your own statistical projects, most people do not know what to look for in the results and are sometimes a bit confused when they see so many graphs, code, output, results and numeric values in a document. They are quite easily overwhelmed by this mass of information.&lt;/p&gt;
&lt;p&gt;With my old R routine, the time I was saving by automating the process of t-tests and ANOVA was (partially) lost when I had to explain R outputs to my students so that they could interpret the results correctly. Although most of the time it simply boiled down to pointing out what to look for in the outputs (i.e., &lt;em&gt;p&lt;/em&gt;-values), I was still losing quite a lot of time because these outputs were, in my opinion, too detailed for most real-life applications. In other words, too much information seemed to be confusing for many people so I was still not convinced that it was the most optimal way to share statistical results to nonscientists.&lt;/p&gt;
&lt;p&gt;Of course, they came to me for statistical advices, so they expected to have these results and I needed to give them answers to their questions and hypotheses. Nonetheless, I wanted to find a better way to communicate these results to this type of audience, with the minimum of information required to arrive at a conclusion. No more and no less than that.&lt;/p&gt;
&lt;p&gt;After a long time spent online trying to figure out a way to present results in a more concise and readable way, I discovered the &lt;a href=&#34;https://cran.r-project.org/web/packages/ggpubr/index.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;{ggpubr}&lt;/code&gt; package&lt;/a&gt;. This package allows to indicate the test used and the &lt;em&gt;p&lt;/em&gt;-value of the test directly on a ggplot2-based graph. It also facilitates the creation of publication-ready plots for non-advanced statistical audiences.&lt;/p&gt;
&lt;p&gt;After many refinements and modifications of the initial code (available in this &lt;a href=&#34;http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/&#34; target=&#34;_blank&#34;&gt;article&lt;/a&gt;), I finally came up with a rather stable and robust process to perform t-tests and ANOVA for more than one variable at once, and more importantly, make the results concise and easily readable by anyone (statisticians or not).&lt;/p&gt;
&lt;p&gt;A graph is worth a thousand words, so here are the exact same tests than in the previous section, but this time with my new R routine:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggpubr)

# Edit from here #
x &amp;lt;- which(names(dat) == &amp;quot;Species&amp;quot;) # name of grouping variable
y &amp;lt;- which(names(dat) == &amp;quot;Sepal.Length&amp;quot; # names of variables to test
| names(dat) == &amp;quot;Sepal.Width&amp;quot;
| names(dat) == &amp;quot;Petal.Length&amp;quot;
| names(dat) == &amp;quot;Petal.Width&amp;quot;)
method &amp;lt;- &amp;quot;t.test&amp;quot; # one of &amp;quot;wilcox.test&amp;quot; or &amp;quot;t.test&amp;quot;
paired &amp;lt;- FALSE # if paired make sure that in the dataframe you have first all individuals at T1, then all individuals again at T2
# Edit until here


# Edit at your own risk
for (i in y) {
  for (j in x) {
    ifelse(paired == TRUE,
      p &amp;lt;- ggpaired(dat,
        x = colnames(dat[j]), y = colnames(dat[i]),
        color = colnames(dat[j]), line.color = &amp;quot;gray&amp;quot;, line.size = 0.4,
        palette = &amp;quot;npg&amp;quot;,
        legend = &amp;quot;none&amp;quot;,
        xlab = colnames(dat[j]),
        ylab = colnames(dat[i]),
        add = &amp;quot;jitter&amp;quot;
      ),
      p &amp;lt;- ggboxplot(dat,
        x = colnames(dat[j]), y = colnames(dat[i]),
        color = colnames(dat[j]),
        palette = &amp;quot;npg&amp;quot;,
        legend = &amp;quot;none&amp;quot;,
        add = &amp;quot;jitter&amp;quot;
      )
    )
    #  Add p-value
    print(p + stat_compare_means(aes(label = paste0(..method.., &amp;quot;, p-value = &amp;quot;, ..p.format..)),
      method = method,
      paired = paired,
      # group.by = NULL,
      ref.group = NULL
    ))
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-2-3.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-2-4.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see from the graphs above, only the most important information is presented for each variable:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a visual comparison of the groups thanks to boxplots&lt;/li&gt;
&lt;li&gt;the name of the statistical test&lt;/li&gt;
&lt;li&gt;the &lt;em&gt;p&lt;/em&gt;-value of the test&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course, experts may be interested in more advanced results. However, this simple yet complete graph, which includes the name of the test and the &lt;em&gt;p&lt;/em&gt;-value, gives all the necessary information to answer the question: “Are the groups different?”.&lt;/p&gt;
&lt;p&gt;In my experience, I have noticed that students and professionals (especially those from a less scientific background) understand way better these results than the ones presented in the previous section.&lt;/p&gt;
&lt;p&gt;The only lines of code that need to be modified for your own project is the name of the grouping variable (&lt;code&gt;Species&lt;/code&gt; in the above code), the names of the variables you want to test (&lt;code&gt;Sepal.Length&lt;/code&gt;, &lt;code&gt;Sepal.Width&lt;/code&gt;, etc.),&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; whether you want to apply a t-test (&lt;code&gt;t.test&lt;/code&gt;) or Wilcoxon test (&lt;code&gt;wilcox.test&lt;/code&gt;) and whether the samples are paired or not (&lt;code&gt;FALSE&lt;/code&gt; if samples are independent, &lt;code&gt;TRUE&lt;/code&gt; if they are paired).&lt;/p&gt;
&lt;p&gt;Based on these graphs, it is easy, even for non-experts, to interpret the results and conclude that the &lt;code&gt;versicolor&lt;/code&gt; and &lt;code&gt;virginica&lt;/code&gt; species are significantly different in terms of all 4 variables (since all &lt;em&gt;p&lt;/em&gt;-values &lt;span class=&#34;math inline&#34;&gt;\(&amp;lt; \frac{0.05}{4} = 0.0125\)&lt;/span&gt; (remind that the Bonferroni correction is applied to avoid the issue of multiple testing, so we divide the usual &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; level by 4 because there are 4 t-tests)).&lt;/p&gt;
&lt;div id=&#34;additional-p-value-adjustment-methods&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Additional &lt;em&gt;p&lt;/em&gt;-value adjustment methods&lt;/h3&gt;
&lt;p&gt;If you would like to use another &lt;em&gt;p&lt;/em&gt;-value adjustment method, you can use the &lt;code&gt;p.adjust()&lt;/code&gt; function. Below are the raw &lt;em&gt;p&lt;/em&gt;-values found above, together with &lt;em&gt;p&lt;/em&gt;-values derived from the main adjustment methods (presented in a dataframe):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_pvalue &amp;lt;- numeric(length = length(1:4))
for (i in (1:4)) {
  raw_pvalue[i] &amp;lt;- t.test(dat[, i] ~ dat$Species,
    paired = FALSE,
    alternative = &amp;quot;two.sided&amp;quot;
  )$p.value
}

df &amp;lt;- data.frame(
  Variable = names(dat[, 1:4]),
  raw_pvalue = round(raw_pvalue, 3)
)

df$Bonferroni &amp;lt;-
  p.adjust(df$raw_pvalue,
    method = &amp;quot;bonferroni&amp;quot;
  )
df$BH &amp;lt;-
  p.adjust(df$raw_pvalue,
    method = &amp;quot;BH&amp;quot;
  )
df$Holm &amp;lt;-
  p.adjust(df$raw_pvalue,
    method = &amp;quot;holm&amp;quot;
  )
df$Hochberg &amp;lt;-
  p.adjust(df$raw_pvalue,
    method = &amp;quot;hochberg&amp;quot;
  )
df$Hommel &amp;lt;-
  p.adjust(df$raw_pvalue,
    method = &amp;quot;hommel&amp;quot;
  )
df$BY &amp;lt;-
  round(p.adjust(df$raw_pvalue,
    method = &amp;quot;BY&amp;quot;
  ), 3)
df&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Variable raw_pvalue Bonferroni    BH  Holm Hochberg Hommel    BY
## 1 Sepal.Length      0.000      0.000 0.000 0.000    0.000  0.000 0.000
## 2  Sepal.Width      0.002      0.008 0.002 0.002    0.002  0.002 0.004
## 3 Petal.Length      0.000      0.000 0.000 0.000    0.000  0.000 0.000
## 4  Petal.Width      0.000      0.000 0.000 0.000    0.000  0.000 0.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Regardless of the &lt;em&gt;p&lt;/em&gt;-value adjustment method, the two species are different for all 4 variables. Note that the adjustment method should be chosen before looking at the results to avoid choosing the method based on the results.&lt;/p&gt;
&lt;p&gt;Below another function that allows to perform multiple Student’s t-tests or Wilcoxon tests at once and choose the &lt;em&gt;p&lt;/em&gt;-value adjustment method. The function also allows to specify whether samples are paired or unpaired and whether the variances are assumed to be equal or not. (The code has been adapted from Mark White’s &lt;a href=&#34;https://www.markhw.com/blog/t-table&#34; target=&#34;_blank&#34;&gt;article&lt;/a&gt;.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t_table &amp;lt;- function(data, dvs, iv,
                    var_equal = TRUE,
                    p_adj = &amp;quot;none&amp;quot;,
                    alpha = 0.05,
                    paired = FALSE,
                    wilcoxon = FALSE) {
  if (!inherits(data, &amp;quot;data.frame&amp;quot;)) {
    stop(&amp;quot;data must be a data.frame&amp;quot;)
  }

  if (!all(c(dvs, iv) %in% names(data))) {
    stop(&amp;quot;at least one column given in dvs and iv are not in the data&amp;quot;)
  }

  if (!all(sapply(data[, dvs], is.numeric))) {
    stop(&amp;quot;all dvs must be numeric&amp;quot;)
  }

  if (length(unique(na.omit(data[[iv]]))) != 2) {
    stop(&amp;quot;independent variable must only have two unique values&amp;quot;)
  }

  out &amp;lt;- lapply(dvs, function(x) {
    if (paired == FALSE &amp;amp; wilcoxon == FALSE) {
      tres &amp;lt;- t.test(data[[x]] ~ data[[iv]], var.equal = var_equal)
    }

    else if (paired == FALSE &amp;amp; wilcoxon == TRUE) {
      tres &amp;lt;- wilcox.test(data[[x]] ~ data[[iv]])
    }

    else if (paired == TRUE &amp;amp; wilcoxon == FALSE) {
      tres &amp;lt;- t.test(data[[x]] ~ data[[iv]],
        var.equal = var_equal,
        paired = TRUE
      )
    }

    else {
      tres &amp;lt;- wilcox.test(data[[x]] ~ data[[iv]],
        paired = TRUE
      )
    }

    c(
      p_value = tres$p.value
    )
  })

  out &amp;lt;- as.data.frame(do.call(rbind, out))
  out &amp;lt;- cbind(variable = dvs, out)
  names(out) &amp;lt;- gsub(&amp;quot;[^0-9A-Za-z_]&amp;quot;, &amp;quot;&amp;quot;, names(out))

  out$p_value &amp;lt;- ifelse(out$p_value &amp;lt; 0.001,
    &amp;quot;&amp;lt;0.001&amp;quot;,
    round(p.adjust(out$p_value, p_adj), 3)
  )
  out$conclusion &amp;lt;- ifelse(out$p_value &amp;lt; alpha,
    paste0(&amp;quot;Reject H0 at &amp;quot;, alpha * 100, &amp;quot;%&amp;quot;),
    paste0(&amp;quot;Do not reject H0 at &amp;quot;, alpha * 100, &amp;quot;%&amp;quot;)
  )

  return(out)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Applied to our dataset, with no adjustment method for the &lt;em&gt;p&lt;/em&gt;-values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result &amp;lt;- t_table(
  data = dat,
  c(&amp;quot;Sepal.Length&amp;quot;, &amp;quot;Sepal.Width&amp;quot;, &amp;quot;Petal.Length&amp;quot;, &amp;quot;Petal.Width&amp;quot;),
  &amp;quot;Species&amp;quot;
)

result&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       variable p_value      conclusion
## 1 Sepal.Length  &amp;lt;0.001 Reject H0 at 5%
## 2  Sepal.Width   0.002 Reject H0 at 5%
## 3 Petal.Length  &amp;lt;0.001 Reject H0 at 5%
## 4  Petal.Width  &amp;lt;0.001 Reject H0 at 5%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And with the &lt;span class=&#34;citation&#34;&gt;Holm (1979)&lt;/span&gt; adjustment method:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;result &amp;lt;- t_table(
  data = dat,
  c(&amp;quot;Sepal.Length&amp;quot;, &amp;quot;Sepal.Width&amp;quot;, &amp;quot;Petal.Length&amp;quot;, &amp;quot;Petal.Width&amp;quot;),
  &amp;quot;Species&amp;quot;,
  p_adj = &amp;quot;holm&amp;quot;
)

result&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       variable p_value      conclusion
## 1 Sepal.Length  &amp;lt;0.001 Reject H0 at 5%
## 2  Sepal.Width   0.002 Reject H0 at 5%
## 3 Petal.Length  &amp;lt;0.001 Reject H0 at 5%
## 4  Petal.Width  &amp;lt;0.001 Reject H0 at 5%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, with the Holm’s adjustment method, we conclude that, at the 5% significance level, the two species are significantly different from each other in terms of all 4 variables.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;anova&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;ANOVA&lt;/h2&gt;
&lt;p&gt;Below the same process with an ANOVA. Note that we reload the dataset &lt;code&gt;iris&lt;/code&gt; to include all three &lt;code&gt;Species&lt;/code&gt; this time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- iris

# Edit from here
x &amp;lt;- which(names(dat) == &amp;quot;Species&amp;quot;) # name of grouping variable
y &amp;lt;- which(names(dat) == &amp;quot;Sepal.Length&amp;quot; # names of variables to test
| names(dat) == &amp;quot;Sepal.Width&amp;quot;
| names(dat) == &amp;quot;Petal.Length&amp;quot;
| names(dat) == &amp;quot;Petal.Width&amp;quot;)
method1 &amp;lt;- &amp;quot;anova&amp;quot; # one of &amp;quot;anova&amp;quot; or &amp;quot;kruskal.test&amp;quot;
method2 &amp;lt;- &amp;quot;t.test&amp;quot; # one of &amp;quot;wilcox.test&amp;quot; or &amp;quot;t.test&amp;quot;
my_comparisons &amp;lt;- list(c(&amp;quot;setosa&amp;quot;, &amp;quot;versicolor&amp;quot;), c(&amp;quot;setosa&amp;quot;, &amp;quot;virginica&amp;quot;), c(&amp;quot;versicolor&amp;quot;, &amp;quot;virginica&amp;quot;)) # comparisons for post-hoc tests
# Edit until here


# Edit at your own risk
for (i in y) {
  for (j in x) {
    p &amp;lt;- ggboxplot(dat,
      x = colnames(dat[j]), y = colnames(dat[i]),
      color = colnames(dat[j]),
      legend = &amp;quot;none&amp;quot;,
      palette = &amp;quot;npg&amp;quot;,
      add = &amp;quot;jitter&amp;quot;
    )
    print(
      p + stat_compare_means(aes(label = paste0(..method.., &amp;quot;, p-value = &amp;quot;, ..p.format..)),
        method = method1, label.y = max(dat[, i], na.rm = TRUE)
      )
      + stat_compare_means(comparisons = my_comparisons, method = method2, label = &amp;quot;p.format&amp;quot;) # remove if p-value of ANOVA or Kruskal-Wallis test &amp;gt;= alpha
    )
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-7-3.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;/blog/2020-03-19-how-to-do-a-t-test-or-anova-for-many-variables-at-once-in-r-and-communicate-the-results-in-a-better-way_files/figure-html/unnamed-chunk-7-4.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Like the improved routine for the t-test, I have noticed that students and non-expert professionals understand ANOVA results presented this way much more easily compared to the default R outputs.&lt;/p&gt;
&lt;p&gt;With one graph for each variable, it is easy to see that all species are different from each other in terms of all 4 variables.&lt;/p&gt;
&lt;p&gt;If you want to apply the same automated process to your data, you will need to modify the name of the grouping variable (&lt;code&gt;Species&lt;/code&gt;), the names of the variables you want to test (&lt;code&gt;Sepal.Length&lt;/code&gt;, etc.), whether you want to perform an ANOVA (&lt;code&gt;anova&lt;/code&gt;) or Kruskal-Wallis test (&lt;code&gt;kruskal.test&lt;/code&gt;) and finally specify the comparisons for the post-hoc tests.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;to-go-even-further&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;To go even further&lt;/h1&gt;
&lt;p&gt;As we have seen, these two improved R routines allow to:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Perform t-tests and ANOVA on a small or large number of variables with only minor changes to the code. I basically only have to replace the variable names and the name of the test I want to use. It takes almost the same time to test one or several variables so it is quite an improvement compared to testing one variable at a time&lt;/li&gt;
&lt;li&gt;Share test results in a much proper and cleaner way. This is possible thanks to a graph showing the observations by group and the &lt;em&gt;p&lt;/em&gt;-value of the appropriate test included on this graph. This is particularily important when communicating results to a wider audience or to people from diverse backgrounds.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;However, like most of my R routines, these two pieces of code are still a work in progress. Below are some additional features I have been thinking of and which could be added in the future to make the process of comparing two or more groups even more optimal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add the possibility to select variables by their numbering in the dataframe. For the moment it is only possible to do it via their names. This will allow to automate the process even further because instead of typing all variable names one by one, we could simply type &lt;code&gt;4:25&lt;/code&gt; (to test variables 4 to 25 for instance).&lt;/li&gt;
&lt;li&gt;Add the possibility to choose a &lt;em&gt;p&lt;/em&gt;-value adjustment method. Currently, raw &lt;em&gt;p&lt;/em&gt;-values are displayed in the graphs and I manually adjust them afterwards.&lt;/li&gt;
&lt;li&gt;When comparing more than two groups, it is only possible to apply an ANOVA or Kruskal-Wallis test at the moment. A major improvement would be to add the possibility to perform a repeated measures ANOVA (i.e., an ANOVA when the samples are dependent). It is currently already possible to do a t-test with two paired samples, but it is not yet possible to do the same with more than two groups.&lt;/li&gt;
&lt;li&gt;Another less important (yet still nice) feature when comparing more than 2 groups would be to automatically apply post-hoc tests only in the case where the null hypothesis of the ANOVA or Kruskal-Wallis test is rejected (so when there is at least one group different from the others, because if the null hypothesis of equal groups is not rejected we do not apply a post-hoc test). At the present time, I manually add or remove the code that displays the &lt;em&gt;p&lt;/em&gt;-values of post-hoc tests depending on the global &lt;em&gt;p&lt;/em&gt;-value of the ANOVA or Kruskal-Wallis test.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will try to add these features in the future, or I would be glad to help if the author of the {ggpubr} package needs help in including these features (I hope he will see this article!).&lt;/p&gt;
&lt;p&gt;Last but not least, the following packages may be of interest to some readers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you want to report statistical results on a graph, I advise you to check the &lt;a href=&#34;https://indrajeetpatil.github.io/ggstatsplot/&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;{ggstatsplot}&lt;/code&gt; package&lt;/a&gt; and in particular the &lt;a href=&#34;https://indrajeetpatil.github.io/ggstatsplot/articles/web_only/ggbetweenstats.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;ggbetweenstats()&lt;/code&gt;&lt;/a&gt; function. This function allows to compare a continuous variable across multiple groups or conditions. Note that many different statistical results are displayed on the graph, not only the name of the test and the &lt;em&gt;p&lt;/em&gt;-value. However, it is still very convenient to be able to include tests results on a graph in order to combine the advantages of a visualization and a sound statistical analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://cloud.r-project.org/web/packages/compareGroups/index.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;{compareGroups}&lt;/code&gt; package&lt;/a&gt; also provides a nice way to compare groups. It comes with a really complete Shiny app, available with:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;compareGroups&amp;quot;)
library(compareGroups)
cGroupsWUI()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks for reading. I hope this article will help you to perform t-tests and ANOVA for multiple variables at once and make the results more easily readable and interpretable by nonscientists. Learn more about the t-test and how to compare two samples in &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/&#34;&gt;this article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;p&gt;McDonald, J.H. 2014. Handbook of Biological Statistics (3rd ed.). Sparky House Publishing, Baltimore, Maryland.&lt;/p&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-holm1979simple&#34;&gt;
&lt;p&gt;Holm, Sture. 1979. “A Simple Sequentially Rejective Multiple Test Procedure.” &lt;em&gt;Scandinavian Journal of Statistics&lt;/em&gt;. JSTOR, 65–70.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;In theory, an ANOVA can also be used to compare two groups as it will give the same results compared to a Student’s t-test, but in practice we use the Student’s t-test to compare two samples and the ANOVA to compare three samples or more.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Do not forget to separate the variables you want to test with &lt;code&gt;|&lt;/code&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Post-hoc test is only the name used to refer to a specific type of statistical tests. Post-hoc test includes, among others, the Tukey HSD test, the Bonferroni correction, Dunnett’s test. Even if an ANOVA or a Kruskal-Wallis test can determine whether there is at least one group that is different from the others, it does not allow us to conclude &lt;strong&gt;which&lt;/strong&gt; are different from each other. For this purpose, there are post-hoc tests that compare all groups two by two to determine which ones are different, after adjusting for multiple comparisons. Concretely, post-hoc tests are performed to each possible pair of groups &lt;strong&gt;after&lt;/strong&gt; an ANOVA or a Kruskal-Wallis test has shown that there is at least one group which is different (hence “post” in the name of this type of test). The null and alternative hypotheses and the interpretations of these tests are similar to a Student’s t-test for two samples.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How to perform a one sample t-test by hand and in R: test on one mean</title>
      <link>/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r-test-on-one-mean/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r-test-on-one-mean/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#null-and-alternative-hypothesis&#34;&gt;Null and alternative hypothesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hypothesis-testing&#34;&gt;Hypothesis testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#two-versions-of-the-one-sample-t-test&#34;&gt;Two versions of the one sample t-test&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-compute-the-one-sample-t-test-by-hand&#34;&gt;How to compute the one sample t-test by hand?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-1-variance-of-the-population-is-known&#34;&gt;Scenario 1: variance of the population is known&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-2-variance-of-the-population-is-unknown&#34;&gt;Scenario 2: variance of the population is unknown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#different-underlying-distributions-for-the-critical-value&#34;&gt;Different underlying distributions for the critical value&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-compute-the-one-sample-t-test-in-r&#34;&gt;How to compute the one sample t-test in R?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-1-variance-of-the-population-is-known-1&#34;&gt;Scenario 1: variance of the population is known&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-2-variance-of-the-population-is-unknown-1&#34;&gt;Scenario 2: variance of the population is unknown&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#confidence-interval&#34;&gt;Confidence interval&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assumptions&#34;&gt;Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r_files/how-to-perform-a-one-sample-t-test-by-hand-and-in-r.jpeg&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;After having written an article on the &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/&#34;&gt;Student’s t-test for two samples&lt;/a&gt; (independent and paired samples), I believe it is time to explain in details how to perform one sample t-tests by hand and in R.&lt;/p&gt;
&lt;p&gt;One sample t-test is an important part of inferential statistics (probably one of the first statistical test that students learn). Remind that, unlike &lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;descriptive statistics&lt;/a&gt;, inferential statistics is a branch of statistics aiming at drawing conclusions about one or two &lt;a href=&#34;/blog/what-is-the-difference-between-population-and-sample/&#34;&gt;populations&lt;/a&gt;, based on a subset (or two) of that population (called samples). In other words, we first collect a random set of observations from a population, and then some measurements are calculated in order to generalize to the population the information found through the sample.&lt;/p&gt;
&lt;p&gt;In this context, the &lt;strong&gt;one sample t-test is used to determine whether the mean of a measurement variable is different from a specified value&lt;/strong&gt; (a belief or a theoretical expectation for example). It works as follows: if the mean of the sample is too distant from the specified value (the value under the null hypothesis), it is considered that the mean of the population is different from what is expected. On the contrary, if the mean of the sample is close to the specified value, we cannot reject the hypothesis that the population mean is equal to what is expected.&lt;/p&gt;
&lt;p&gt;Like the Student’s t-test for two samples, there are also different versions of the one sample t-test. Luckily, there are only two different versions for this test (the Student’s t-test for two samples has 5 versions!). The difference between the two versions of the one sample t-test lies in the fact that one version is used when the variance of the population (not the variance of the sample!) is known, the other version being used when the variance of the population is unknown.&lt;/p&gt;
&lt;p&gt;In this article, I will first detail step by step how to perform both versions of the one sample t-test by hand. The analyses will be done on a small set of observations for the sake of illustration and easiness. I will then show how to perform this test in R with the exact same data in order to verify the results found by hand. Reminders about the reasoning behind hypothesis testing, interpretations of the &lt;em&gt;p&lt;/em&gt;-value and the results, and assumptions of this test will also be presented.&lt;/p&gt;
&lt;p&gt;Note that the aim of this article is to show how to compute the one sample t-test by hand and in R, so we refrain from testing the assumptions and we assume all assumptions are met for this exercise. For completeness, we still mention the assumptions and how to test them. Interested readers are invited to have a look at the &lt;a href=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r-test-on-one-mean/#assumptions&#34;&gt;end of the article&lt;/a&gt; for more information about these assumptions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-and-alternative-hypothesis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Null and alternative hypothesis&lt;/h1&gt;
&lt;p&gt;Before diving into the computations of the one sample t-test by hand, let’s recap the null and alternative hypotheses of this test:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu = \mu_0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu \ne \mu_0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the population mean and &lt;span class=&#34;math inline&#34;&gt;\(\mu_0\)&lt;/span&gt; is the known or &lt;strong&gt;hypothesized&lt;/strong&gt; value of the mean in the population.&lt;/p&gt;
&lt;p&gt;This is in the general case where we simply want to determine whether the population mean is &lt;strong&gt;different&lt;/strong&gt; (in terms of the dependent variable) compared to the hypothesized value. In this sense, we have no prior belief about the population mean being larger or smaller than the hypothesized value. This type of test is referred as a &lt;strong&gt;two-sided&lt;/strong&gt; or bilateral test.&lt;/p&gt;
&lt;p&gt;If we have some prior beliefs about the population mean being larger or smaller than the hypothesized value, the one sample t-test also allows to test the following hypotheses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu = \mu_0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu &amp;gt; \mu_0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu = \mu_0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu &amp;lt; \mu_0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the first case, we want to test if the population mean is significantly larger than the hypothesized value, while in the latter case, we want to test if the population mean is significantly smaller than the hypothesized value. This type of test is referred as a &lt;strong&gt;one-sided&lt;/strong&gt; or unilateral test.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hypothesis-testing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hypothesis testing&lt;/h1&gt;
&lt;p&gt;In statistics, many statistical tests is in the form of hypothesis tests. Hypothesis tests are used to determine whether a certain belief can be deemed as true (plausible) or not, based on the data at hand (i.e., the sample(s)). Most hypothesis tests boil down to the following 4 steps:&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;State the null and alternative hypothesis.&lt;/li&gt;
&lt;li&gt;Compute the test statistic, denoted t-stat. Formulas to compute the test statistic differ among the different versions of the one sample t-test but they have the same structure. See scenarios 1 and 2 below to see the different formulas.&lt;/li&gt;
&lt;li&gt;Find the critical value given the theoretical statistical distribution of the test, the parameters of the distribution and the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. For the two versions of the one sample t-test, it is either the normal or the Student’s t distribution (&lt;em&gt;t&lt;/em&gt; denoting the Student distribution and &lt;em&gt;z&lt;/em&gt; denoting the normal distribution).&lt;/li&gt;
&lt;li&gt;Conclude by comparing the t-stat (found in step 2.) with the critical value (found in step. 3). If the t-stat lies in the rejection region (determined thanks to the critical value and the direction of the test), we reject the null hypothesis, otherwise we do not reject the null hypothesis. These two alternatives (reject or do not reject the null hypothesis) are the only two possible solutions, we never “accept” an hypothesis. It is also a good practice to always interpret the decision in the terms of the initial question.
&lt;!-- See why we do not accept an hypothesis in this article covering the reasoning behind [hypothesis tests](/blog/xxx/). --&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;two-versions-of-the-one-sample-t-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Two versions of the one sample t-test&lt;/h1&gt;
&lt;p&gt;There are two versions of the one sample t-test, depending on whether the variance of the population (not the variance of the sample!) is known or unknown. This criteria is rather straightforward, we either know the variance of the population or we do not. The variance of the population cannot be computed because if you can compute the variance of a population, it means you have the data for the whole population, then there is no need to do a hypothesis test anymore…&lt;/p&gt;
&lt;p&gt;So the variance of the population is either given in the statement (use them in that case), or there is no information about the variance and in that case, it is assumed that the variance is unknown. In practice, the variance of the population is most of the time unknown. However, we still illustrate how to do both versions of this test by hand and in R in the next sections following the 4 steps of hypothesis testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-compute-the-one-sample-t-test-by-hand&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to compute the one sample t-test by hand?&lt;/h1&gt;
&lt;p&gt;Note that the data are artificial and do not represent any real variable. Furthermore, remind that the assumptions may or may not be met. The point of the article is to detail how to compute the different versions of the test by hand and in R, so all assumptions are assumed to be met. Moreover, assume that the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 5\)&lt;/span&gt;% for all tests.&lt;/p&gt;
&lt;p&gt;If you are interested in applying these tests by hand without having to do the computations yourself, here is a &lt;a href=&#34;/blog/a-shiny-app-for-inferential-statistics-by-hand/&#34;&gt;Shiny app&lt;/a&gt; which does it for you. You just need to enter the data and choose the appropriate version of the test thanks to the sidebar menu. There is also a graphical representation that helps you to visualize the test statistic and the rejection region. I hope you will find it useful!&lt;/p&gt;
&lt;div id=&#34;scenario-1-variance-of-the-population-is-known&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 1: variance of the population is known&lt;/h2&gt;
&lt;p&gt;For the first scenario, suppose the data below. Moreover, suppose that the population variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 = 1\)&lt;/span&gt; and that we would like to test whether the population mean is different from 0.&lt;/p&gt;
&lt;table style=&#34;width:11%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5 observations: &lt;span class=&#34;math inline&#34;&gt;\(n = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of the sample: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x} = 0.56\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variance of the population: &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 = 1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_0 = 0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the 4 steps of hypothesis testing we have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu \ne 0\)&lt;/span&gt;. (&lt;span class=&#34;math inline&#34;&gt;\(\ne\)&lt;/span&gt; because we want to test whether the population mean is different from 0, we do not impose a direction in the test.)&lt;/li&gt;
&lt;li&gt;Test statistic: &lt;span class=&#34;math display&#34;&gt;\[z_{obs} = \frac{\bar{x} - \mu_0}{\frac{\sigma}{\sqrt{n}}} = \frac{0.56-0}{0.447} = 1.252\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Critical value: &lt;span class=&#34;math inline&#34;&gt;\(\pm z_{\alpha / 2} = \pm z_{0.025} = \pm 1.96\)&lt;/span&gt; (see a guide on &lt;a href=&#34;/blog/a-guide-on-how-to-read-statistical-tables/&#34;&gt;how to read statistical tables&lt;/a&gt; if you struggle to find the critical value)&lt;/li&gt;
&lt;li&gt;Conclusion: The rejection regions are thus from &lt;span class=&#34;math inline&#34;&gt;\(-\infty\)&lt;/span&gt; to -1.96 and from 1.96 to &lt;span class=&#34;math inline&#34;&gt;\(+\infty\)&lt;/span&gt;. The test statistic is outside the rejection regions so we do not reject the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. In terms of the initial question: At the 5% significance level, we do not reject the hypothesis that the population mean is equal to 0, or there is no sufficient evidence in the data to conclude that the population mean is different from 0.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-2-variance-of-the-population-is-unknown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 2: variance of the population is unknown&lt;/h2&gt;
&lt;p&gt;For the second scenario, suppose the data below. Moreover, suppose that the variance in the population is unknown and that we would like to test whether the population mean is larger than 5.&lt;/p&gt;
&lt;table style=&#34;width:11%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5 observations: &lt;span class=&#34;math inline&#34;&gt;\(n = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of the sample: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x} = 6.8\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;standard deviation of the sample: &lt;span class=&#34;math inline&#34;&gt;\(s = 0.825\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mu_0 = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the 4 steps of hypothesis testing we have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu = 5\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu &amp;gt; 5\)&lt;/span&gt;. (&amp;gt; because we want to test whether the population mean is larger than 5.)&lt;/li&gt;
&lt;li&gt;Test statistic: &lt;span class=&#34;math display&#34;&gt;\[t_{obs} = \frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}}} = \frac{6.8-5}{0.369} = 4.881\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Critical value: &lt;span class=&#34;math inline&#34;&gt;\(t_{\alpha, n - 1} = t_{0.05, 4} = 2.132\)&lt;/span&gt; (see a guide on &lt;a href=&#34;/blog/a-guide-on-how-to-read-statistical-tables/&#34;&gt;how to read statistical tables&lt;/a&gt; if you struggle to find the critical value)&lt;/li&gt;
&lt;li&gt;Conclusion: The rejection region is thus from 2.132 to &lt;span class=&#34;math inline&#34;&gt;\(+\infty\)&lt;/span&gt;. The test statistic lies within the rejection region so we reject the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. In terms of the initial question: At the 5% significance level, we conclude that the population mean is larger than 5.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This concludes how to perform the two versions of the one sample t-test by hand. In the next sections, we detail how to perform the exact same tests in R.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;different-underlying-distributions-for-the-critical-value&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Different underlying distributions for the critical value&lt;/h2&gt;
&lt;p&gt;As you may have noticed, the underlying probability distributions used to find the critical value are different depending on whether the variance of the population is known or unknown.&lt;/p&gt;
&lt;p&gt;The underlying probability distribution when the variance is known (scenario 1) is the normal distribution, while the probability distribution in the case where the variance is unknown (scenario 2) is the Student’s t distribution. This difference is partially explained by the fact that when the variance of the population is unknown, there is more “uncertainty” in the data, so we need to use the Student’s t distribution instead of the normal distribution.&lt;/p&gt;
&lt;p&gt;Note that when the sample size is large (usually when &lt;em&gt;n &amp;gt; 30&lt;/em&gt;), the Student’s t distribution tends to a normal distribution. Using a normal distribution when the variance is known and a Student’s t distribution when the variance is unknown also applies to a &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/&#34;&gt;t-test for two samples&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-compute-the-one-sample-t-test-in-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to compute the one sample t-test in R?&lt;/h1&gt;
&lt;p&gt;A good practice before doing t-tests in R is to visualize the data thanks to a &lt;a href=&#34;/blog/descriptive-statistics-in-r/#boxplot&#34;&gt;boxplot&lt;/a&gt; (or a &lt;a href=&#34;/blog/descriptive-statistics-in-r/#density-plot&#34;&gt;density plot&lt;/a&gt;, or eventually both). A boxplot gives a first indication on the location of the sample, and thus, a first indication on whether the null hypothesis is likely to be rejected or not. However, even if a boxplot or a density plot is great in showing the distribution of a sample, only a sound statistical test will confirm our first impression.&lt;/p&gt;
&lt;p&gt;After a visualization of the data, we replicate in R the results found by hand. We will see that for the version of the t-test with a known population variance, there is no default function built in R (at least to my knowledge, do not hesitate to let me know if I’m mistaken). In this case, a function is written to replicate the results by hand.&lt;/p&gt;
&lt;p&gt;Note that we use the same data, the same assumptions and the same question for both scenarios to facilitate the comparison between the tests performed by hand and in R.&lt;/p&gt;
&lt;div id=&#34;scenario-1-variance-of-the-population-is-known-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 1: variance of the population is known&lt;/h2&gt;
&lt;p&gt;For the first scenario, suppose the data below. Moreover, suppose that the population variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 = 1\)&lt;/span&gt; and that we would like to test whether the population mean is different from 0.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat1 &amp;lt;- data.frame(
  value = c(0.9, -0.8, 1.3, -0.3, 1.7)
)

dat1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   value
## 1   0.9
## 2  -0.8
## 3   1.3
## 4  -0.3
## 5   1.7&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

ggplot(dat1) +
  aes(y = value) +
  geom_boxplot() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that you can use the &lt;a href=&#34;/blog/rstudio-addins-or-how-to-make-your-coding-life-easier/#esquisse&#34;&gt;&lt;code&gt;{esquisse}&lt;/code&gt; RStudio addin&lt;/a&gt; if you want to draw a boxplot with the package &lt;code&gt;{ggplot2}&lt;/code&gt; without writing the code yourself. If you prefer the default graphics, use the &lt;code&gt;boxplot()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boxplot(dat1$value)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The boxplot shows that the distribution of the sample is not distant from 0 (the hypothesized value), so we tend to believe that we will not be able to reject the null hypothesis that the population mean is equal to 0. However, only a formal statistical test will confirm this belief.&lt;/p&gt;
&lt;p&gt;Since there is no function in R to perform a t-test with a known population variance, here is one with arguments accepting the sample (&lt;code&gt;x&lt;/code&gt;), the variance of the population (&lt;code&gt;V&lt;/code&gt;), the mean under the null hypothesis (&lt;code&gt;m0&lt;/code&gt;, default is &lt;code&gt;0&lt;/code&gt;), the significance level (&lt;code&gt;alpha&lt;/code&gt;, default is &lt;code&gt;0.05&lt;/code&gt;) and the alternative (&lt;code&gt;alternative&lt;/code&gt;, one of &lt;code&gt;&amp;quot;two.sided&amp;quot;&lt;/code&gt; (default), &lt;code&gt;&amp;quot;less&amp;quot;&lt;/code&gt; or &lt;code&gt;&amp;quot;greater&amp;quot;&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test2 &amp;lt;- function(x, V, m0 = 0, alpha = 0.05, alternative = &amp;quot;two.sided&amp;quot;) {
  M &amp;lt;- mean(x)
  n &amp;lt;- length(x)
  sigma &amp;lt;- sqrt(V)
  S &amp;lt;- sqrt(V / n)
  statistic &amp;lt;- (M - m0) / S
  p &amp;lt;- if (alternative == &amp;quot;two.sided&amp;quot;) {
    2 * pnorm(abs(statistic), lower.tail = FALSE)
  } else if (alternative == &amp;quot;less&amp;quot;) {
    pnorm(statistic, lower.tail = TRUE)
  } else {
    pnorm(statistic, lower.tail = FALSE)
  }
  LCL &amp;lt;- (M - S * qnorm(1 - alpha / 2))
  UCL &amp;lt;- (M + S * qnorm(1 - alpha / 2))
  value &amp;lt;- list(mean = M, m0 = m0, sigma = sigma, statistic = statistic, p.value = p, LCL = LCL, UCL = UCL, alternative = alternative)
  # print(sprintf(&amp;quot;P-value = %g&amp;quot;,p))
  # print(sprintf(&amp;quot;Lower %.2f%% Confidence Limit = %g&amp;quot;,
  #               alpha, LCL))
  # print(sprintf(&amp;quot;Upper %.2f%% Confidence Limit = %g&amp;quot;,
  #               alpha, UCL))
  return(value)
}

test &amp;lt;- t.test2(dat1$value,
  V = 1
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $mean
## [1] 0.56
## 
## $m0
## [1] 0
## 
## $sigma
## [1] 1
## 
## $statistic
## [1] 1.252198
## 
## $p.value
## [1] 0.2104977
## 
## $LCL
## [1] -0.3165225
## 
## $UCL
## [1] 1.436523
## 
## $alternative
## [1] &amp;quot;two.sided&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above recaps all the information needed to perform the test: the test statistic, the &lt;em&gt;p&lt;/em&gt;-value, the alternative used, the sample mean, the hypothesized value and the population variance (compare these results found in R with the results found by hand).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value can be extracted as usual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2104977&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.21 so at the 5% significance level we do not reject the null hypothesis. There is no sufficient evidence in the data to reject the hypothesis that the population mean is equal to 0. This result confirms what we found by hand.&lt;/p&gt;
&lt;p&gt;If you are unfamiliar with the concept of &lt;em&gt;p&lt;/em&gt;-value, I invite you to read my &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/#a-note-on-p-value-and-significance-level-alpha&#34;&gt;note on &lt;em&gt;p&lt;/em&gt;-value and significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To sum up&lt;/strong&gt; what have been said in that article about &lt;em&gt;p&lt;/em&gt;-value and significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the &lt;em&gt;p&lt;/em&gt;-value is smaller than the predetermined significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; (usually 5%) so if &lt;em&gt;p&lt;/em&gt;-value &amp;lt; 0.05, we reject the null hypothesis&lt;/li&gt;
&lt;li&gt;If the &lt;em&gt;p&lt;/em&gt;-value is greater than or equal to the predetermined significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; (usually 5%) so if &lt;em&gt;p&lt;/em&gt;-value &lt;span class=&#34;math inline&#34;&gt;\(\ge\)&lt;/span&gt; 0.05, we do &lt;strong&gt;not reject&lt;/strong&gt; the null hypothesis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This applies to all statistical tests without exception. Of course, the null and alternative hypotheses change depending on the test.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-2-variance-of-the-population-is-unknown-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 2: variance of the population is unknown&lt;/h2&gt;
&lt;p&gt;For the second scenario, suppose the data below. Moreover, suppose that the variance in the population is unknown and that we would like to test whether the population mean is larger than 5.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat2 &amp;lt;- data.frame(
  value = c(7.9, 5.8, 6.3, 7.3, 6.7)
)

dat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   value
## 1   7.9
## 2   5.8
## 3   6.3
## 4   7.3
## 5   6.7&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat2) +
  aes(y = value) +
  geom_boxplot() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unlike the previous scenario, the box is quite distant from the hypothesized value of 5. From this boxplot, we can expect the test to reject the null hypothesis of the population mean being equal to 5. Nonetheless, only a formal statistical test will confirm this expectation.&lt;/p&gt;
&lt;p&gt;There is a function in R, and it is simply the &lt;code&gt;t.test()&lt;/code&gt; function. This version of the test is actually the “standard” t-test for one sample. Note that in our case the alternative hypothesis is &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu &amp;gt; 5\)&lt;/span&gt; so we need to add the arguments &lt;code&gt;mu = 5&lt;/code&gt; and &lt;code&gt;alternative = &amp;quot;greater&amp;quot;&lt;/code&gt; to the function because the default arguments are &lt;code&gt;mu = 0&lt;/code&gt; and the two-sided test:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- t.test(dat2$value,
  mu = 5,
  alternative = &amp;quot;greater&amp;quot;
)

test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  One Sample t-test
## 
## data:  dat2$value
## t = 4.8809, df = 4, p-value = 0.004078
## alternative hypothesis: true mean is greater than 5
## 95 percent confidence interval:
##  6.013814      Inf
## sample estimates:
## mean of x 
##       6.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above recaps all the information needed to perform the test: the name of the test, the test statistic, the degrees of freedom, the &lt;em&gt;p&lt;/em&gt;-value, the alternative used, the hypothesized value and the sample mean (compare these results found in R with the results found by hand).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value can be extracted as usual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.004077555&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.004 so at the 5% significance level we reject the null hypothesis.&lt;/p&gt;
&lt;p&gt;Unlike the first scenario, the &lt;em&gt;p&lt;/em&gt;-value in this scenario is below 5% so we reject the null hypothesis. At the 5% significance level, we can conclude that the population mean is significantly larger than 5. This result confirms what we found by hand.&lt;/p&gt;
&lt;div id=&#34;confidence-interval&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Confidence interval&lt;/h3&gt;
&lt;p&gt;Note that the confidence interval can be extracted with &lt;code&gt;$conf.int&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$conf.int&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6.013814      Inf
## attr(,&amp;quot;conf.level&amp;quot;)
## [1] 0.95&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see that the 95% confidence interval for the population mean is &lt;span class=&#34;math inline&#34;&gt;\([6.01; \infty]\)&lt;/span&gt;, meaning that, at the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 5\)&lt;/span&gt;%, we reject the null hypothesis as long as the hypothesized value &lt;span class=&#34;math inline&#34;&gt;\(\mu_0\)&lt;/span&gt; is below 6.01, otherwise the null hypothesis cannot be rejected.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Assumptions&lt;/h1&gt;
&lt;p&gt;As for many statistical tests, there are some assumptions that need to be met in order to be able to interpret the results. When one or several assumptions are not met, although it is technically possible to perform these tests, it would be incorrect to interpret the results. Below are the assumptions of the one sample t-test and how to test them:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The data, collected from a representative and randomly selected portion of the total population, should be independent of one another.&lt;/li&gt;
&lt;li&gt;The dependent variable (i.e., the measured variable) must be continuous.&lt;/li&gt;
&lt;li&gt;Observations should follow a &lt;a href=&#34;/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/&#34;&gt;&lt;strong&gt;normal distribution&lt;/strong&gt;&lt;/a&gt;. The normality assumption can be tested visually thanks to a histogram and a QQ-plot, and/or formally via a normality test such as the Shapiro-Wilk or Kolmogorov-Smirnov test (see more information about the normality assumption and how to test it &lt;a href=&#34;/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/#how-to-test-the-normality-assumption&#34;&gt;here&lt;/a&gt;). Some transformations, such as, among others, taking the logarithm, the square root or the Box-Cox transformation can be applied on the observations to transform you data to better fit the normal distribution.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks for reading. I hope this article helped you to understand how the different versions of the one sample t-test work and how to perform them by hand and in R. If you are interested, here is a &lt;a href=&#34;/blog/a-shiny-app-for-inferential-statistics-by-hand/&#34;&gt;Shiny app&lt;/a&gt; to perform these tests by hand easily (you just need to enter your data and select the appropriate version of the test thanks to the sidebar menu). Moreover, read &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/&#34;&gt;this article&lt;/a&gt; if you would like to know how to compute the Student’s t-test but this time, for two samples, in order to compare two dependent or independent groups.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;It is a least the case regarding parametric hypothesis tests. A parametric test means that it is based on a theoretical statistical distribution, which depends on some defined parameters. In the case of the one sample t-test, it is based on the Student’s t distribution with a single parameter, the degrees of freedom (&lt;span class=&#34;math inline&#34;&gt;\(df = n - 1\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the sample size), or the normal distribution.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Student&#39;s t-test in R and by hand: how to compare two groups under different scenarios</title>
      <link>/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;/rmarkdown-libs/viz/viz.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/DiagrammeR-styles/styles.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/grViz-binding/grViz.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#null-and-alternative-hypothesis&#34;&gt;Null and alternative hypothesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hypothesis-testing&#34;&gt;Hypothesis testing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#different-versions-of-the-students-t-test&#34;&gt;Different versions of the Student’s t-test&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-compute-students-t-test-by-hand&#34;&gt;How to compute Student’s t-test by hand?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-1-independent-samples-with-2-known-variances&#34;&gt;Scenario 1: Independent samples with 2 known variances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-2-independent-samples-with-2-equal-but-unknown-variances&#34;&gt;Scenario 2: Independent samples with 2 equal but unknown variances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-3-independent-samples-with-2-unequal-and-unknown-variances&#34;&gt;Scenario 3: Independent samples with 2 unequal and unknown variances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-4-paired-samples-where-the-variance-of-the-differences-is-known&#34;&gt;Scenario 4: Paired samples where the variance of the differences is known&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-5-paired-samples-where-the-variance-of-the-differences-is-unknown&#34;&gt;Scenario 5: Paired samples where the variance of the differences is unknown&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-compute-students-t-test-in-r&#34;&gt;How to compute Student’s t-test in R?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-1-independent-samples-with-2-known-variances-1&#34;&gt;Scenario 1: Independent samples with 2 known variances&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#a-note-on-p-value-and-significance-level-alpha&#34;&gt;A note on &lt;em&gt;p&lt;/em&gt;-value and significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-2-independent-samples-with-2-equal-but-unknown-variances-1&#34;&gt;Scenario 2: Independent samples with 2 equal but unknown variances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-3-independent-samples-with-2-unequal-and-unknown-variances-1&#34;&gt;Scenario 3: Independent samples with 2 unequal and unknown variances&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-4-paired-samples-where-the-variance-of-the-differences-is-known-1&#34;&gt;Scenario 4: Paired samples where the variance of the differences is known&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scenario-5-paired-samples-where-the-variance-of-the-differences-is-unknown-1&#34;&gt;Scenario 5: Paired samples where the variance of the differences is unknown&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#assumptions&#34;&gt;Assumptions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios_files/Student-t-test-in-R-and-by-hand-how-to-compare-two-groups-under-different-scenarios.jpeg&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;One of the most important test within the branch of inferential statistics is the &lt;strong&gt;Student’s t-test&lt;/strong&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The Student’s t-test for two samples is used to &lt;strong&gt;test whether two groups (two populations) are different&lt;/strong&gt; in terms of a quantitative variable, &lt;strong&gt;based on the comparison of two samples&lt;/strong&gt; drawn from these two groups. In other words, a Student’s t-test for two samples allows to determine whether the two populations from which your two samples are drawn are different (with the two samples being measured on a &lt;a href=&#34;/blog/variable-types-and-examples/#continuous&#34;&gt;quantitative continuous&lt;/a&gt; variable).&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The reasoning behind this statistical test is that if your two samples are markedly different from each other, it can be assumed that the two populations from which the samples are drawn are different. On the contrary, if the two samples are rather similar, we cannot reject the hypothesis that the two populations are similar, so there is no sufficient evidence in the data at hand to conclude that the two populations from which the samples are drawn are different. Note that this statistical tool belongs to the branch of inferential statistics because conclusions drawn from the study of the samples are generalized to the population, even though we do not have the data on the entire population.&lt;/p&gt;
&lt;p&gt;To compare two samples, it is usual to compare a measure of central tendency computed for each sample. In the case of the Student’s t-test, the &lt;a href=&#34;/blog/descriptive-statistics-by-hand/#mean&#34;&gt;mean&lt;/a&gt; is used to compare the two samples. However, in some cases, the mean is not appropriate to compare two samples so the &lt;a href=&#34;/blog/descriptive-statistics-by-hand/#median&#34;&gt;median&lt;/a&gt; is used to compare them via the Wilcoxon test. This article being already quite long and complete, the Wilcoxon test will be covered in a separate article, together with some illustrations on when to use one test or the other.&lt;/p&gt;
&lt;p&gt;These two tests (Student’s t-test and Wilcoxon test) have the same final goal, that is, compare two samples in order to determine whether the two populations from which they were drawn are different or not. Note that the Student’s t-test is more powerful than the Wilcoxon test (it more often detects a significant difference if there is a true difference, so a smaller difference can be detected with the Student’s t-test) but the Student’s t-test is sensitive to outliers and data asymmetry. Furthermore, within each of these two tests, several versions exist, with each version using different formulas to arrive at the final result. It is thus necessary to understand the difference between the two tests and which version to use in order to carry out the appropriate analyses depending on the question and the data at hand.&lt;/p&gt;
&lt;p&gt;In this article, I will first detail step by step how to perform all versions of the Student’s t-test for independent and paired samples by hand. The analyses will be done on a small set of observations for the sake of illustration and easiness. I will then show how to perform this test in R with the exact same data in order to verify the results found by hand. Reminders about the reasoning behind hypothesis testing, interpretations of the &lt;em&gt;p&lt;/em&gt;-value and the results, and assumptions of this test will also be presented.&lt;/p&gt;
&lt;p&gt;Note that the aim of this article is to show how to compute the Student’s t-test by hand and in R, so we refrain from testing the assumptions and we assume all assumptions are met for this exercise. For completeness, we still mention the assumptions, how to test them and what other tests exist if an assumption is not met. Interested readers are invited to have a look at the &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/#assumptions&#34;&gt;end of the article&lt;/a&gt; for more information about these assumptions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;null-and-alternative-hypothesis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Null and alternative hypothesis&lt;/h1&gt;
&lt;p&gt;Before diving into the computations of the Student’s t-test by hand, let’s recap the null and alternative hypotheses of this test:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu_1 = \mu_2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu_1 \ne \mu_2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_2\)&lt;/span&gt; are the means of the two populations from which the samples were drawn.&lt;/p&gt;
&lt;p&gt;As mentioned in the introduction, although technically the Student’s t-test is based on the comparison of the means of the two samples, the final goal of this test is actually to test the following hypotheses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: the two populations are similar&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: the two populations are different&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is in the general case where we simply want to determine whether the two populations are &lt;strong&gt;different&lt;/strong&gt; or not (in terms of the dependent variable). In this sense, we have no prior belief about a particular population being larger or smaller than the other. This type of test is referred as a &lt;strong&gt;two-sided&lt;/strong&gt; or bilateral test.&lt;/p&gt;
&lt;p&gt;If we have some prior beliefs about one population being larger or smaller than the other, the Student’s t-test also allows to test the following hypotheses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu_1 = \mu_2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu_1 &amp;gt; \mu_2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu_1 = \mu_2\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\mu_1 &amp;lt; \mu_2\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the first case, we want to test if the first population is significantly larger than the second, while in the latter case, we want to test if the first population is significantly smaller than the second. This type of test is referred as a &lt;strong&gt;one-sided&lt;/strong&gt; or unilateral test.&lt;/p&gt;
&lt;p&gt;Some authors argue that one-sided tests should not be used in practice for the simple reason that, if a researcher is so sure that one population is larger (smaller) than the other and would never be smaller (larger) than the other, why would she needs to test for significance at all? This a rather philosophical question and it is beyond the scope of this article. Interested readers are invited to see part of the discussion in &lt;span class=&#34;citation&#34;&gt;Rowntree (2000)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hypothesis-testing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hypothesis testing&lt;/h1&gt;
&lt;p&gt;In statistics, many statistical tests is in the form of hypothesis tests. Hypothesis tests are used to determine whether a certain belief can be deemed as true (plausible) or not, based on the data at hand (i.e., the sample(s)). Most hypothesis tests boil down to the following 4 steps:&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;State the null and alternative hypothesis.&lt;/li&gt;
&lt;li&gt;Compute the test statistic, denoted t-stat. Formulas to compute the test statistic differ among the different versions of the Student’s t-test but they have the same structure. See scenarios 1 to 5 below to see the different formulas.&lt;/li&gt;
&lt;li&gt;Find the critical value given the theoretical statistical distribution of the test, the parameters of the distribution and the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. For a Student’s t-test and its extended version, it is either the normal or the Student’s t distribution (&lt;em&gt;t&lt;/em&gt; denoting the Student distribution and &lt;em&gt;z&lt;/em&gt; denoting the normal distribution).&lt;/li&gt;
&lt;li&gt;Conclude by comparing the t-stat (found in step 2.) with the critical value (found in step. 3). If the t-stat lies in the rejection region (determined thanks to the critical value and the direction of the test), we reject the null hypothesis, otherwise we do not reject the null hypothesis. These two alternatives (reject or do not reject the null hypothesis) are the only two possible solutions, we never “accept” an hypothesis. It is also a good practice to always interpret the decision in the terms of the initial question.
&lt;!-- See why we do not accept an hypothesis in this article covering the reasoning behind [hypothesis tests](/blog/xxx). --&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;different-versions-of-the-students-t-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Different versions of the Student’s t-test&lt;/h1&gt;
&lt;p&gt;There are several versions of the Student’s t-test for two samples, depending on whether the samples are independent or paired and depending on the variances of the populations:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:480px;&#34; class=&#34;grViz html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;diagram&#34;:&#34;digraph {\n\ngraph [rankdir = \&#34;LR\&#34;]\n\n\n\n  \&#34;1\&#34; [label = \&#34;Test on 2 means\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: Test on 2 means\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;2\&#34; [label = \&#34;2 independepent samples\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: 2 independepent samples\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;3\&#34; [label = \&#34;2 variances are known (scenario 1)\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: 2 variances are known (scenario 1)\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;4\&#34; [label = \&#34;2 variances are equal but unknown (scenario 2)\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: 2 variances are equal but unknown (scenario 2)\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;5\&#34; [label = \&#34;2 variances are unequal and unknown (scenario 3)\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: 2 variances are unequal and unknown (scenario 3)\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;6\&#34; [label = \&#34;2 paired samples\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: 2 paired samples\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;7\&#34; [label = \&#34;Variance of the differences is known (scenario 4)\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: Variance of the differences is known (scenario 4)\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;8\&#34; [label = \&#34;Variance of the differences is unknown (scenario 5)\&#34;, style = \&#34;filled,rounded\&#34;, shape = \&#34;box\&#34;, fontname = \&#34;helvetica\&#34;, tooltip = \&#34;- name: Variance of the differences is unknown (scenario 5)\&#34;, fillcolor = \&#34;LightGray\&#34;, fontcolor = \&#34;#000000\&#34;] \n  \&#34;1\&#34;-&gt;\&#34;2\&#34; \n  \&#34;1\&#34;-&gt;\&#34;6\&#34; \n  \&#34;2\&#34;-&gt;\&#34;3\&#34; \n  \&#34;2\&#34;-&gt;\&#34;4\&#34; \n  \&#34;2\&#34;-&gt;\&#34;5\&#34; \n  \&#34;6\&#34;-&gt;\&#34;7\&#34; \n  \&#34;6\&#34;-&gt;\&#34;8\&#34; \n}&#34;,&#34;config&#34;:{&#34;engine&#34;:&#34;dot&#34;,&#34;options&#34;:null}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;On the one hand, &lt;strong&gt;independent&lt;/strong&gt; samples means that the two samples are collected on &lt;strong&gt;different&lt;/strong&gt; experimental units or different individuals, for instance when we are working on women and men separately, or working on patients who have been randomly assigned to a control and a treatment group (and a patient belongs to only one group). On the other hand, we face &lt;strong&gt;paired&lt;/strong&gt; samples when measurements are collected on the &lt;strong&gt;same&lt;/strong&gt; experimental units, same individuals. This is often the case, for example in medical studies, when testing the efficiency of a treatment at two different times. The same patients are measured twice, before and after the treatment, and the dependency between the two samples must be taken into account in the computation of the test statistic by working on the &lt;strong&gt;differences&lt;/strong&gt; of measurements for each subject. Paired samples are usually the result of measurements at two different times, but not exclusively. Suppose we want to test the difference in vision between the left and right eyes of 50 athletes. Although the measurements are not made at two different time (before-after), it is clear that both eyes are dependent within each subject. Therefore, the Student’s t-test for paired samples should be used to account for the dependency between the two samples instead of the standard Student’s t-test for independent samples.&lt;/p&gt;
&lt;p&gt;Another criteria for choosing the appropriate version of the Student’s t-test is whether the variances of the populations (not the variances of the samples!) are known or unknown and equal or unequal. This criteria is rather straightforward, we either know the variances of the populations or we do not. The variances of the populations cannot be computed because if you can compute the variance of a population, it means you have the data for the whole population, then there is no need to do a hypothesis test anymore… So the variances of the populations are either given in the statement (use them in that case), or there is no information about these variances and in this case, it is assumed that the variances are unknown. In practice, the variances of the populations are most of the time unknown and the only thing to do in order to choose the appropriate version of the test is to check whether the variances are equal or not. However, we still illustrate how to do all versions of this test by hand and in R in the next sections following the 4 steps of hypothesis testing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-compute-students-t-test-by-hand&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to compute Student’s t-test by hand?&lt;/h1&gt;
&lt;p&gt;Note that the data are artificial and do not represent any real variable. Furthermore, remind that the assumptions may or may not be met. The point of the article is to detail how to compute the different versions of the test by hand and in R, so all assumptions are assumed to be met. Moreover, assume that the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 5\)&lt;/span&gt;% for all tests.&lt;/p&gt;
&lt;p&gt;If you are interested in applying these tests by hand without having to do the computations yourself, here is a &lt;a href=&#34;/blog/a-shiny-app-for-inferential-statistics-by-hand/&#34;&gt;Shiny app&lt;/a&gt; which does it for you. You just need to enter the data and choose the appropriate version of the test thanks to the sidebar menu. There is also a graphical representation that helps you to visualize the test statistic and the rejection region. I hope you will find it useful!&lt;/p&gt;
&lt;div id=&#34;scenario-1-independent-samples-with-2-known-variances&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 1: Independent samples with 2 known variances&lt;/h2&gt;
&lt;p&gt;For the first scenario, suppose the data below. Moreover, suppose that the two samples are independent, that the variances &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 = 1\)&lt;/span&gt; in both populations and that we would like to test whether the two populations are different.&lt;/p&gt;
&lt;table style=&#34;width:24%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sample&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5 observations in each sample: &lt;span class=&#34;math inline&#34;&gt;\(n_1 = n_2 = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of sample 1: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_1 = 0.02\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of sample 2: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_2 = 0.06\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variances of both populations: &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_1 = \sigma^2_2 = 1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the 4 steps of hypothesis testing we have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1 = \mu_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_1 - \mu_2 \ne 0\)&lt;/span&gt;. (&lt;span class=&#34;math inline&#34;&gt;\(\ne\)&lt;/span&gt; because we want to test whether the two means are different, we do not impose a direction in the test.)&lt;/li&gt;
&lt;li&gt;Test statistic: &lt;span class=&#34;math display&#34;&gt;\[z_{obs} = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}}}\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[= \frac{0.02-0.06-0}{0.632} = -0.063\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Critical value: &lt;span class=&#34;math inline&#34;&gt;\(\pm z_{\alpha / 2} = \pm z_{0.025} = \pm 1.96\)&lt;/span&gt; (see a guide on &lt;a href=&#34;/blog/a-guide-on-how-to-read-statistical-tables/&#34;&gt;how to read statistical tables&lt;/a&gt; if you struggle to find the critical value)&lt;/li&gt;
&lt;li&gt;Conclusion: The rejection regions are thus from &lt;span class=&#34;math inline&#34;&gt;\(-\infty\)&lt;/span&gt; to -1.96 and from 1.96 to &lt;span class=&#34;math inline&#34;&gt;\(+\infty\)&lt;/span&gt;. The test statistic is outside the rejection regions so we do not reject the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. In terms of the initial question: At the 5% significance level, we do not reject the hypothesis that the two populations are the same, or there is no sufficient evidence in the data to conclude that the two populations considered are different.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-2-independent-samples-with-2-equal-but-unknown-variances&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 2: Independent samples with 2 equal but unknown variances&lt;/h2&gt;
&lt;p&gt;For the second scenario, suppose the data below. Moreover, suppose that the two samples are independent, that the variances in both populations are unknown but equal (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_1 = \sigma^2_1\)&lt;/span&gt;) and that we would like to test whether population 1 is larger than population 2.&lt;/p&gt;
&lt;table style=&#34;width:24%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sample&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.78&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;6 observations in sample 1: &lt;span class=&#34;math inline&#34;&gt;\(n_1 = 6\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;5 observations in sample 2: &lt;span class=&#34;math inline&#34;&gt;\(n_2 = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of sample 1: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_1 = 1.247\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of sample 2: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_2 = 0.1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variance of sample 1: &lt;span class=&#34;math inline&#34;&gt;\(s^2_1 = 0.303\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variance of sample 2: &lt;span class=&#34;math inline&#34;&gt;\(s^2_1 = 0.315\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the 4 steps of hypothesis testing we have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1 = \mu_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_1 - \mu_2 &amp;gt; 0\)&lt;/span&gt;. (&amp;gt; because we want to test if the mean of the first population is larger than the mean of the second population.)&lt;/li&gt;
&lt;li&gt;Test statistic: &lt;span class=&#34;math display&#34;&gt;\[t_{obs} = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{s_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}\]&lt;/span&gt; where &lt;span class=&#34;math display&#34;&gt;\[s_p = \sqrt{\frac{(n_1-1)s^2_1+ (n_2 - 1)s^2_2}{n_1 + n_2 - 2}} = 0.555\]&lt;/span&gt; so &lt;span class=&#34;math display&#34;&gt;\[t_{obs} = \frac{1.247-0.1-0}{0.555 * 0.606} = 3.411\]&lt;/span&gt;
(Note that as it is assumed the variances of the two populations are equal, a pooled (common) variance, denoted &lt;span class=&#34;math inline&#34;&gt;\(s_p\)&lt;/span&gt;, is computed.)&lt;/li&gt;
&lt;li&gt;Critical value: &lt;span class=&#34;math inline&#34;&gt;\(t_{\alpha, n_1 + n_2 - 2} = t_{0.05, 9} = 1.833\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Conclusion: The rejection region is thus from 1.833 to &lt;span class=&#34;math inline&#34;&gt;\(+\infty\)&lt;/span&gt; (there is only one rejection region because it is a one-sided test). The test statistic lies within the rejection region so we reject the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. In terms of the initial question: At the 5% significance level, we conclude that the population 1 is larger than the population 2.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-3-independent-samples-with-2-unequal-and-unknown-variances&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 3: Independent samples with 2 unequal and unknown variances&lt;/h2&gt;
&lt;p&gt;For the third scenario, suppose the data below. Moreover, suppose that the two samples are independent, that the variances in both populations are unknown and unequal (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_1 \ne \sigma^2_1\)&lt;/span&gt;) and that we would like to test whether population 1 is smaller than population 2.&lt;/p&gt;
&lt;table style=&#34;width:24%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;value&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;sample&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.78&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;5 observations in sample 1: &lt;span class=&#34;math inline&#34;&gt;\(n_1 = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;6 observations in sample 2: &lt;span class=&#34;math inline&#34;&gt;\(n_2 = 6\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of sample 1: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_1 = 0.42\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of sample 2: &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}_2 = 1.247\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variance of sample 1: &lt;span class=&#34;math inline&#34;&gt;\(s^2_1 = 0.107\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variance of sample 2: &lt;span class=&#34;math inline&#34;&gt;\(s^2_1 = 0.303\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the 4 steps of hypothesis testing we have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_1 = \mu_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_1 - \mu_2 &amp;lt; 0\)&lt;/span&gt;. (&amp;lt; because we want to test if the mean of the first population is smaller than the mean of the second population.)&lt;/li&gt;
&lt;li&gt;Test statistic: &lt;span class=&#34;math display&#34;&gt;\[t_{obs} = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)}{\sqrt{\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}}}\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[= \frac{0.42-1.247-0}{0.268} = -3.084\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Critical value: &lt;span class=&#34;math inline&#34;&gt;\(-t_{\alpha, \upsilon}\)&lt;/span&gt; where &lt;span class=&#34;math display&#34;&gt;\[\upsilon = \frac{\bigg(\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2} \bigg)^2}{\frac{\bigg(\frac{s^2_1}{n_1}\bigg)^2}{n_1 - 1} + \frac{\bigg(\frac{s^2_2}{n_2}\bigg)^2}{n_2 - 1}} = 8.28\]&lt;/span&gt; so &lt;span class=&#34;math display&#34;&gt;\[-t_{0.05, 8.28} = -1.851\]&lt;/span&gt; The degrees of freedom 8.28 does not exist in the standard Student distribution table, so simply take 8, or compute it in R with &lt;code&gt;qt(p = 0.05, df = 8.28)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Conclusion: The rejection region is thus from &lt;span class=&#34;math inline&#34;&gt;\(-\infty\)&lt;/span&gt; to -1.851. The test statistic lies within the rejection region so we reject the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. In terms of the initial question: At the 5% significance level, we conclude that the population 1 is smaller than the population 2.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-4-paired-samples-where-the-variance-of-the-differences-is-known&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 4: Paired samples where the variance of the differences is known&lt;/h2&gt;
&lt;p&gt;Student’s t-test with paired samples are a bit different than with independent samples, they are actually more similar to &lt;a href=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r-test-on-one-mean/&#34;&gt;one sample Student’s t-test&lt;/a&gt;. Here is how it works. We actually compute the difference between the two samples for each pair of observations, and then we work on these differences as if we were doing a one sample Student’s t-test by computing the test statistic on these differences.&lt;/p&gt;
&lt;p&gt;In case it is not clear, here is the fourth scenario as an illustration. Suppose the data below. Moreover, suppose that the two samples are dependent (matched), that the variance of the differences in the population is known and equal to 1 (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_D = 1\)&lt;/span&gt;) and that we would like to test whether the difference in the population is different than 0.&lt;/p&gt;
&lt;table style=&#34;width:25%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;before&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;after&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The first thing to do is to compute the differences for all pairs of observations:&lt;/p&gt;
&lt;table style=&#34;width:42%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;before&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;after&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;difference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;-0.3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;0.2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of pairs: &lt;span class=&#34;math inline&#34;&gt;\(n = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of the difference: &lt;span class=&#34;math inline&#34;&gt;\(\bar{D} = 0.04\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variance of the difference in the population: &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_D = 1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;standard deviation of the difference in the population: &lt;span class=&#34;math inline&#34;&gt;\(\sigma_D = 1\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the 4 steps of hypothesis testing we have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_D = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_D \ne 0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Test statistic: &lt;span class=&#34;math display&#34;&gt;\[z_{obs} = \frac{\bar{D} - \mu_0}{\frac{\sigma_D}{\sqrt{n}}} = \frac{0.04-0}{0.447} = 0.089\]&lt;/span&gt;
(This formula is exactly the same than for one sample Student’s t-test with a known variance, except that we work on the mean of the differences.)&lt;/li&gt;
&lt;li&gt;Critical value: &lt;span class=&#34;math inline&#34;&gt;\(\pm z_{\alpha/2} = \pm z_{0.025} = \pm 1.96\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Conclusion: The rejection regions are thus from &lt;span class=&#34;math inline&#34;&gt;\(-\infty\)&lt;/span&gt; to -1.96 and from 1.96 to &lt;span class=&#34;math inline&#34;&gt;\(+\infty\)&lt;/span&gt;. The test statistic is outside the rejection regions so we do not reject the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. In terms of the initial question: At the 5% significance level, we do not reject the hypothesis that the difference in the two populations is equal to 0.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-5-paired-samples-where-the-variance-of-the-differences-is-unknown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 5: Paired samples where the variance of the differences is unknown&lt;/h2&gt;
&lt;p&gt;For the fifth and final scenario, suppose the data below. Moreover, suppose that the two samples are dependent (matched), that the variance of the differences in the population is unknown and that we would like to test whether a treatment is effective in increasing running capabilities (the higher the value, the better in terms of running capabilities).&lt;/p&gt;
&lt;table style=&#34;width:25%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;before&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;after&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The first thing to do is to compute the differences for all pairs of observations:&lt;/p&gt;
&lt;table style=&#34;width:42%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;before&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;after&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;difference&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;So we have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of pairs: &lt;span class=&#34;math inline&#34;&gt;\(n = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;mean of the difference: &lt;span class=&#34;math inline&#34;&gt;\(\bar{D} = 8\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;variance of the difference in the sample: &lt;span class=&#34;math inline&#34;&gt;\(s^2_D = 16\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;standard deviation of the difference in the sample: &lt;span class=&#34;math inline&#34;&gt;\(s_D = 4\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following the 4 steps of hypothesis testing we have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0: \mu_D = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_D &amp;gt; 0\)&lt;/span&gt; (&amp;gt; because we would like to test whether the treatment is effective, so whether the treatment has a positive impact on the running capabilities.)&lt;/li&gt;
&lt;li&gt;Test statistic: &lt;span class=&#34;math display&#34;&gt;\[t_{obs} = \frac{\bar{D} - \mu_0}{\frac{s_D}{\sqrt{n}}} = \frac{8-0}{1.789} = 4.472\]&lt;/span&gt;
(This formula is exactly the same than for one sample Student’s t-test with an unknown variance, except that we work on the mean of the differences.)&lt;/li&gt;
&lt;li&gt;Critical value: &lt;span class=&#34;math inline&#34;&gt;\(t_{\alpha, n-1} = t_{0.05, 4} = 2.132\)&lt;/span&gt; (&lt;em&gt;n&lt;/em&gt; is the number of pairs, not the number of observations!)&lt;/li&gt;
&lt;li&gt;Conclusion: The rejection regions are thus from 2.132 to &lt;span class=&#34;math inline&#34;&gt;\(+\infty\)&lt;/span&gt;. The test statistic lies within the rejection region so we reject the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;. In terms of the initial question: At the 5% significance level, we conclude that the treatment has a positive impact on the running capabilities.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This concludes how to perform the different versions of the Student’s t-test for two samples by hand. In the next sections, we detail how to perform the exact same tests in R.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-compute-students-t-test-in-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to compute Student’s t-test in R?&lt;/h1&gt;
&lt;p&gt;A good practice before doing t-tests in R is to visualize the data by group thanks to a boxplot (or a &lt;a href=&#34;/blog/descriptive-statistics-in-r/#density-plot&#34;&gt;density plot&lt;/a&gt;, or eventually both). A boxplot with the two boxes overlapping each other gives a first indication that the two samples are similar, and thus, that the null hypothesis of equal means may not be rejected. On the contrary, if the two boxes are not overlapping, it indicates that the two samples are not similar, and thus, that the populations may be different. However, even if boxplots or density plots are great in showing a comparison between the two groups, only a sound statistical test will confirm our first impression.&lt;/p&gt;
&lt;p&gt;After a visualization of the data by group, we replicate in R the results found by hand. We will see that for some versions of the t-test, there is no default function built in R (at least to my knowledge, do not hesitate to let me know if I’m mistaken). In these cases, a function is written to replicate the results by hand.&lt;/p&gt;
&lt;p&gt;Note that we use the same data, the same assumptions and the same question for all 5 scenarios to facilitate the comparison between the tests performed by hand and in R.&lt;/p&gt;
&lt;div id=&#34;scenario-1-independent-samples-with-2-known-variances-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 1: Independent samples with 2 known variances&lt;/h2&gt;
&lt;p&gt;For the first scenario, suppose the data below. Moreover, suppose that the two samples are independent, that the variances &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2 = 1\)&lt;/span&gt; in both populations and that we would like to test whether the two populations are different.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat1 &amp;lt;- data.frame(
  sample1 = c(0.9, -0.8, 0.1, -0.3, 0.2),
  sample2 = c(0.8, -0.9, -0.1, 0.4, 0.1)
)
dat1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   sample1 sample2
## 1     0.9     0.8
## 2    -0.8    -0.9
## 3     0.1    -0.1
## 4    -0.3     0.4
## 5     0.2     0.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_ggplot &amp;lt;- data.frame(
  value = c(0.9, -0.8, 0.1, -0.3, 0.2, 0.8, -0.9, -0.1, 0.4, 0.1),
  sample = c(rep(&amp;quot;1&amp;quot;, 5), rep(&amp;quot;2&amp;quot;, 5))
)

library(ggplot2)

ggplot(dat_ggplot) +
  aes(x = sample, y = value) +
  geom_boxplot() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that you can use the &lt;a href=&#34;/blog/rstudio-addins-or-how-to-make-your-coding-life-easier/#esquisse&#34;&gt;&lt;code&gt;{esquisse}&lt;/code&gt; RStudio addin&lt;/a&gt; if you want to draw a boxplot with the package &lt;code&gt;{ggplot2}&lt;/code&gt; without writing the code yourself. If you prefer the default graphics, use the &lt;code&gt;boxplot()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boxplot(value ~ sample,
  data = dat_ggplot
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The two boxes seem to overlap which illustrate that the two samples are quite similar, so we tend to believe that we will not be able to reject the null hypothesis that the two populations are similar. However, only a formal statistical test will confirm this belief.&lt;/p&gt;
&lt;p&gt;Since there is no function in R to perform a t-test with known variances, here is one with arguments accepting the two samples (&lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;), the two variances of the populations (&lt;code&gt;V1&lt;/code&gt; and &lt;code&gt;V2&lt;/code&gt;), the difference in means under the null hypothesis (&lt;code&gt;m0&lt;/code&gt;, default is &lt;code&gt;0&lt;/code&gt;), the significance level (&lt;code&gt;alpha&lt;/code&gt;, default is &lt;code&gt;0.05&lt;/code&gt;) and the alternative (&lt;code&gt;alternative&lt;/code&gt;, one of &lt;code&gt;&amp;quot;two.sided&amp;quot;&lt;/code&gt; (default), &lt;code&gt;&amp;quot;less&amp;quot;&lt;/code&gt; or &lt;code&gt;&amp;quot;greater&amp;quot;&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test_knownvar &amp;lt;- function(x, y, V1, V2, m0 = 0, alpha = 0.05, alternative = &amp;quot;two.sided&amp;quot;) {
  M1 &amp;lt;- mean(x)
  M2 &amp;lt;- mean(y)
  n1 &amp;lt;- length(x)
  n2 &amp;lt;- length(y)
  sigma1 &amp;lt;- sqrt(V1)
  sigma2 &amp;lt;- sqrt(V2)
  S &amp;lt;- sqrt((V1 / n1) + (V2 / n2))
  statistic &amp;lt;- (M1 - M2 - m0) / S
  p &amp;lt;- if (alternative == &amp;quot;two.sided&amp;quot;) {
    2 * pnorm(abs(statistic), lower.tail = FALSE)
  } else if (alternative == &amp;quot;less&amp;quot;) {
    pnorm(statistic, lower.tail = TRUE)
  } else {
    pnorm(statistic, lower.tail = FALSE)
  }
  LCL &amp;lt;- (M1 - M2 - S * qnorm(1 - alpha / 2))
  UCL &amp;lt;- (M1 - M2 + S * qnorm(1 - alpha / 2))
  value &amp;lt;- list(mean1 = M1, mean2 = M2, m0 = m0, sigma1 = sigma1, sigma2 = sigma2, S = S, statistic = statistic, p.value = p, LCL = LCL, UCL = UCL, alternative = alternative)
  # print(sprintf(&amp;quot;P-value = %g&amp;quot;,p))
  # print(sprintf(&amp;quot;Lower %.2f%% Confidence Limit = %g&amp;quot;,
  #               alpha, LCL))
  # print(sprintf(&amp;quot;Upper %.2f%% Confidence Limit = %g&amp;quot;,
  #               alpha, UCL))
  return(value)
}

test &amp;lt;- t.test_knownvar(dat1$sample1, dat1$sample2,
  V1 = 1, V2 = 1
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $mean1
## [1] 0.02
## 
## $mean2
## [1] 0.06
## 
## $m0
## [1] 0
## 
## $sigma1
## [1] 1
## 
## $sigma2
## [1] 1
## 
## $S
## [1] 0.6324555
## 
## $statistic
## [1] -0.06324555
## 
## $p.value
## [1] 0.949571
## 
## $LCL
## [1] -1.27959
## 
## $UCL
## [1] 1.19959
## 
## $alternative
## [1] &amp;quot;two.sided&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above recaps all the information needed to perform the test: the test statistic, the &lt;em&gt;p&lt;/em&gt;-value, the alternative used, the two sample means and the two variances of the populations (compare these results found in R with the results found by hand).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value can be extracted as usual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.949571&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.95 so at the 5% significance level we do not reject the null hypothesis of equal means. There is no sufficient evidence in the data to reject the hypothesis that the two means in the populations are similar. This result confirms what we found by hand.&lt;/p&gt;
&lt;div id=&#34;a-note-on-p-value-and-significance-level-alpha&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A note on &lt;em&gt;p&lt;/em&gt;-value and significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;For those unfamiliar with the concept of &lt;em&gt;p&lt;/em&gt;-value, the &lt;em&gt;p&lt;/em&gt;-value is a probability and as any probability it goes from 0 to 1. The &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;-value is the probability of having observations as extreme as what we measured (via the samples) if the null hypothesis was true&lt;/strong&gt;. In other words, it is the probability of having a test statistic as extreme as what we computed, given that the null hypothesis is true. If the observations are not so extreme, i.e., not unlikely to occur if the null hypothesis was true, we do not reject this null hypothesis because it is deemed plausible to be true. And if the observations are considered too extreme, i.e., too unlikely to happen under the null hypothesis, we reject the null hypothesis because it is deemed too implausible to be true. Note that it does not mean that we are 100% sure that it is too unlikely, it happens sometimes that the null hypothesis is rejected although it is true (see the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; later on).&lt;/p&gt;
&lt;p&gt;In our example above, the observations are not really extreme and the difference between the two means is not extreme, so the test statistic is not extreme (since the test statistic is partially based on the difference of the means of the two samples). Having a test statistic which is not extreme is not unlikely and that is the reason why the &lt;em&gt;p&lt;/em&gt;-value is quite high. The &lt;em&gt;p&lt;/em&gt;-value of 0.95 actually tells us that the probability of having two samples with a difference in means of -0.04 (= 0.02 - 0.06), given that the difference in means in the populations is 0 (the null hypothesis), equals 95%. A probability of 95% is definitely considered as plausible, so we do not reject the null hypothesis of equal means in the populations.&lt;/p&gt;
&lt;p&gt;One may then wonder, “What is too extreme for a test statistic?” Most of the time, we consider that a test statistic is too extreme to happen just by chance when the probability of having such an extreme test statistic given that the null hypothesis is true is below 5%. The threshold of 5% (&lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;) that you very often see in statistic courses or textbooks is the threshold used in many fields. With a &lt;em&gt;p&lt;/em&gt;-value under that threshold of 5%, we consider that the observations (and thus the test statistic) is &lt;strong&gt;too unlikely&lt;/strong&gt; to happen just by chance if the null hypothesis was true, so the null hypothesis is rejected. With a &lt;em&gt;p&lt;/em&gt;-value above that threshold of 5%, we consider that it is not really implausible to face the observations we have if the null hypothesis was true, and we therefore do not reject the null hypothesis.&lt;/p&gt;
&lt;p&gt;Note that I wrote “we do not reject the null hypothesis”, and not “we accept the null hypothesis”. This is because it may be the case that the null hypothesis is in fact false, but we failed to prove it with the samples. Suppose the analogy of a suspect accused of murder and we do not know the truth. On the one hand, if we have collected enough evidence that the suspect committed the murder, he is considered guilty: we reject the null hypothesis that he is innocent. On the other hand, if we have &lt;em&gt;not&lt;/em&gt; collected enough evidence against the suspect, he is presumed to be innocent although he may in fact have committed the crime: we failed to reject the null hypothesis of him being innocent. We are never sure that he did not committed the crime even if he is released, we just did not find sufficient evidence against the null hypothesis of the suspect being innocent. This is the reason why we do not reject the null hypothesis instead of accepting it, and why you will often read things like “there is no sufficient evidence in the data to reject the null hypothesis” or “based on the samples we fail to reject the null hypothesis”.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;&lt;/strong&gt;, derived from the threshold of 5% mentioned earlier, &lt;strong&gt;is the probability of rejecting the null hypothesis when it is in fact true&lt;/strong&gt;. In this sense, it is an error (of 5%) that we accept to deal with, in order to be able to draw conclusions. If we would accept no error (an error of 0%), we would not be able to draw any conclusion about the population(s) since we only have access to a limited portion of the population(s) via the sample(s). As a consequence, we will never be 100% sure when interpreting the result of a hypothesis test unless we have access to the data for the entire population, but then there is no reason to do a hypothesis test anymore since we can simply compare the two populations. We usually allow this error (called Type I error) to be 5%, but in order to be a bit more certain when concluding that we reject the null hypothesis, the alpha level can also be set to 1% (or even to 0.1% in some rare cases).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;To sum up&lt;/strong&gt; what you need to remember about &lt;em&gt;p&lt;/em&gt;-value and significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the &lt;em&gt;p&lt;/em&gt;-value is smaller than the predetermined significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; (usually 5%) so if &lt;em&gt;p&lt;/em&gt;-value &amp;lt; 0.05, we reject the null hypothesis&lt;/li&gt;
&lt;li&gt;If the &lt;em&gt;p&lt;/em&gt;-value is greater than or equal to the predetermined significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; (usually 5%) so if &lt;em&gt;p&lt;/em&gt;-value &lt;span class=&#34;math inline&#34;&gt;\(\ge\)&lt;/span&gt; 0.05, we do &lt;strong&gt;not reject&lt;/strong&gt; the null hypothesis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This applies to all statistical tests without exception. Of course, the null and alternative hypotheses change depending on the test.&lt;/p&gt;
&lt;p&gt;A rule of thumb is that, for most hypothesis tests, the alternative hypothesis is what you want to test and the null hypothesis is the status quo. Take this with extreme caution (!) because, even if it works for all versions of the Student’s t-test it does not apply to ALL statistical tests. For example, when testing for normality, you usually want to test whether your distribution follows a normal distribution. Following this piece of advice, you would write the alternative hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_1:\)&lt;/span&gt; the distribution follows a normal distribution. Nonetheless, for &lt;a href=&#34;/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/#normality-test&#34;&gt;normality tests&lt;/a&gt; such as the Shapiro-Wilk or Kolmogorov-Smirnov test, it is the opposite; the alternative hypothesis is &lt;span class=&#34;math inline&#34;&gt;\(H_1:\)&lt;/span&gt; the distribution does not follow a normal distribution. So for every test, make sure to use the correct hypotheses, otherwise the conclusion and interpretation of your test will be wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-2-independent-samples-with-2-equal-but-unknown-variances-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 2: Independent samples with 2 equal but unknown variances&lt;/h2&gt;
&lt;p&gt;For the second scenario, suppose the data below. Moreover, suppose that the two samples are independent, that the variances in both populations are unknown but equal (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_1 = \sigma^2_1\)&lt;/span&gt;) and that we would like to test whether population 1 is larger than population 2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat2 &amp;lt;- data.frame(
  sample1 = c(1.78, 1.5, 0.9, 0.6, 0.8, 1.9),
  sample2 = c(0.8, -0.7, -0.1, 0.4, 0.1, NA)
)
dat2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   sample1 sample2
## 1    1.78     0.8
## 2    1.50    -0.7
## 3    0.90    -0.1
## 4    0.60     0.4
## 5    0.80     0.1
## 6    1.90      NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat_ggplot &amp;lt;- data.frame(
  value = c(1.78, 1.5, 0.9, 0.6, 0.8, 1.9, 0.8, -0.7, -0.1, 0.4, 0.1),
  sample = c(rep(&amp;quot;1&amp;quot;, 6), rep(&amp;quot;2&amp;quot;, 5))
)

ggplot(dat_ggplot) +
  aes(x = sample, y = value) +
  geom_boxplot() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Unlike the previous scenario, the two boxes do not overlap which illustrates that the two samples are different from each other. From this boxplot, we can expect the test to reject the null hypothesis of equal means in the populations. Nonetheless, only a formal statistical test will confirm this expectation.&lt;/p&gt;
&lt;p&gt;There is a function in R, and it is simply the &lt;code&gt;t.test()&lt;/code&gt; function. This version of the test is actually the “standard” Student’s t-test for two samples. Note that it is assumed that the variances of the two populations are equal so we need to specify it in the function with the argument &lt;code&gt;var.equal = TRUE&lt;/code&gt; (the default is &lt;code&gt;FALSE&lt;/code&gt;) and the alternative hypothesis is &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_1 - \mu_2 &amp;gt; 0\)&lt;/span&gt; so we need to add the argument &lt;code&gt;alternative = &amp;quot;greater&amp;quot;&lt;/code&gt; as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- t.test(dat2$sample1, dat2$sample2,
  var.equal = TRUE, alternative = &amp;quot;greater&amp;quot;
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Two Sample t-test
## 
## data:  dat2$sample1 and dat2$sample2
## t = 3.4113, df = 9, p-value = 0.003867
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.5304908       Inf
## sample estimates:
## mean of x mean of y 
##  1.246667  0.100000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above recaps all the information needed to perform the test: the name of the test, the test statistic, the degrees of freedom, the &lt;em&gt;p&lt;/em&gt;-value, the alternative used and the two sample means (compare these results found in R with the results found by hand).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value can be extracted as usual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.003866756&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.004 so at the 5% significance level we reject the null hypothesis of equal means. This result confirms what we found by hand.&lt;/p&gt;
&lt;p&gt;Unlike the first scenario, the &lt;em&gt;p&lt;/em&gt;-value in this scenario is below 5% so we reject the null hypothesis. At the 5% significance level, we can conclude that the population 1 is larger than the population 2.&lt;/p&gt;
&lt;p&gt;If your data is formatted in the long format (which is even better), simply use the &lt;code&gt;~&lt;/code&gt;. For instance, imagine the exact same data presented like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat2bis &amp;lt;- data.frame(
  value = c(1.78, 1.5, 0.9, 0.6, 0.8, 1.9, 0.8, -0.7, -0.1, 0.4, 0.1),
  sample = c(rep(&amp;quot;1&amp;quot;, 6), rep(&amp;quot;2&amp;quot;, 5))
)
dat2bis&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    value sample
## 1   1.78      1
## 2   1.50      1
## 3   0.90      1
## 4   0.60      1
## 5   0.80      1
## 6   1.90      1
## 7   0.80      2
## 8  -0.70      2
## 9  -0.10      2
## 10  0.40      2
## 11  0.10      2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is how to perform the Student’s t-test in R with long data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- t.test(value ~ sample,
  data = dat2bis,
  var.equal = TRUE,
  alternative = &amp;quot;greater&amp;quot;
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Two Sample t-test
## 
## data:  value by sample
## t = 3.4113, df = 9, p-value = 0.003867
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  0.5304908       Inf
## sample estimates:
## mean in group 1 mean in group 2 
##        1.246667        0.100000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.003866756&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results are exactly the same.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-3-independent-samples-with-2-unequal-and-unknown-variances-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 3: Independent samples with 2 unequal and unknown variances&lt;/h2&gt;
&lt;p&gt;For the third scenario, suppose the data below. Moreover, suppose that the two samples are independent, that the variances in both populations are unknown and unequal (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_1 \ne \sigma^2_1\)&lt;/span&gt;) and that we would like to test whether population 1 is smaller than population 2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat3 &amp;lt;- data.frame(
  value = c(0.8, 0.7, 0.1, 0.4, 0.1, 1.78, 1.5, 0.9, 0.6, 0.8, 1.9),
  sample = c(rep(&amp;quot;1&amp;quot;, 5), rep(&amp;quot;2&amp;quot;, 6))
)
dat3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    value sample
## 1   0.80      1
## 2   0.70      1
## 3   0.10      1
## 4   0.40      1
## 5   0.10      1
## 6   1.78      2
## 7   1.50      2
## 8   0.90      2
## 9   0.60      2
## 10  0.80      2
## 11  1.90      2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat3) +
  aes(x = sample, y = value) +
  geom_boxplot() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is a function in R for this version of the test as well, and it is simply the &lt;code&gt;t.test()&lt;/code&gt; function with the &lt;code&gt;var.equal = FALSE&lt;/code&gt; argument. &lt;code&gt;FALSE&lt;/code&gt; is the default option for the &lt;code&gt;var.equal&lt;/code&gt; argument so you actually do not need to specify it. This version of the test is actually the Welch test, used when the variances of the populations are unknown and unequal. To test if two variances are equal, you can use the Levene’s test (&lt;code&gt;leveneTest(dat3$value, dat3$sample)&lt;/code&gt; from the &lt;code&gt;{car}&lt;/code&gt; package). Note that the alternative hypothesis is &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_1 - \mu_2 &amp;lt; 0\)&lt;/span&gt; so we need to add the argument &lt;code&gt;alternative = &amp;quot;less&amp;quot;&lt;/code&gt; as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- t.test(value ~ sample,
  data = dat3,
  var.equal = FALSE,
  alternative = &amp;quot;less&amp;quot;
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  value by sample
## t = -3.0841, df = 8.2796, p-value = 0.007206
## alternative hypothesis: true difference in means is less than 0
## 95 percent confidence interval:
##        -Inf -0.3304098
## sample estimates:
## mean in group 1 mean in group 2 
##        0.420000        1.246667&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above recaps all the information needed to perform the test (compare these results found in R with the results found by hand).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value can be extracted as usual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.00720603&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.007 so at the 5% significance level we reject the null hypothesis of equal means, meaning that we can conclude that the population 1 is smaller than the population 2. This result confirms what we found by hand.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-4-paired-samples-where-the-variance-of-the-differences-is-known-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 4: Paired samples where the variance of the differences is known&lt;/h2&gt;
&lt;p&gt;For the fourth scenario, suppose the data below. Moreover, suppose that the two samples are dependent (matched), that the variance of the differences in the population is known and equal to 1 (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_D = 1\)&lt;/span&gt;) and that we would like to test whether the difference in the population is different than 0.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat4 &amp;lt;- data.frame(
  before = c(0.9, -0.8, 0.1, -0.3, 0.2),
  after = c(0.8, -0.9, -0.1, 0.4, 0.1)
)
dat4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   before after
## 1    0.9   0.8
## 2   -0.8  -0.9
## 3    0.1  -0.1
## 4   -0.3   0.4
## 5    0.2   0.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat4$difference &amp;lt;- dat4$after - dat4$before

ggplot(dat4) +
  aes(y = difference) +
  geom_boxplot() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Since there is no function in R to perform a t-test with paired samples where the variance of the differences is known, here is one with arguments accepting the differences between the two samples (&lt;code&gt;x&lt;/code&gt;), the variance of the differences in the population (&lt;code&gt;V&lt;/code&gt;), the mean of the differences under the null hypothesis (&lt;code&gt;m0&lt;/code&gt;, default is &lt;code&gt;0&lt;/code&gt;), the significance level (&lt;code&gt;alpha&lt;/code&gt;, default is &lt;code&gt;0.05&lt;/code&gt;) and the alternative (&lt;code&gt;alternative&lt;/code&gt;, one of &lt;code&gt;&amp;quot;two.sided&amp;quot;&lt;/code&gt; (default), &lt;code&gt;&amp;quot;less&amp;quot;&lt;/code&gt; or &lt;code&gt;&amp;quot;greater&amp;quot;&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test_pairedknownvar &amp;lt;- function(x, V, m0 = 0, alpha = 0.05, alternative = &amp;quot;two.sided&amp;quot;) {
  M &amp;lt;- mean(x)
  n &amp;lt;- length(x)
  sigma &amp;lt;- sqrt(V)
  S &amp;lt;- sqrt(V / n)
  statistic &amp;lt;- (M - m0) / S
  p &amp;lt;- if (alternative == &amp;quot;two.sided&amp;quot;) {
    2 * pnorm(abs(statistic), lower.tail = FALSE)
  } else if (alternative == &amp;quot;less&amp;quot;) {
    pnorm(statistic, lower.tail = TRUE)
  } else {
    pnorm(statistic, lower.tail = FALSE)
  }
  LCL &amp;lt;- (M - S * qnorm(1 - alpha / 2))
  UCL &amp;lt;- (M + S * qnorm(1 - alpha / 2))
  value &amp;lt;- list(mean = M, m0 = m0, sigma = sigma, statistic = statistic, p.value = p, LCL = LCL, UCL = UCL, alternative = alternative)
  # print(sprintf(&amp;quot;P-value = %g&amp;quot;,p))
  # print(sprintf(&amp;quot;Lower %.2f%% Confidence Limit = %g&amp;quot;,
  #               alpha, LCL))
  # print(sprintf(&amp;quot;Upper %.2f%% Confidence Limit = %g&amp;quot;,
  #               alpha, UCL))
  return(value)
}

test &amp;lt;- t.test_pairedknownvar(dat4$after - dat4$before,
  V = 1
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $mean
## [1] 0.04
## 
## $m0
## [1] 0
## 
## $sigma
## [1] 1
## 
## $statistic
## [1] 0.08944272
## 
## $p.value
## [1] 0.9287301
## 
## $LCL
## [1] -0.8365225
## 
## $UCL
## [1] 0.9165225
## 
## $alternative
## [1] &amp;quot;two.sided&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above recaps all the information needed to perform the test (compare these results found in R with the results found by hand).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value can be extracted as usual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9287301&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.929 so at the 5% significance level we do not reject the null hypothesis of the mean of the differences being equal to 0. There is no sufficient evidence in the data to reject the hypothesis that the difference in the two populations is equal to 0. This result confirms what we found by hand.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scenario-5-paired-samples-where-the-variance-of-the-differences-is-unknown-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario 5: Paired samples where the variance of the differences is unknown&lt;/h2&gt;
&lt;p&gt;For the fifth and final scenario, suppose the data below. Moreover, suppose that the two samples are dependent (matched), that the variance of the differences in the population is unknown and that we would like to test whether a treatment is effective in increasing running capabilities (the higher the value, the better in terms of running capabilities).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat5 &amp;lt;- data.frame(
  before = c(9, 8, 1, 3, 2),
  after = c(16, 11, 15, 12, 9)
)
dat5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   before after
## 1      9    16
## 2      8    11
## 3      1    15
## 4      3    12
## 5      2     9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat5$difference &amp;lt;- dat5$after - dat5$before

ggplot(dat5) +
  aes(y = difference) +
  geom_boxplot() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is a function in R for this version of the test, and it is simply the &lt;code&gt;t.test()&lt;/code&gt; function with the &lt;code&gt;paired = TRUE&lt;/code&gt; argument. This version of the test is actually the standard version of the Student’s t-test with paired samples. Note that the alternative hypothesis is &lt;span class=&#34;math inline&#34;&gt;\(H_1: \mu_D &amp;gt; 0\)&lt;/span&gt; so we need to add the argument &lt;code&gt;alternative = &amp;quot;greater&amp;quot;&lt;/code&gt; as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- t.test(dat5$after, dat5$before,
  alternative = &amp;quot;greater&amp;quot;,
  paired = TRUE
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Paired t-test
## 
## data:  dat5$after and dat5$before
## t = 4.4721, df = 4, p-value = 0.005528
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  4.186437      Inf
## sample estimates:
## mean of the differences 
##                       8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we wrote &lt;code&gt;after&lt;/code&gt; and then &lt;code&gt;before&lt;/code&gt; in this order. If you write &lt;code&gt;before&lt;/code&gt; and then &lt;code&gt;after&lt;/code&gt;, make sure to change the alternative to &lt;code&gt;alternative = &amp;quot;less&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If your data is in the long format, use the &lt;code&gt;~&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat5 &amp;lt;- data.frame(
  value = c(9, 8, 1, 3, 2, 16, 11, 15, 12, 9),
  time = c(rep(&amp;quot;before&amp;quot;, 5), rep(&amp;quot;after&amp;quot;, 5))
)
dat5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    value   time
## 1      9 before
## 2      8 before
## 3      1 before
## 4      3 before
## 5      2 before
## 6     16  after
## 7     11  after
## 8     15  after
## 9     12  after
## 10     9  after&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- t.test(value ~ time,
  data = dat5,
  alternative = &amp;quot;greater&amp;quot;,
  paired = TRUE
)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Paired t-test
## 
## data:  value by time
## t = 4.4721, df = 4, p-value = 0.005528
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  4.186437      Inf
## sample estimates:
## mean of the differences 
##                       8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output above recaps all the information needed to perform the test (compare these results found in R with the results found by hand).&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value can be extracted as usual:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.005528247&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is 0.006 so at the 5% significance level we reject the null hypothesis of the mean of the differences being equal to 0, meaning that we can conclude that the treatment is effective in increasing the running capabilities. This result confirms what we found by hand.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;assumptions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Assumptions&lt;/h1&gt;
&lt;p&gt;As for many statistical tests, there are some assumptions that need to be met in order to be able to interpret the results. When one or several assumptions are not met, although it is technically possible to perform these tests, it would be incorrect to interpret the results. Below are the assumptions of the Student’s t-test for two samples, how to test them and which other tests exist if an assumption is not met:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The data, collected from a representative and randomly selected portion of the total population, should be independent. If observations between the two samples are dependent (for example if two measurements have been collected on the &lt;strong&gt;same individual&lt;/strong&gt; as it is often the case in medical studies when measuring a value after and before a treatment), the paired version of the Student’s t-test, called the Student’s t-test for paired samples, should be preferred in order to take into account the dependency between the two groups to be compared.&lt;/li&gt;
&lt;li&gt;When the two samples are independent, observations in &lt;strong&gt;both samples&lt;/strong&gt; should follow a &lt;a href=&#34;/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/&#34;&gt;&lt;strong&gt;normal distribution&lt;/strong&gt;&lt;/a&gt;. When using the Student’s t-test for paired samples, it is the difference between the observations of the two samples that should follow a normal distribution. The normality assumption can be tested visually thanks to a histogram and a QQ-plot, and/or formally via a normality test such as the Shapiro-Wilk or Kolmogorov-Smirnov test (see more information about the normality assumption and how to test it &lt;a href=&#34;/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/#how-to-test-the-normality-assumption&#34;&gt;here&lt;/a&gt;). If, even after a transformation (logarithmic transformation, etc.), your data still do not follow a normal distribution, the Wilcoxon test (&lt;code&gt;wilcox.test(variable1 ~ variable2, data = dat&lt;/code&gt; in R) can be applied. This test, robust to non normal distributions, compares the medians instead of the means in order to compare the two populations.&lt;/li&gt;
&lt;li&gt;When the two samples are independent, the variances of the two groups should be equal in the populations (an assumption called homogeneity of the variances, or even sometimes referred as homoscedasticity, as opposed to heteroscedasticity). This assumption can be tested thanks to the Levene’s test (&lt;code&gt;leveneTest(variable ~ group)&lt;/code&gt; from the &lt;code&gt;{car}&lt;/code&gt; package) or via a F test (&lt;code&gt;var.test(variable ~ group)&lt;/code&gt;). If the hypothesis of equal variances is rejected, another version of the Student’s t-test can be used: the Welch test (&lt;code&gt;t.test(variable ~ group, var.equal = FALSE)&lt;/code&gt;). Note that the Welch test does not require homogeneity of the variances, but the distributions should still follow a normal distribution. If your distributions are not normally distributed and the variances are unequal, the Wilcoxon test should be used. This test does not require normality or homoscedasticity of the variances.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This concludes a relatively long article. Thanks for reading it. I hope this article helped you to understand how the different versions of the Student’s t-test for two samples work and how to perform them by hand and in R. If you are interested, here is a &lt;a href=&#34;/blog/a-shiny-app-for-inferential-statistics-by-hand/&#34;&gt;Shiny app&lt;/a&gt; to perform these tests by hand easily (you just need to enter your data and select the appropriate version of the test thanks to the sidebar menu). Moreover, read &lt;a href=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r-test-on-one-mean/&#34;&gt;this article&lt;/a&gt; if you would like to know how to compute the Student’s t-test but this time, for one sample.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-rowntree2000statistics&#34;&gt;
&lt;p&gt;Rowntree, Derek. 2000. &lt;em&gt;Statistics Without Tears&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Remind that inferential statistics, as opposed to &lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;descriptive statistics&lt;/a&gt;, is a branch of statistics defined as the science of drawing conclusions about a population from observations made on a representative sample of that population. See the &lt;a href=&#34;/blog/what-is-the-difference-between-population-and-sample/&#34;&gt;difference between population and sample&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;For the rest of the present article, when we write Student’s t-test, we refer to the case of 2 samples. See &lt;a href=&#34;/blog/how-to-perform-a-one-sample-t-test-by-hand-and-in-r-test-on-one-mean/&#34;&gt;one sample t-test&lt;/a&gt; if you want to compare only one sample.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;It is a least the case for parametric hypothesis tests. A parametric test means that it is based on a theoretical statistical distribution, which depends on some defined parameters. In the case of the Student’s t-test for two samples, it is based on the Student’s t distribution with a single parameter, the degrees of freedom (&lt;span class=&#34;math inline&#34;&gt;\(df = n_1 + n_2 - 2\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(n_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n_2\)&lt;/span&gt; are the two sample sizes), or the normal distribution.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Inferential statistics: confidence intervals and hypothesis tests explained in 4 easy steps</title>
      <link>/blog/inferential-statistics-confidence-intervals-and-hypothesis-tests-explained-in-4-easy-steps/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/inferential-statistics-confidence-intervals-and-hypothesis-tests-explained-in-4-easy-steps/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hypothesis-tests-and-confidence-intervals-why-and-when&#34;&gt;Hypothesis tests and confidence intervals: why and when?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;xxx add image and put the link in the YAML&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Remember that &lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;descriptive statistics&lt;/a&gt; is a branch of statistics aiming at describing and summarizing a set of data in the best possible manner, that is, by reducing them down to a few meaningful key measures and visualizations (with as little loss of information as possible). In other words, descriptive statistics helps to have a better understanding and a clear image about a set of observations thanks to summary statistics and graphics. With descriptive statistics, there is no uncertainty because we describe only the group of observations that we decided to work on and no attempt is made to generalize the observed characteristics to another or to a larger group of observations.&lt;/p&gt;
&lt;p&gt;Inferential statistics is another branch of statistics that uses a random sample of data taken from a population to make inferences, i.e., to draw conclusions about the population (see the &lt;a href=&#34;/blog/what-is-the-difference-between-population-and-sample/&#34;&gt;difference between population and sample&lt;/a&gt;). In other words, information from the sample is used to make generalizations about the parameter of interest in the population. Inferential statistics includes two important tools: hypothesis tests and confidence intervals.&lt;/p&gt;
&lt;p&gt;As part of my teaching assistant position, I quickly realized that students often struggle to compute confidence intervals, perform hypothesis tests and interpret the results. It seems to me that students often encounter difficulties because this branch of statistics is rather unclear and abstract to them. I believe the main reason why it looks abstract to them is because they do not understand the final goal of inferential statistics, that is, the why behind these tools. They often perform hypothesis tests and confidence intervals by simply following the steps presented in another example whitout understanding the reasoning behind it, as they would follow a cooking recipe because they must prepare food, but not because they actually want to prepare &lt;em&gt;good&lt;/em&gt; food.&lt;/p&gt;
&lt;p&gt;For this reason, I though it would be useful to write an article on the goal of hypothesis tests and confidence intervals (the why), in which context they should be used (the when), how they work (in 4 easy steps) and how to interpret the results (as statistical results are meaningless without proper interpretation). Like anything else in statistics, it becomes much easier when we understand what we are trying to demonstrate before knowing how to compute it.&lt;/p&gt;
&lt;p&gt;Inferential statistics can be applied to many parameters. Nonetheless, in order to keep this article easy and accessible to people from diverse backgrounds, I focus on hypothesis tests and confidences intervals applied to the 3 main parameters: &lt;strong&gt;mean, proportion and variance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If you are familiar with these two tools, below are 3 articles that may be of interest to you:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/blog/xxx/&#34;&gt;Hypothesis tests and confidence intervals for one and two means (independent and paired samples)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/blog/xxx/&#34;&gt;Hypothesis tests and confidence intervals for one and two proportions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;/blog/xxx/&#34;&gt;Hypothesis tests and confidence intervals for one and two variances&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The 3 articles above focus on the practical application of the two tools of inferential statistics by hand and in R. The present article covers the same topic but from a theoritical perspective in order to lay the foundations of hypothesis testing and confidence interval, with a special focus on the understanding and the reasoning behind the tools. I believe that grasping the concepts behind these tools from a theoritical perspective is of great help when applying them in practice.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hypothesis-tests-and-confidence-intervals-why-and-when&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hypothesis tests and confidence intervals: why and when?&lt;/h1&gt;
&lt;p&gt;Unlike descriptive statistics where we have describe only the data at hand, hypothesis tests and confidence intervals use a subset of observations (a sample) to draw conclusions about the population.&lt;/p&gt;
&lt;p&gt;One may wonder why we would try to “guess” a parameter of a population based on a sample, instead of simply collecting the data for the entire population and compute the statistics we are interested in. The main reason why we actually use a sample instead of the population is because most of the time collecting the data on the entire population is impossible, too complex, too expensive, it would take too long, or a combination of any of these reasons. Suppose a researcher wants to test if Belgian women are taller than French women. Suppose a health professional would like to know whether the proportion of smokers is the same among athletes and non-athletes. It would take way too long to measure the height of all Belgian and French women and to ask all athletes and non-athletes if they smoke or not.
For these reasons, we simply xxx&lt;/p&gt;
&lt;p&gt;Thanks for reading. I hope this article helped you to understand better how to perform hypothesis tests and construct confidence intervals by hand.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fisher&#39;s exact test in R: independence test for a small sample</title>
      <link>/blog/fisher-s-exact-test-in-r-independence-test-for-a-small-sample/</link>
      <pubDate>Tue, 28 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/fisher-s-exact-test-in-r-independence-test-for-a-small-sample/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hypotheses&#34;&gt;Hypotheses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example&#34;&gt;Example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#observed-frequencies&#34;&gt;Observed frequencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#expected-frequencies&#34;&gt;Expected frequencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#fishers-exact-test-in-r&#34;&gt;Fisher’s exact test in R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion-and-interpretation&#34;&gt;Conclusion and interpretation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/blog/fisher-s-exact-test-in-r-independence-test-for-a-small-sample_files/0_73Z2pBxY4UbGaVXz.jpeg&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;After presenting the &lt;a href=&#34;/blog/chi-square-test-of-independence-by-hand/&#34;&gt;Chi-square test of independence by hand&lt;/a&gt; and &lt;a href=&#34;/blog/chi-square-test-of-independence-in-r/&#34;&gt;in R&lt;/a&gt;, this article focuses on the Fisher’s exact test.&lt;/p&gt;
&lt;p&gt;Independence tests are used to determine if there is a significant relationship between two categorical variables. There exists two different types of independence test:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the Chi-square test (the most common)&lt;/li&gt;
&lt;li&gt;the Fisher’s exact test&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On the one hand, the Chi-square test is used when the sample is large enough (in this case the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is an approximation that becomes exact when the sample becomes infinite, which is the case for many statistical tests). On the other hand, the Fisher’s exact test is used when the sample is small (and in this case the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is exact and is not an approximation).&lt;/p&gt;
&lt;p&gt;The literature indicates that the usual rule for deciding whether the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; approximation is good enough is that the Chi-square test is not appropriate when the &lt;strong&gt;expected&lt;/strong&gt; values in one of the cells of the contingency table is less than 5, and in this case the Fisher’s exact test is preferred &lt;span class=&#34;citation&#34;&gt;(McCrum-Gardner 2008; Bower 2003)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hypotheses&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hypotheses&lt;/h1&gt;
&lt;p&gt;The hypotheses of the Fisher’s exact test are the same than for the Chi-square test, that is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; : the variables are independent, there is &lt;strong&gt;no&lt;/strong&gt; relationship between the two categorical variables. Knowing the value of one variable does not help to predict the value of the other variable&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; : the variables are dependent, there is a relationship between the two categorical variables. Knowing the value of one variable helps to predict the value of the other variable&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;For our example, we want to determine whether there is a statistically significant association between smoking and being a professional athlete. Smoking can only be “yes” or “no” and being a professional athlete can only be “yes” or “no”. The two variables of interest are qualitative variables and we collected data on 14 persons.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;observed-frequencies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Observed frequencies&lt;/h2&gt;
&lt;p&gt;Our data are summarized in the contingency table below reporting the number of people in each subgroup:&lt;/p&gt;
&lt;table style=&#34;width:56%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;25%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt; &lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Non-smoker&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Smoker&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Athlete&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Non-athlete&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;expected-frequencies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Expected frequencies&lt;/h2&gt;
&lt;p&gt;Remember that the Fisher’s exact test is used when there is at least one cell in the contingency table of the expected frequencies below 5. To retrieve the expected frequencies, use the &lt;code&gt;chisq.test()&lt;/code&gt; function together with &lt;code&gt;$expected&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;chisq.test(dat)$expected&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in chisq.test(dat): Chi-squared approximation may be incorrect&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Non-smoker Smoker
## Athlete            4.5    4.5
## Non-athlete        2.5    2.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The contingency table above confirms that we should use the Fisher’s exact test instead of the Chi-square test because there is at least one cell below 5.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tip&lt;/em&gt;: although it is a good practice to check the expected frequencies &lt;strong&gt;before&lt;/strong&gt; deciding between the Chi-square and the Fisher test, it is not a big issue if you forget. As you can see above, when doing the Chi-square test in R (with &lt;code&gt;chisq.test()&lt;/code&gt;), a warning such as “Chi-squared approximation may be incorrect” will appear. This warning means that the smallest expected frequencies is lower than 5. Therefore, do not worry if you forgot to check the expected frequencies before applying the appropriate test to your data, R will warn you that you should use the Fisher’s exact test instead of the Chi-square test if that is the case.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fishers-exact-test-in-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fisher’s exact test in R&lt;/h2&gt;
&lt;p&gt;To perform the Fisher’s exact test in R, use the &lt;code&gt;fisher.test()&lt;/code&gt; function as you would do for the Chi-square test:&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- fisher.test(dat)
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Fisher&amp;#39;s Exact Test for Count Data
## 
## data:  dat
## p-value = 0.02098
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  1.449481      Inf
## sample estimates:
## odds ratio 
##        Inf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The most important in the output is the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value. You can also retrieve the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02097902&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion-and-interpretation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion and interpretation&lt;/h2&gt;
&lt;p&gt;From the output and from &lt;code&gt;test$p.value&lt;/code&gt; we see that the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is less than the significance level of 5%. Like any other statistical test, if the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is less than the significance level, we can reject the null hypothesis. If you are not familiar with &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values, I invite you to read this &lt;a href=&#34;https://www.statsandr.com/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/#a-note-on-p-value-and-significance-level-alpha&#34;&gt;section&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow\)&lt;/span&gt; In our context, rejecting the null hypothesis for the Fisher’s exact test of independence means that there is a significant relationship between the two categorical variables (smoking habits and being an athlete or not). Therefore, knowing the value of one variable helps to predict the value of the other variable.&lt;/p&gt;
&lt;p&gt;Thanks for reading. I hope the article helped you to perform the Fisher’s exact test of independence in R and interpret its results. Learn more about the Chi-square test of independence &lt;a href=&#34;/blog/chi-square-test-of-independence-by-hand/&#34;&gt;by hand&lt;/a&gt; or &lt;a href=&#34;/blog/chi-square-test-of-independence-in-r/&#34;&gt;in R&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-bower2003use&#34;&gt;
&lt;p&gt;Bower, Keith M. 2003. “When to Use Fisher’s Exact Test.” In &lt;em&gt;American Society for Quality, Six Sigma Forum Magazine&lt;/em&gt;, 2:35–37. 4.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mccrum2008correct&#34;&gt;
&lt;p&gt;McCrum-Gardner, Evie. 2008. “Which Is the Correct Statistical Test to Use?” &lt;em&gt;British Journal of Oral and Maxillofacial Surgery&lt;/em&gt; 46 (1). Elsevier: 38–41.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The data are the same than for the article covering the &lt;a href=&#34;/blog/chi-square-test-of-independence-by-hand/&#34;&gt;Chi-square test by hand&lt;/a&gt;, except that some observations have been removed to decrease the sample size.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Use &lt;code&gt;fisher.test(table(dat$variable1, dat$variable2))&lt;/code&gt; if &lt;code&gt;dat&lt;/code&gt; represents the raw data and is not already presented as a contingency table.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chi-square test of independence by hand</title>
      <link>/blog/chi-square-test-of-independence-by-hand/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/chi-square-test-of-independence-by-hand/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hypotheses&#34;&gt;Hypotheses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#how-the-test-works&#34;&gt;How the test works?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example&#34;&gt;Example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#observed-frequencies&#34;&gt;Observed frequencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#expected-frequencies&#34;&gt;Expected frequencies&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#test-statistic&#34;&gt;Test statistic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#critical-value&#34;&gt;Critical value&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion-and-interpretation&#34;&gt;Conclusion and interpretation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/blog/chi-square-test-of-independence-by-hand_files/chi-square-test-of-independence-by-hand.jpeg&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Chi-square tests of independence test whether two &lt;a href=&#34;/blog/variable-types-and-examples/#qualitative&#34;&gt;qualitative variables&lt;/a&gt; are independent, that is, whether there exists a relationship between two categorical variables. In other words, this test is used to determine whether the values of one of the 2 qualitative variables depend on the values of the other qualitative variable.&lt;/p&gt;
&lt;p&gt;If the test shows no association between the two variables (i.e., the variables are independent), it means that knowing the value of one variable gives no information about the value of the other variable. On the contrary, if the test shows a relationship between the variables (i.e., the variables are dependent), it means that knowing the value of one variable provides information about the value of the other variable.&lt;/p&gt;
&lt;p&gt;This article focuses on how to perform a Chi-square test of independence by hand and how to interpret the results with a concrete example. To learn how to do this test in R, read the article “&lt;a href=&#34;/blog/chi-square-test-of-independence-in-r/&#34;&gt;Chi-square test of independence in R&lt;/a&gt;”.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hypotheses&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hypotheses&lt;/h1&gt;
&lt;p&gt;The Chi-square test of independence is a hypothesis test so it has a null (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) and an alternative hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; : the variables are independent, there is &lt;strong&gt;no&lt;/strong&gt; relationship between the two categorical variables. Knowing the value of one variable does not help to predict the value of the other variable&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; : the variables are dependent, there is a relationship between the two categorical variables. Knowing the value of one variable helps to predict the value of the other variable&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;how-the-test-works&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How the test works?&lt;/h1&gt;
&lt;p&gt;The Chi-square test of independence works by comparing the observed frequencies (so the frequencies observed in your sample) to the expected frequencies if there was no relationship between the two categorical variables (so the expected frequencies if the null hypothesis was true).&lt;/p&gt;
&lt;p&gt;If the difference between the observed frequencies and the expected frequencies is &lt;strong&gt;small&lt;/strong&gt;, we cannot reject the null hypothesis of independence and thus we cannot reject the fact that the two &lt;strong&gt;variables are not related&lt;/strong&gt;. On the other hand, if the difference between the observed frequencies and the expected frequencies is &lt;strong&gt;large&lt;/strong&gt;, we can reject the null hypothesis of independence and thus we can conclude that the two &lt;strong&gt;variables are related&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The threshold between a small and large difference is a value that comes from the Chi-square distribution (hence the name of the test). This value, referred as the critical value, depends on the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; (usually set equal to 5%) and on the degrees of freedom. This critical value can be found in the statistical table of the Chi-square distribution. More on this critical value and the degrees of freedom later in the article.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example&lt;/h1&gt;
&lt;p&gt;For our example, we want to determine whether there is a statistically significant association between smoking and being a professional athlete. Smoking can only be “yes” or “no” and being a professional athlete can only be “yes” or “no”. The two variables of interest are qualitative variables so we need to use a Chi-square test of independence, and the data have been collected on 28 persons.&lt;/p&gt;
&lt;p&gt;Note that we chose binary variables (binary variables = qualitative variables with two levels) for the sake of easiness, but the Chi-square test of independence can also be performed on qualitative variables with more than two levels. For instance, if the variable smoking had three levels: (i) non-smokers, (ii) moderate smokers and (iii) heavy smokers, the steps and the interpretation of the results of the test are similar than with two levels.&lt;/p&gt;
&lt;div id=&#34;observed-frequencies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Observed frequencies&lt;/h2&gt;
&lt;p&gt;Our data are summarized in the contingency table below reporting the number of people in each subgroup, totals by row, by column and the grand total:&lt;/p&gt;
&lt;table style=&#34;width:68%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;25%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;col width=&#34;12%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt; &lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Non-smoker&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Smoker&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Total&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Athlete&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Non-athlete&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Total&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;expected-frequencies&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Expected frequencies&lt;/h2&gt;
&lt;p&gt;Remember that for the Chi-square test of independence we need to determine whether the observed counts are significantly different from the counts that we would expect if there was no association between the two variables. We have the observed counts (see the table above), so we now need to compute the expected counts in the case the variables were independent. These expected frequencies are computed for each subgroup one by one with the following formula:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{expected frequencies} = \frac{\text{total # of obs. for the row} \cdot \text{total # of obs. for the column}}{\text{total number of observations}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where obs. correspond to observations. Given our table of observed frequencies above, below is the table of the expected frequencies computed for each subgroup:&lt;/p&gt;
&lt;table style=&#34;width:94%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;25%&#34; /&gt;
&lt;col width=&#34;29%&#34; /&gt;
&lt;col width=&#34;29%&#34; /&gt;
&lt;col width=&#34;11%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt; &lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Non-smoker&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Smoker&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Total&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Athlete&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;(18 * 14) / 28 = 9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;(18 * 14) / 28 = 9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Non-athlete&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;(10 * 14) / 28 = 5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;(10 * 14) / 28 = 5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;&lt;strong&gt;Total&lt;/strong&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note that the Chi-square test of independence should only be done when the &lt;strong&gt;expected&lt;/strong&gt; frequencies in all groups are equal to or greater than 5. This assumption is met for our example as the minimum number of expected frequencies is 5. If the condition is not met, the &lt;a href=&#34;/blog/fisher-s-exact-test-in-r-independence-test-for-a-small-sample/&#34;&gt;Fisher’s exact test&lt;/a&gt; is preferred.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;test-statistic&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Test statistic&lt;/h2&gt;
&lt;p&gt;We have the observed and expected frequencies. We now need to compare these frequencies to determine if they differ significantly. The difference between the observed and expected frequencies, referred as the test statistic (or t-stat) and denoted &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;, is computed as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\chi^2 = \sum_{i, j} \frac{\big(O_{ij} - E_{ij}\big)^2}{E_{ij}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(O\)&lt;/span&gt; represents the observed frequencies and &lt;span class=&#34;math inline&#34;&gt;\(E\)&lt;/span&gt; the expected frequencies. We use the square of the differences between the observed and expected frequencies to make sure that negative differences are not compensated by positive differences. The formula looks more complex than what it really is, so let’s illustrate it with our example. We first compute the difference in each subgroup one by one according to the formula:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in the subgroup of athlete and non-smoker: &lt;span class=&#34;math inline&#34;&gt;\(\frac{(14 - 9)^2}{9} = 2.78\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;in the subgroup of non-athlete and non-smoker: &lt;span class=&#34;math inline&#34;&gt;\(\frac{(0 - 5)^2}{5} = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;in the subgroup of athlete and smoker: &lt;span class=&#34;math inline&#34;&gt;\(\frac{(4 - 9)^2}{9} = 2.78\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;in the subgroup of non-athlete and smoker: &lt;span class=&#34;math inline&#34;&gt;\(\frac{(10 - 5)^2}{5} = 5\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and then we sum them all to obtain the test statistic:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\chi^2 = 2.78 + 5 + 2.78 + 5 = 15.56\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;critical-value&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Critical value&lt;/h2&gt;
&lt;p&gt;The test statistic alone is not enough to conclude for independence or dependence between the two variables. As previously mentioned, this test statistic (which in some sense is the difference between the observed and expected frequencies) must be compared to a critical value to determine whether the difference is large or small. One cannot tell that a test statistic is large or small without putting it in perspective with the critical value.&lt;/p&gt;
&lt;p&gt;If the test statistic is above the critical value, it means that the probability of observing such a difference between the observed and expected frequencies is unlikely. On the other hand, if the test statistic is below the critical value, it means that the probability of observing such a difference is likely. If it is likely to observe this difference, we cannot reject the hypothesis that the two variables are independent, otherwise we can conclude that there exists a relationship between the variables.&lt;/p&gt;
&lt;p&gt;The critical value can be found in the statistical table of the Chi-square distribution and depends on the significance level, denoted &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, and the degrees of freedom, denoted &lt;span class=&#34;math inline&#34;&gt;\(df\)&lt;/span&gt;. The significance level is usually set equal to 5%. The degrees of freedom for a Chi-square test of independence is found as follow:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[df = (\text{number of rows} - 1) \cdot (\text{number of columns} - 1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In our example, the degrees of freedom is thus &lt;span class=&#34;math inline&#34;&gt;\(df = (2 - 1) \cdot (2 - 1) = 1\)&lt;/span&gt; since there are two rows and two columns in the contingency table (totals do not count as a row or column).&lt;/p&gt;
&lt;p&gt;We now have all the necessary information to find the critical value in the Chi-square table (&lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(df = 1\)&lt;/span&gt;). To find the critical value we need to look at the row &lt;span class=&#34;math inline&#34;&gt;\(df = 1\)&lt;/span&gt; and the column &lt;span class=&#34;math inline&#34;&gt;\(\chi^2_{0.050}\)&lt;/span&gt; (since &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;) in the picture below. The critical value is &lt;span class=&#34;math inline&#34;&gt;\(3.84146\)&lt;/span&gt;.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/chi-square-test-of-independence-by-hand_files/Screenshot%202020-01-28%20at%2000.56.28.png&#34; alt=&#34;Chi-square table - Critical value for alpha = 5% and df = 1&#34; style=&#34;width:100.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Chi-square table - Critical value for alpha = 5% and df = 1&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion-and-interpretation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion and interpretation&lt;/h2&gt;
&lt;p&gt;Now that we have the test statistic and the critical value, we can compare them to check whether the null hypothesis of independence of the variables is rejected or not. In our example,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{test statistic} = 15.56 &amp;gt; \text{critical value} = 3.84146\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Like for any statistical test, when the test statistic is larger than the critical value, we can reject the null hypothesis at the specified significance level.&lt;/p&gt;
&lt;p&gt;In our case, we can therefore reject the null hypothesis of independence between the two categorical variables at the 5% significance level.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow\)&lt;/span&gt; This means that there is a significant relationship between the smoking habit and being an athlete or not. Knowing the value of one variable helps to predict the value of the other variable.&lt;/p&gt;
&lt;p&gt;Thanks for reading. I hope the article helped you to perform the Chi-square test of independence by hand and interpret its results. If you would like to learn how to do this test in R, read the article “&lt;a href=&#34;/blog/chi-square-test-of-independence-in-r/&#34;&gt;Chi-square test of independence in R&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;For readers that prefer to check the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value in order to reject or not the null hypothesis, I also created a &lt;a href=&#34;/blog/a-guide-on-how-to-read-statistical-tables/&#34;&gt;Shiny app&lt;/a&gt; to help you compute the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value given a test statistic.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Chi-square test of independence in R</title>
      <link>/blog/chi-square-test-of-independence-in-r/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/chi-square-test-of-independence-in-r/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#example&#34;&gt;Example&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#chi-square-test-of-independence-in-r&#34;&gt;Chi-square test of independence in R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion-and-interpretation&#34;&gt;Conclusion and interpretation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;/blog/chi-square-test-of-independence-in-r_files/Chi-square-test-independence-in-R.jpeg&#34; style=&#34;width:100.0%&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This article explains how to perform the Chi-square test of independence in R and how to interpret its results. To learn more about how the test works and how to do it by hand, I invite you to read the article “&lt;a href=&#34;/blog/chi-square-test-of-independence-by-hand/&#34;&gt;Chi-square test of independence by hand&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;To briefly recap what have been said in that article, the Chi-square test of independence tests whether there is a relationship between two categorical variables. The null and alternative hypotheses are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; : the variables are independent, there is &lt;strong&gt;no&lt;/strong&gt; relationship between the two categorical variables. Knowing the value of one variable does not help to predict the value of the other variable&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt; : the variables are dependent, there is a relationship between the two categorical variables. Knowing the value of one variable helps to predict the value of the other variable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Chi-square test of independence works by comparing the observed frequencies (so the frequencies observed in your sample) to the expected frequencies if there was no relationship between the two categorical variables (so the expected frequencies if the null hypothesis was true).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example&lt;/h1&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;For our example, let’s reuse the dataset introduced in the article “&lt;a href=&#34;/blog/descriptive-statistics-in-r/&#34;&gt;Descriptive statistics in R&lt;/a&gt;”. This dataset is the well-known &lt;code&gt;iris&lt;/code&gt; dataset slightly enhanced. Since there is only one categorical variable and the Chi-square test requires two categorical variables, we added the variable &lt;code&gt;size&lt;/code&gt; which corresponds to &lt;code&gt;small&lt;/code&gt; if the length of the petal is smaller than the median of all flowers, &lt;code&gt;big&lt;/code&gt; otherwise:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- iris
dat$size &amp;lt;- ifelse(dat$Sepal.Length &amp;lt; median(dat$Sepal.Length),
  &amp;quot;small&amp;quot;, &amp;quot;big&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now create a contingency table of the two variables &lt;code&gt;Species&lt;/code&gt; and &lt;code&gt;size&lt;/code&gt; with the &lt;code&gt;table()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(dat$Species, dat$size)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             
##              big small
##   setosa       1    49
##   versicolor  29    21
##   virginica   47     3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The contingency table gives the observed number of cases in each subgroup. For instance, there is only one big setosa flower, while there are 49 small setosa flowers in the dataset.&lt;/p&gt;
&lt;p&gt;It is also a good practice to draw a barplot to visually represent the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)

ggplot(dat) +
  aes(x = Species, fill = size) +
  geom_bar() +
  scale_fill_hue() +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/chi-square-test-of-independence-in-r_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;chi-square-test-of-independence-in-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Chi-square test of independence in R&lt;/h2&gt;
&lt;p&gt;For this example, we are going to test in R if there is a relationship between the variables &lt;code&gt;Species&lt;/code&gt; and &lt;code&gt;size&lt;/code&gt;. For this, the &lt;code&gt;chisq.test()&lt;/code&gt; function is used:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test &amp;lt;- chisq.test(table(dat$Species, dat$size))
test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test
## 
## data:  table(dat$Species, dat$size)
## X-squared = 86.035, df = 2, p-value &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Everything you need appears in this output: the title of the test, what variables have been used, the test statistic, the degrees of freedom and the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value of the test. You can also retrieve the &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; test statistic and the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$statistic # test statistic&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## X-squared 
##  86.03451&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;test$p.value # p-value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.078944e-19&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you need to find the expected frequencies, use &lt;code&gt;test$expected&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If a warning such as “Chi-squared approximation may be incorrect” appears, it means that the smallest expected frequencies is lower than 5. To avoid this issue, you can either:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gather some levels (especially those with a small number of observations) to increase the number of observations in the subgroups, or&lt;/li&gt;
&lt;li&gt;use the Fisher’s exact test&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The Fisher’s exact test does not require the assumption of a minimum of 5 expected counts. It can be applied in R thanks to the function &lt;code&gt;fisher.test()&lt;/code&gt;. This test is similar to the Chi-square test in terms of hypothesis and interpretation of the results. Learn more about this test in this &lt;a href=&#34;/blog/fisher-s-exact-test-in-r-independence-test-for-a-small-sample/&#34;&gt;article&lt;/a&gt; dedicated to this type of test.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion-and-interpretation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion and interpretation&lt;/h2&gt;
&lt;p&gt;From the output and from &lt;code&gt;test$p.value&lt;/code&gt; we see that the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is less than the significance level of 5%. Like any other statistical test, if the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value is less than the significance level, we can reject the null hypothesis. If you are not familiar with &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values, I invite you to read this &lt;a href=&#34;/blog/student-s-t-test-in-r-and-by-hand-how-to-compare-two-groups-under-different-scenarios/#a-note-on-p-value-and-significance-level-alpha&#34;&gt;section&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Rightarrow\)&lt;/span&gt; In our context, rejecting the null hypothesis for the Chi-square test of independence means that there is a significant relationship between the species and the size. Therefore, knowing the value of one variable helps to predict the value of the other variable.&lt;/p&gt;
&lt;p&gt;Thanks for reading. I hope the article helped you to perform the Chi-square test of independence in R and interpret its results. If you would like to learn how to do this test by hand and how it works, read the article “&lt;a href=&#34;/blog/chi-square-test-of-independence-by-hand/&#34;&gt;Chi-square test of independence by hand&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Shiny app for inferential statistics by hand</title>
      <link>/blog/a-shiny-app-for-inferential-statistics-by-hand/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/a-shiny-app-for-inferential-statistics-by-hand/</guid>
      <description>


&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/a-shiny-app-for-inferential-statistics_files/Screenshot%202020-02-04%20at%2011.36.38.png&#34; alt=&#34;A Shiny app for inferential statistics: hypothesis tests and confidence intervals&#34; style=&#34;width:100.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;A Shiny app for inferential statistics: hypothesis tests and confidence intervals&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Statistics is divided into four main branches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Descriptive statistics&lt;/li&gt;
&lt;li&gt;Inferential statistics&lt;/li&gt;
&lt;li&gt;Predictive analysis&lt;/li&gt;
&lt;li&gt;Exploratory analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Descriptive statistics provide a summary of the data; it helps explaining the data in a concise way without losing too much information. Data can be summarized numerically or graphically. See &lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;descriptive statistics by hand&lt;/a&gt; or &lt;a href=&#34;/blog/descriptive-statistics-in-r/&#34;&gt;in R&lt;/a&gt; to learn more about this branch of statistics.&lt;/p&gt;
&lt;p&gt;The branch of predictive analysis aims at predicting a dependent variable based on one or several independent variables. Depending on the type of data to be predicted, it often encompasses methods such as regression or classification.&lt;/p&gt;
&lt;p&gt;Exploratory analyses focus on using graphical approaches to delve into the data and identify the relationships that exist between the different variables in the dataset. They are therefore more akin to data visualization.&lt;/p&gt;
&lt;p&gt;Inferential statistics uses a random sample of data taken from a population to make inferences, i.e., to draw conclusions about the population (see the &lt;a href=&#34;/blog/what-is-the-difference-between-population-and-sample/&#34;&gt;difference between population and sample&lt;/a&gt;). In other words, information from the sample is used to make generalizations about the parameter of interest in the population. The two major tools in inferential statistics are confidence intervals and hypothesis tests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Here is a Shiny app which helps you to use these two tools:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://antoinesoetewey.shinyapps.io/statistics-201/&#34; target=&#34;_blank&#34;&gt;Statistics-201&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This Shiny app focuses on confidence intervals and hypothesis tests for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 and 2 means (with unpaired and paired samples)&lt;/li&gt;
&lt;li&gt;1 and 2 proportions&lt;/li&gt;
&lt;li&gt;1 and 2 variances&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is the entire code in case you would like to enhance it (see an example on how to use this app after the embedded code):&lt;/p&gt;
&lt;script src=&#34;https://gist.github.com/AntoineSoetewey/296d78c473561254eaaff60395488fa6.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;&lt;em&gt;Note that the link may not work if the app has hit the monthly usage limit. Try again later if that is the case.&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;how-to-use-this-app&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to use this app?&lt;/h1&gt;
&lt;p&gt;Follow these steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Open the app via this &lt;a href=&#34;https://antoinesoetewey.shinyapps.io/statistics-201/&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Choose the parameter(s) you want to do inference for (i.e., mean(s), proportion(s) or variance(s))&lt;/li&gt;
&lt;li&gt;Write your data in Sample. Observations are separated by a comma and the decimal is a point&lt;/li&gt;
&lt;li&gt;Set the null and alternative hypothesis&lt;/li&gt;
&lt;li&gt;Select the significance level (most of the time &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the results panel (on the right side or below depending on the size of your screen), you will see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a recap of your sample together with some appropriate descriptive statistics&lt;/li&gt;
&lt;li&gt;the confidence interval&lt;/li&gt;
&lt;li&gt;the hypothesis test&lt;/li&gt;
&lt;li&gt;the interpretation&lt;/li&gt;
&lt;li&gt;and an illustration of the hypothesis test&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All formulas, steps and computations to arrive at the final results are also provided.&lt;/p&gt;
&lt;p&gt;Thanks for reading. I hope you will find this app useful to do inferential statistics and in particular confidence interval and hypothesis testing by hand.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by raising an issue on GitHub. For all other requests, you can contact me.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by subscribing to this blog.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>