<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Descriptive statistics on Stats and R</title>
    <link>/tags/descriptive-statistics/</link>
    <description>Recent content in Descriptive statistics on Stats and R</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 22 Feb 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/descriptive-statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Correlogram in R: how to highlight the most correlated variables in a dataset</title>
      <link>/blog/correlogram-in-r-how-to-highlight-the-most-correlated-variables-in-a-dataset/</link>
      <pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/correlogram-in-r-how-to-highlight-the-most-correlated-variables-in-a-dataset/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlation-matrix&#34;&gt;Correlation matrix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlogram&#34;&gt;Correlogram&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlation-test&#34;&gt;Correlation test&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#code&#34;&gt;Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lares-package&#34;&gt;&lt;code&gt;{lares}&lt;/code&gt; package&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#all-possible-correlations&#34;&gt;All possible correlations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlation-of-one-variable-against-all-others&#34;&gt;Correlation of one variable against all others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reference&#34;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/correlogram-in-r-how-to-highlight-correlations-between-variables_files/correlogram-in-r-how-to-highlight-correlations-between-variables.jpeg&#34; alt=&#34;Photo by Pritesh Sudra&#34; style=&#34;width:100.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Photo by Pritesh Sudra&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Correlation, often computed as part of &lt;a href=&#34;/blog/descriptive-statistics-in-r/&#34;&gt;descriptive statistics&lt;/a&gt;, is a statistical tool used to study the relationship between two variables, that is, whether and how strongly couples of variables are associated.&lt;/p&gt;
&lt;p&gt;Correlations are measured between only 2 variables at a time. Therefore, for datasets with many variables, computing correlations can become quite cumbersome and time consuming.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-matrix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Correlation matrix&lt;/h1&gt;
&lt;p&gt;A solution to this problem is to compute correlations and display them in a correlation matrix, which shows correlation coefficients for all possible combinations of two variables in the dataset.&lt;/p&gt;
&lt;p&gt;For example, below is the correlation matrix for the dataset &lt;code&gt;mtcars&lt;/code&gt; (which, as described by the help documentation of R, comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles).&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; For this article, we include only the &lt;a href=&#34;/blog/variable-types-and-examples/#continuous&#34;&gt;continuous&lt;/a&gt; variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- mtcars[, c(1, 3:7)]
round(cor(dat), 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        mpg  disp    hp  drat    wt  qsec
## mpg   1.00 -0.85 -0.78  0.68 -0.87  0.42
## disp -0.85  1.00  0.79 -0.71  0.89 -0.43
## hp   -0.78  0.79  1.00 -0.45  0.66 -0.71
## drat  0.68 -0.71 -0.45  1.00 -0.71  0.09
## wt   -0.87  0.89  0.66 -0.71  1.00 -0.17
## qsec  0.42 -0.43 -0.71  0.09 -0.17  1.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even after rounding the correlation coefficients to 2 digits, you will conceive that this correlation matrix is not easily and quickly interpretable.&lt;/p&gt;
&lt;p&gt;If you are using &lt;a href=&#34;/blog/getting-started-in-r-markdown/&#34;&gt;R Markdown&lt;/a&gt;, you can use the &lt;code&gt;pander()&lt;/code&gt; function from the &lt;code&gt;{pander}&lt;/code&gt; package to make it slightly more readable, but still, we must admit that this table is not optimal when it comes to visualizing correlations between several variables of a dataset, especially for large datasets.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlogram&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Correlogram&lt;/h1&gt;
&lt;p&gt;To tackle this issue and make it much more insightful, let’s transform the correlation matrix into a correlation plot. A correlation plot (also referred as a correlogram or corrgram in &lt;span class=&#34;citation&#34;&gt;Friendly (2002)&lt;/span&gt;) allows to highlight the variables that are most (positively and negatively) correlated. Below an example with the same dataset presented above:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/correlogram-in-r-how-to-highlight-correlations-between-variables_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The correlogram represents the correlations for all pairs of variables. Positive correlations are displayed in blue and negative correlations in red. The intensity of the color is proportional to the correlation coefficient so the stronger the correlation (i.e., the closer to -1 or 1), the darker the boxes. The color legend on the right hand side of the correlogram shows the correlation coefficients and the corresponding colors.&lt;/p&gt;
&lt;p&gt;As a reminder, a negative correlation implies that the two variables under consideration vary in opposite directions, that is, if one variable increases the other decreases and vice versa. A positive correlation implies that the two variables under consideration vary in the same direction, that is, if one variable increases the other increases and if one variable decreases the other decreases as well. Furthermore, the stronger the correlation, the stronger the association between the two variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-test&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Correlation test&lt;/h1&gt;
&lt;p&gt;Finally, a white box in the correlogram indicates that the correlation is not significantly different from 0 at the specified significance level (in this example, at &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 5\)&lt;/span&gt;%) for the couple of variables. A correlation not significantly different from 0 means that there is &lt;strong&gt;no linear&lt;/strong&gt; relationship between the two variables considered (there could be another kind of association, but other than linear).&lt;/p&gt;
&lt;p&gt;To determine whether a specific correlation coefficient is significantly different from 0, a correlation test has been performed. Remind that the null and alternative hypotheses of this test are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\rho = 0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(\rho \ne 0\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is the correlation coefficient. The correlation test is based on two factors: the number of observations and the correlation coefficient. The more observations and the stronger the correlation between 2 variables, the more likely it is to reject the null hypothesis of no correlation between these 2 variables.&lt;/p&gt;
&lt;p&gt;In the context of our example, the correlogram above shows that the variables &lt;code&gt;wt&lt;/code&gt; (weight) and &lt;code&gt;hp&lt;/code&gt; (horsepower) are positively correlated, while the variables &lt;code&gt;mpg&lt;/code&gt; (miles per gallon) and &lt;code&gt;wt&lt;/code&gt; (weight) are negatively correlated (both correlations make sense if we think about it). Furthermore, the variables &lt;code&gt;wt&lt;/code&gt; and &lt;code&gt;qsec&lt;/code&gt; are not correlated (indicated by a white box). Even if the correlation coefficient is -0.17 between the 2 variables, the correlation test has shown that we cannot reject the hypothesis of no correlation. This is the reason the box for these two variable is white.&lt;/p&gt;
&lt;p&gt;Although this correlogram presents exactly the same information than the correlation matrix, the correlogram presents a visual representation of the correlation matrix, allowing to quickly scan through it to see which variables are correlated and which are not.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;code&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Code&lt;/h1&gt;
&lt;p&gt;For those interested to draw this correlogram with their own data, here is the code of the function I adapted based on the &lt;code&gt;corrplot()&lt;/code&gt; function from the &lt;code&gt;{corrplot}&lt;/code&gt; package (thanks again to all contributors of this package):&lt;/p&gt;
&lt;script src=&#34;https://gist.github.com/AntoineSoetewey/1fc0fe939336a8b8085e1872e045b48f.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;The main arguments in the &lt;code&gt;corrplot2()&lt;/code&gt; function are the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data&lt;/code&gt;: name of your dataset&lt;/li&gt;
&lt;li&gt;&lt;code&gt;method&lt;/code&gt;: the correlation method to be computed, one of “pearson” (default), “kendall”, or “spearman”. As a rule of thumb, if your dataset contains quantitative continuous variables, you can keep the Pearson method, if you have &lt;a href=&#34;/blog/variable-types-and-examples/&#34;&gt;qualitative ordinal&lt;/a&gt; variables, the Spearman method is more appropriate&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sig.level&lt;/code&gt;: the significance level for the correlation test, default is 0.05&lt;/li&gt;
&lt;li&gt;&lt;code&gt;order&lt;/code&gt;: order of the variables, one of “original” (default), “AOE” (angular order of the eigenvectors), “FPC” (first principal component order), “hclust” (hierarchical clustering order), “alphabet” (alphabetical order)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;diag&lt;/code&gt;: display the correlation coefficients on the diagonal? The default is &lt;code&gt;FALSE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;type&lt;/code&gt;: display the entire correlation matrix or simply the upper/lower part, one of “upper” (default), “lower”, “full”&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tl.srt&lt;/code&gt;: rotation of the variable labels&lt;/li&gt;
&lt;li&gt;(note that missing values in the dataset are automatically removed)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can also play with the arguments of the &lt;code&gt;corrplot2&lt;/code&gt; function and see the results thanks to this &lt;a href=&#34;https://antoinesoetewey.shinyapps.io/correlogram/&#34; target=&#34;_blank&#34;&gt;R Shiny app&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lares-package&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;code&gt;{lares}&lt;/code&gt; package&lt;/h1&gt;
&lt;p&gt;Thanks to this article, I discovered the &lt;code&gt;{lares}&lt;/code&gt; package which has really nice features regarding plotting correlations. Another advantage of this package is that it can be used to compute correlations with numerical, logical, categorical and date variables.&lt;/p&gt;
&lt;p&gt;See more information about the package in this &lt;a href=&#34;https://datascienceplus.com/find-insights-with-ranked-cross-correlations/&#34; target=&#34;_blank&#34;&gt;article&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;all-possible-correlations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;All possible correlations&lt;/h2&gt;
&lt;p&gt;Use the &lt;code&gt;corr_cross()&lt;/code&gt; function if you want to compute all correlations and return the highest and significant ones in a plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# devtools::install_github(&amp;quot;laresbernardo/lares&amp;quot;)
library(lares)

corr_cross(dat, # name of dataset
  max_pvalue = 0.05, # display only significant correlations (at 5% level)
  top = 10 # display top 10 couples of variables (by correlation coefficient)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/correlogram-in-r-how-to-highlight-correlations-between-variables_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Negative correlations are represented in red and positive correlations in blue.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-of-one-variable-against-all-others&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Correlation of one variable against all others&lt;/h2&gt;
&lt;p&gt;Use the &lt;code&gt;corr_var()&lt;/code&gt; function if you want to focus on the correlation of one variable against all others, and return the highest ones in a plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;corr_var(dat, # name of dataset
  mpg, # name of variable to focus on
  top = 5 # display top 5 correlations
) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/correlogram-in-r-how-to-highlight-correlations-between-variables_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Thanks for reading. I hope this article will help you to visualize correlations between variables in a dataset and to make correlation matrices more insightful and more appealing.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by &lt;a href=&#34;https://github.com/AntoineSoetewey/statsandr/issues&#34; target=&#34;_blank&#34;&gt;raising an issue on GitHub&lt;/a&gt;. For all other requests, you can &lt;a href=&#34;/contact/&#34;&gt;contact me&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by &lt;a href=&#34;/subscribe/&#34;&gt;subscribing to this blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related articles:&lt;/strong&gt;&lt;/p&gt;
&lt;script src=&#34;//rss.bloople.net/?url=https%3A%2F%2Fwww.statsandr.com%2Ftags%2Fr%2Findex.xml&amp;detail=-1&amp;limit=5&amp;showtitle=false&amp;type=js&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;reference&#34; class=&#34;section level1 unnumbered&#34;&gt;
&lt;h1&gt;Reference&lt;/h1&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-friendly2002corrgrams&#34;&gt;
&lt;p&gt;Friendly, Michael. 2002. “Corrgrams: Exploratory Displays for Correlation Matrices.” &lt;em&gt;The American Statistician&lt;/em&gt; 56 (4). Taylor &amp;amp; Francis: 316–24.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The dataset &lt;code&gt;mtcars&lt;/code&gt; is preloaded in R by default, so there is no need to import it into R. Check the article “&lt;a href=&#34;/blog/how-to-import-an-excel-file-in-rstudio/&#34;&gt;How to import an Excel file in R&lt;/a&gt;” if you need help in importing your own dataset.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Descriptive statistics in R</title>
      <link>/blog/descriptive-statistics-in-r/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/descriptive-statistics-in-r/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data&#34;&gt;Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#minimum-and-maximum&#34;&gt;Minimum and maximum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#range&#34;&gt;Range&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mean&#34;&gt;Mean&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#median&#34;&gt;Median&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#first-and-third-quartile&#34;&gt;First and third quartile&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#other-quantiles&#34;&gt;Other quantiles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#interquartile-range&#34;&gt;Interquartile range&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#standard-deviation-and-variance&#34;&gt;Standard deviation and variance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summary&#34;&gt;Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#coefficient-of-variation&#34;&gt;Coefficient of variation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mode&#34;&gt;Mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#contingency-table&#34;&gt;Contingency table&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#mosaic-plot&#34;&gt;Mosaic plot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#barplot&#34;&gt;Barplot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#histogram&#34;&gt;Histogram&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#boxplot&#34;&gt;Boxplot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scatterplot&#34;&gt;Scatterplot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#qq-plot&#34;&gt;QQ-plot&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#for-a-single-variable&#34;&gt;For a single variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#by-groups&#34;&gt;By groups&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#density-plot&#34;&gt;Density plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlation-plot&#34;&gt;Correlation plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#advanced-descriptive-statistics&#34;&gt;Advanced descriptive statistics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#summarytools-package&#34;&gt;&lt;code&gt;{summarytools}&lt;/code&gt; package&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#frequency-tables-with-freq&#34;&gt;Frequency tables with &lt;code&gt;freq()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cross-tabulations-with-ctable&#34;&gt;Cross-tabulations with &lt;code&gt;ctable()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#descriptive-statistics-with-descr&#34;&gt;Descriptive statistics with &lt;code&gt;descr()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-frame-summaries-with-dfsummary&#34;&gt;Data frame summaries with &lt;code&gt;dfSummary()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#describeby-from-the-psych-package&#34;&gt;&lt;code&gt;describeBy()&lt;/code&gt; from the &lt;code&gt;{psych}&lt;/code&gt; package&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aggregate&#34;&gt;&lt;code&gt;aggregate()&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/descriptive-statistics-in-r.jpeg&#34; alt=&#34;Photo by Ruthson Zimmerman&#34; style=&#34;width:100.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Photo by Ruthson Zimmerman&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This article explains how to compute the main descriptive statistics in R and how to present them graphically. To learn more about the reasoning behind each descriptive statistics, how to compute them by hand and how to interpret them, read the article “&lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;Descriptive statistics by hand&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;To briefly recap what have been said in that article, descriptive statistics (in the broad sense of the term) is a branch of statistics aiming at summarizing, describing and presenting a series of values or a dataset. Descriptive statistics is often the first step and an important part in any statistical analysis. It allows to check the quality of the data and it helps to “understand” the data by having a clear overview of it. If well presented, descriptive statistics is already a good starting point for further analyses. There exists many measures to summarize a dataset. They are divided into two types:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;location measures and&lt;/li&gt;
&lt;li&gt;dispersion measures&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Location measures give an understanding about the central tendency of the data, whereas dispersion measures give an understanding about the spread of the data. In this article, we focus only on the implementation in R of the most common descriptive statistics and their visualizations (when deemed appropriate). See online or in the &lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;above mentioned article&lt;/a&gt; for more information about the purpose and usage of each measure.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data&lt;/h1&gt;
&lt;p&gt;We use the dataset &lt;code&gt;iris&lt;/code&gt; throughout the article. This dataset is imported by default in R, you only need to load it by running &lt;code&gt;iris&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat &amp;lt;- iris # load the iris dataset and renamed it dat&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Below a preview of this dataset and its structure:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(dat) # first 6 observations&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa
## 6          5.4         3.9          1.7         0.4  setosa&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(dat) # structure of dataset&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &amp;quot;setosa&amp;quot;,&amp;quot;versicolor&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset contains 150 observations and 5 variables, representing the length and width of the sepal and petal and the species of 150 flowers. Length and width of the sepal and petal are numeric variables and the species is a factor with 3 levels (indicated by &lt;code&gt;num&lt;/code&gt; and &lt;code&gt;Factor w/ 3 levels&lt;/code&gt; after the name of the variables). See the &lt;a href=&#34;/blog/data-types-in-r/&#34;&gt;different variables types in R&lt;/a&gt; if you need a refresh.&lt;/p&gt;
&lt;p&gt;Regarding plots, we present the default graphs and the graphs from the well-known &lt;code&gt;{ggplot2}&lt;/code&gt; package. Graphs from the &lt;code&gt;{ggplot2}&lt;/code&gt; package usually have a better look but it requires more advanced coding skills. If you need to publish or share your graphs, I suggest using &lt;code&gt;{ggplot2}&lt;/code&gt; if you can, otherwise the default graphics will do the job.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip: I recently discovered the ggplot2 builder from the &lt;code&gt;{esquisse}&lt;/code&gt; addins. See how you can easily &lt;a href=&#34;/blog/rstudio-addins-or-how-to-make-your-coding-life-easier/&#34;&gt;draw graphs from the &lt;code&gt;{ggplot2}&lt;/code&gt; package&lt;/a&gt; without having to code it yourself.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;All plots displayed in this article can be customized. For instance, it is possible to edit the title, x and y-axis labels, color, etc. However, customizing plots is beyond the scope of this article so all plots are presented without any customization. Interested readers will find numerous resources online.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;minimum-and-maximum&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Minimum and maximum&lt;/h1&gt;
&lt;p&gt;Minimum and maximum can be found thanks to the &lt;code&gt;min()&lt;/code&gt; and &lt;code&gt;max()&lt;/code&gt; functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;min(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4.3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;max(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 7.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Alternatively the &lt;code&gt;range()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rng &amp;lt;- range(dat$Sepal.Length)
rng&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4.3 7.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;gives you the minimum and maximum directly. Note that the output of the &lt;code&gt;range()&lt;/code&gt; function is actually an object containing the minimum and maximum (in that order). This means you can actually access the minimum with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rng[1] # rng = name of the object specified above&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the maximum with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rng[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 7.9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This reminds us that, in R, there are often several ways to arrive at the same result. The method that uses the shortest piece of code is usually preferred as a shorter piece of code is less prone to coding errors and more readable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;range&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Range&lt;/h1&gt;
&lt;p&gt;The range can then be easily computed, as you have guessed, by subtracting the minimum from the maximum:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;max(dat$Sepal.Length) - min(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To my knowledge, there is no default function to compute the range. However, if you are familiar with writing functions in R
&lt;!-- (if not, see this article on [how to write a function in R](/blog/xxx/)) --&gt;
, you can create your own function to compute the range:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;range2 &amp;lt;- function(x) {
  range &amp;lt;- max(x) - min(x)
  return(range)
}

range2(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is equivalent than &lt;span class=&#34;math inline&#34;&gt;\(max - min\)&lt;/span&gt; presented above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mean&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mean&lt;/h1&gt;
&lt;p&gt;The mean can be computed with the &lt;code&gt;mean()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5.843333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Tips:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if there is at least one missing value in your dataset, use &lt;code&gt;mean(dat$Sepal.Length, na.rm = TRUE)&lt;/code&gt; to compute the mean with the NA excluded. This argument can be used for most functions presented in this article, not only the mean&lt;/li&gt;
&lt;li&gt;for a truncated mean, use &lt;code&gt;mean(dat$Sepal.Length, trim = 0.10)&lt;/code&gt; and change the &lt;code&gt;trim&lt;/code&gt; argument to your needs&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;median&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Median&lt;/h1&gt;
&lt;p&gt;The median can be computed thanks to the &lt;code&gt;median()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or with the &lt;code&gt;quantile()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dat$Sepal.Length, 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 50% 
## 5.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;since the quantile of order 0.5 (&lt;span class=&#34;math inline&#34;&gt;\(q_{0.5}\)&lt;/span&gt;) corresponds to the median.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;first-and-third-quartile&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;First and third quartile&lt;/h1&gt;
&lt;p&gt;As the median, the first and third quartiles can be computed thanks to the &lt;code&gt;quantile()&lt;/code&gt; function and by setting the second argument to 0.25 or 0.75:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dat$Sepal.Length, 0.25) # first quartile&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 25% 
## 5.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dat$Sepal.Length, 0.75) # third quartile&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 75% 
## 6.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may have seen that the results above are slightly different than the results you would have found if you compute the first and third quartiles &lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;by hand&lt;/a&gt;. It is normal, there are many methods to compute them (R actually has 7 methods to compute the quantiles!). However, the methods presented here and in the article “&lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;descriptive statistics by hand&lt;/a&gt;” are the easiest and most “standard” ones. Furthermore, results do not dramatically change between the two methods.&lt;/p&gt;
&lt;div id=&#34;other-quantiles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other quantiles&lt;/h2&gt;
&lt;p&gt;As you have guessed, any quantile can also be computed with the &lt;code&gt;quantile()&lt;/code&gt; function. For instance, the &lt;span class=&#34;math inline&#34;&gt;\(4^{th}\)&lt;/span&gt; decile or the &lt;span class=&#34;math inline&#34;&gt;\(98^{th}\)&lt;/span&gt; percentile:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dat$Sepal.Length, 0.4) # 4th decile&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 40% 
## 5.6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dat$Sepal.Length, 0.98) # 98th percentile&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 98% 
## 7.7&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;interquartile-range&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Interquartile range&lt;/h1&gt;
&lt;p&gt;The interquartile range (i.e., the difference between the first and third quartile) can be computed with the &lt;code&gt;IQR()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;IQR(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or alternatively with the &lt;code&gt;quantile()&lt;/code&gt; function again:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dat$Sepal.Length, 0.75) - quantile(dat$Sepal.Length, 0.25)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 75% 
## 1.3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As mentioned earlier, when possible it is usually recommended to use the shortest piece of code to arrive at the result. For this reason, the &lt;code&gt;IQR()&lt;/code&gt; function is preferred to compute the interquartile range.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-deviation-and-variance&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Standard deviation and variance&lt;/h1&gt;
&lt;p&gt;The standard deviation and the variance is computed with the &lt;code&gt;sd()&lt;/code&gt; and &lt;code&gt;var()&lt;/code&gt; functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(dat$Sepal.Length) # standard deviation&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8280661&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;var(dat$Sepal.Length) # variance&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6856935&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember from the article &lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;descriptive statistics by hand&lt;/a&gt; that the standard deviation and the variance are different whether we compute it for a sample or a population (see the &lt;a href=&#34;/blog/what-is-the-difference-between-population-and-sample/&#34;&gt;difference between sample and population&lt;/a&gt;). In R, the standard deviation and the variance are computed as if the data represent a sample (so the denominator is &lt;span class=&#34;math inline&#34;&gt;\(n - 1\)&lt;/span&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of observations). To my knowledge, there is no function by default in R that computes the standard deviation or variance for a population.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Tip:&lt;/em&gt; to compute the standard deviation (or variance) of multiple variables at the same time, use &lt;code&gt;lapply()&lt;/code&gt; with the appropriate statistics as second argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lapply(dat[, 1:4], sd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $Sepal.Length
## [1] 0.8280661
## 
## $Sepal.Width
## [1] 0.4358663
## 
## $Petal.Length
## [1] 1.765298
## 
## $Petal.Width
## [1] 0.7622377&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The command &lt;code&gt;dat[, 1:4]&lt;/code&gt; selects the variables 1 to 4 as the fifth variable is a qualitative variable and the standard deviation cannot be computed on such type of variable. See a recap of the different &lt;a href=&#34;/blog/data-types-in-r/&#34;&gt;data types in R&lt;/a&gt; if needed.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Summary&lt;/h1&gt;
&lt;p&gt;You can compute the minimum, &lt;span class=&#34;math inline&#34;&gt;\(1^{st}\)&lt;/span&gt; quartile, median, mean, &lt;span class=&#34;math inline&#34;&gt;\(3^{rd}\)&lt;/span&gt; quartile and the maximum for all numeric variables of a dataset at once using &lt;code&gt;summary()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
##  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
##  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
##  Median :5.800   Median :3.000   Median :4.350   Median :1.300  
##  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
##  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
##  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
##        Species  
##  setosa    :50  
##  versicolor:50  
##  virginica :50  
##                 
##                 
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Tip:&lt;/em&gt; if you need these descriptive statistics by group use the &lt;code&gt;by()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;by(dat, dat$Species, summary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dat$Species: setosa
##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
##  Min.   :4.300   Min.   :2.300   Min.   :1.000   Min.   :0.100  
##  1st Qu.:4.800   1st Qu.:3.200   1st Qu.:1.400   1st Qu.:0.200  
##  Median :5.000   Median :3.400   Median :1.500   Median :0.200  
##  Mean   :5.006   Mean   :3.428   Mean   :1.462   Mean   :0.246  
##  3rd Qu.:5.200   3rd Qu.:3.675   3rd Qu.:1.575   3rd Qu.:0.300  
##  Max.   :5.800   Max.   :4.400   Max.   :1.900   Max.   :0.600  
##        Species  
##  setosa    :50  
##  versicolor: 0  
##  virginica : 0  
##                 
##                 
##                 
## ------------------------------------------------------------ 
## dat$Species: versicolor
##   Sepal.Length    Sepal.Width     Petal.Length   Petal.Width          Species  
##  Min.   :4.900   Min.   :2.000   Min.   :3.00   Min.   :1.000   setosa    : 0  
##  1st Qu.:5.600   1st Qu.:2.525   1st Qu.:4.00   1st Qu.:1.200   versicolor:50  
##  Median :5.900   Median :2.800   Median :4.35   Median :1.300   virginica : 0  
##  Mean   :5.936   Mean   :2.770   Mean   :4.26   Mean   :1.326                  
##  3rd Qu.:6.300   3rd Qu.:3.000   3rd Qu.:4.60   3rd Qu.:1.500                  
##  Max.   :7.000   Max.   :3.400   Max.   :5.10   Max.   :1.800                  
## ------------------------------------------------------------ 
## dat$Species: virginica
##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
##  Min.   :4.900   Min.   :2.200   Min.   :4.500   Min.   :1.400  
##  1st Qu.:6.225   1st Qu.:2.800   1st Qu.:5.100   1st Qu.:1.800  
##  Median :6.500   Median :3.000   Median :5.550   Median :2.000  
##  Mean   :6.588   Mean   :2.974   Mean   :5.552   Mean   :2.026  
##  3rd Qu.:6.900   3rd Qu.:3.175   3rd Qu.:5.875   3rd Qu.:2.300  
##  Max.   :7.900   Max.   :3.800   Max.   :6.900   Max.   :2.500  
##        Species  
##  setosa    : 0  
##  versicolor: 0  
##  virginica :50  
##                 
##                 
## &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where the arguments are the name of the dataset, the grouping variable and the summary function. Follow this order, or specify the name of the arguments if you do not follow this order.&lt;/p&gt;
&lt;p&gt;If you need more descriptive statistics, use &lt;code&gt;stat.desc()&lt;/code&gt; from the package &lt;code&gt;{pastecs}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(pastecs)
stat.desc(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              Sepal.Length  Sepal.Width Petal.Length  Petal.Width Species
## nbr.val      150.00000000 150.00000000  150.0000000 150.00000000      NA
## nbr.null       0.00000000   0.00000000    0.0000000   0.00000000      NA
## nbr.na         0.00000000   0.00000000    0.0000000   0.00000000      NA
## min            4.30000000   2.00000000    1.0000000   0.10000000      NA
## max            7.90000000   4.40000000    6.9000000   2.50000000      NA
## range          3.60000000   2.40000000    5.9000000   2.40000000      NA
## sum          876.50000000 458.60000000  563.7000000 179.90000000      NA
## median         5.80000000   3.00000000    4.3500000   1.30000000      NA
## mean           5.84333333   3.05733333    3.7580000   1.19933333      NA
## SE.mean        0.06761132   0.03558833    0.1441360   0.06223645      NA
## CI.mean.0.95   0.13360085   0.07032302    0.2848146   0.12298004      NA
## var            0.68569351   0.18997942    3.1162779   0.58100626      NA
## std.dev        0.82806613   0.43586628    1.7652982   0.76223767      NA
## coef.var       0.14171126   0.14256420    0.4697441   0.63555114      NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can have even more statistics (i.e., skewness, kurtosis and normality test) by adding the argument &lt;code&gt;norm = TRUE&lt;/code&gt; in the previous function. Note that the variable &lt;code&gt;Species&lt;/code&gt; is not numeric, so descriptive statistics cannot be computed for this variable and NA are displayed.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;coefficient-of-variation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Coefficient of variation&lt;/h1&gt;
&lt;p&gt;The coefficient of variation can be found with &lt;code&gt;stat.desc()&lt;/code&gt; (see the line &lt;code&gt;coef.var&lt;/code&gt; in the table above) or by computing manually (remember that the coefficient of variation is the standard deviation divided by the mean):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(dat$Sepal.Length) / mean(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1417113&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mode&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mode&lt;/h1&gt;
&lt;p&gt;To my knowledge there is no function to find the mode of a variable. However, we can easily find it thanks to the functions &lt;code&gt;table()&lt;/code&gt; and &lt;code&gt;sort()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tab &amp;lt;- table(dat$Sepal.Length) # number of occurrences for each unique value
sort(tab, decreasing = TRUE) # sort highest to lowest&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   5 5.1 6.3 5.7 6.7 5.5 5.8 6.4 4.9 5.4 5.6   6 6.1 4.8 6.5 4.6 5.2 6.2 6.9 7.7 
##  10   9   9   8   8   7   7   7   6   6   6   6   6   5   5   4   4   4   4   4 
## 4.4 5.9 6.8 7.2 4.7 6.6 4.3 4.5 5.3   7 7.1 7.3 7.4 7.6 7.9 
##   3   3   3   3   2   2   1   1   1   1   1   1   1   1   1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;table()&lt;/code&gt; gives the number of occurrences for each unique value, then &lt;code&gt;sort()&lt;/code&gt; with the argument &lt;code&gt;decreasing = TRUE&lt;/code&gt; displays the number of occurrences from highest to lowest. The mode of the variable &lt;code&gt;Sepal.Length&lt;/code&gt; is thus 5. This code to find the mode can also be applied to qualitative variables such as &lt;code&gt;Species&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sort(table(dat$Species), decreasing = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     setosa versicolor  virginica 
##         50         50         50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(dat$Species)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     setosa versicolor  virginica 
##         50         50         50&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;contingency-table&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Contingency table&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;table()&lt;/code&gt; introduced above can also be used on two qualitative variables to create a contingency table. The dataset &lt;code&gt;iris&lt;/code&gt; has only one qualitative variable so we create a new qualitative variable just for this example. We create the variable &lt;code&gt;size&lt;/code&gt; which corresponds to &lt;code&gt;small&lt;/code&gt; if the length of the petal is smaller than the median of all flowers, &lt;code&gt;big&lt;/code&gt; otherwise:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dat$size &amp;lt;- ifelse(dat$Sepal.Length &amp;lt; median(dat$Sepal.Length),
  &amp;quot;small&amp;quot;, &amp;quot;big&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a recap of the occurrences by size:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(dat$size)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   big small 
##    77    73&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now create a contingency table of the two variables &lt;code&gt;Species&lt;/code&gt; and &lt;code&gt;size&lt;/code&gt; with the &lt;code&gt;table()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(dat$Species, dat$size)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             
##              big small
##   setosa       1    49
##   versicolor  29    21
##   virginica   47     3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or with the &lt;code&gt;xtabs()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xtabs(~ dat$Species + dat$size)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             dat$size
## dat$Species  big small
##   setosa       1    49
##   versicolor  29    21
##   virginica   47     3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The contingency table gives the number of cases in each subgroup. For instance, there is only one big setosa flower, while there are 49 small setosa flowers in the dataset.&lt;/p&gt;
&lt;p&gt;To go further, we can see from the table that setosa flowers seem to be larger in size than virginica flowers. In order to check whether size is significantly associated with species, we could perform a Chi-square test of independence since both variables are categorical variables. See how to do this test &lt;a href=&#34;/blog/chi-square-test-of-independence-by-hand/&#34;&gt;by hand&lt;/a&gt; and &lt;a href=&#34;/blog/chi-square-test-of-independence-in-r/&#34;&gt;in R&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Note that &lt;code&gt;Species&lt;/code&gt; are in rows and &lt;code&gt;size&lt;/code&gt; in column because we specified &lt;code&gt;Species&lt;/code&gt; and then &lt;code&gt;size&lt;/code&gt; in &lt;code&gt;table()&lt;/code&gt;. Change the order if you want to switch the two variables.&lt;/p&gt;
&lt;p&gt;Instead of having the frequencies (i.e.. the number of cases) you can also have the relative frequencies (i.e., proportions) in each subgroup by adding the &lt;code&gt;table()&lt;/code&gt; function inside the &lt;code&gt;prop.table()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop.table(table(dat$Species, dat$size))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             
##                      big       small
##   setosa     0.006666667 0.326666667
##   versicolor 0.193333333 0.140000000
##   virginica  0.313333333 0.020000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that you can also compute the percentages by row or by column by adding a second argument to the &lt;code&gt;prop.table()&lt;/code&gt; function: &lt;code&gt;1&lt;/code&gt; for row, or &lt;code&gt;2&lt;/code&gt; for column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# percentages by row:
round(prop.table(table(dat$Species, dat$size), 1), 2) # round to 2 digits with round()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             
##               big small
##   setosa     0.02  0.98
##   versicolor 0.58  0.42
##   virginica  0.94  0.06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# percentages by column:
round(prop.table(table(dat$Species, dat$size), 2), 2) # round to 2 digits with round()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             
##               big small
##   setosa     0.01  0.67
##   versicolor 0.38  0.29
##   virginica  0.61  0.04&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;See the section on &lt;a href=&#34;/blog/descriptive-statistics-in-r/#cross-tabulations-with-ctable&#34;&gt;advanced descriptive statistics&lt;/a&gt; for more advanced contingency tables.&lt;/p&gt;
&lt;div id=&#34;mosaic-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mosaic plot&lt;/h2&gt;
&lt;p&gt;A mosaic plot allows to visualize a contingency table of two variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mosaicplot(table(dat$Species, dat$size),
  color = TRUE,
  xlab = &amp;quot;Species&amp;quot;,
  ylab = &amp;quot;Size&amp;quot;
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The mosaic plot shows that, for our sample, the proportion of big and small flowers is clearly different between the three species.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;barplot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Barplot&lt;/h1&gt;
&lt;p&gt;Barplots can only be done on qualitative variables (see the difference with a quantitative variable &lt;a href=&#34;/blog/variable-types-and-examples/&#34;&gt;here&lt;/a&gt;). A barplot is a tool to visualize the distribution of a qualitative variable. We draw a barplot on the qualitative variable &lt;code&gt;size&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;barplot(table(dat$size)) # table() is mandatory&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can also draw a barplot of the relative frequencies instead of the frequencies by adding &lt;code&gt;prop.table()&lt;/code&gt; as we did earlier:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;barplot(prop.table(table(dat$size)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;{ggplot2}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2) # needed each time you open RStudio
# The package ggplot2 must be installed first

ggplot(dat) +
  aes(x = size) +
  geom_bar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-34-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;histogram&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Histogram&lt;/h1&gt;
&lt;p&gt;A histogram gives an idea about the distribution of a quantitative variable. The idea is to break the range of values into intervals and count how many observations fall into each interval. Histograms are a bit similar to barplots, but histograms are used for quantitative variables whereas barplots are used for qualitative variables. To draw a histogram in R, use &lt;code&gt;hist()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-35-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Add the arguments &lt;code&gt;breaks =&lt;/code&gt; inside the &lt;code&gt;hist()&lt;/code&gt; function if you want to change the number of bins. A rule of thumb (known as Sturges’ law) is that the number of bins should be the rounded value of the square root of the number of observations. The dataset includes 150 observations so in this case the number of bins can be set to 12.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;{ggplot2}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat) +
  aes(x = Sepal.Length) +
  geom_histogram()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-36-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By default, the number of bins is 30. You can change this value with &lt;code&gt;geom_histogram(bins = 12)&lt;/code&gt; for instance.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;boxplot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Boxplot&lt;/h1&gt;
&lt;p&gt;Boxplots are really useful in descriptive statistics and are often underused (mostly because it is not well understood by the public). A boxplot graphically represents the distribution of a quantitative variable by visually displaying five common location summary (minimum, median, first and third quartiles and maximum) and any observation that was classified as a suspected outlier using the interquartile range (IQR) criterion. The IQR criterion means that all observations above &lt;span class=&#34;math inline&#34;&gt;\(q_{0.75} + 1.5 \cdot IQR\)&lt;/span&gt; and below &lt;span class=&#34;math inline&#34;&gt;\(q_{0.25} - 1.5 \cdot IQR\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(q_{0.25}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(q_{0.75}\)&lt;/span&gt; correspond to first and third quartile respectively) are considered as potential outliers by R. The minimum and maximum in the boxplot are represented without these suspected outliers. Seeing all these information on the same plot help to have a good first overview of the dispersion and the location of the data. Before drawing a boxplot of our data, see below a graph explaining the information present on a boxplot:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/boxplot.png&#34; alt=&#34;Detailed boxplot. Source: LFSAB1105 at UCLouvain&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Detailed boxplot. Source: LFSAB1105 at UCLouvain&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now an example with our dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boxplot(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Boxplots are even more informative when presented side-by-side for comparing and contrasting distributions from two or more groups. For instance, we compare the length of the sepal across the different species:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boxplot(dat$Sepal.Length ~ dat$Species)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-38-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;{ggplot2}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat) +
  aes(x = Species, y = Sepal.Length) +
  geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scatterplot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Scatterplot&lt;/h1&gt;
&lt;p&gt;Scatterplots allow to check whether there is a potential link between two quantitative variables. For instance, when drawing a scatterplot of the length of the sepal and the length of the petal:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(dat$Sepal.Length, dat$Petal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-40-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There seems to be a positive association between the two variables.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;{ggplot2}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat) +
  aes(x = Sepal.Length, y = Petal.Length) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-41-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As boxplots, scatterplots are even more informative when differentiating the points according to a factor, in this case the species:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat) +
  aes(x = Sepal.Length, y = Petal.Length, colour = Species) +
  geom_point() +
  scale_color_hue()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-42-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;qq-plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;QQ-plot&lt;/h1&gt;
&lt;div id=&#34;for-a-single-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;For a single variable&lt;/h2&gt;
&lt;p&gt;In order to check the normality assumption of a variable (normality means that the data follow a normal distribution, also known as a Gaussian distribution), we usually use histograms and/or QQ-plots.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; See an article discussing about the &lt;a href=&#34;/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/&#34;&gt;normal distribution and how to evaluate the normality assumption in R&lt;/a&gt; if you need a refresh on that subject. Histograms have been presented earlier, so here is how to draw a QQ-plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Draw points on the qq-plot:
qqnorm(dat$Sepal.Length)
# Draw the reference line:
qqline(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-43-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Or a QQ-plot with confidence bands with the &lt;code&gt;qqPlot()&lt;/code&gt; function from the &lt;code&gt;{car}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(car) # package must be installed first
qqPlot(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-44-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## [1] 132 118&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If points are close to the reference line (sometimes referred as Henry’s line) and within the confidence bands, the normality assumption can be considered as met. The bigger the deviation between the points and the reference line and the more they lie outside the confidence bands, the less likely that the normality condition is met. The variable &lt;code&gt;Sepal.Length&lt;/code&gt; does not seem to follow a normal distribution because several points lie outside the confidence bands. When facing a non-normal distribution, the first step is usually to apply the logarithm transformation on the data and recheck to see whether the log-transformed data are normally distributed. Applying the logarithm transformation can be done with the &lt;code&gt;log()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;{ggpubr}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggpubr)
ggqqplot(dat$Sepal.Length)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-45-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;by-groups&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;By groups&lt;/h2&gt;
&lt;p&gt;For some statistical tests, the normality assumption is required in all groups. One solution is to draw a QQ-plot for each group by manually splitting the dataset into different groups and then draw a QQ-plot for each subset of the data (with the methods shown above). Another (easier) solution is to draw a QQ-plot for each group automatically with the argument &lt;code&gt;groups =&lt;/code&gt; in the function &lt;code&gt;qqPlot()&lt;/code&gt; from the &lt;code&gt;{car}&lt;/code&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqPlot(dat$Sepal.Length, groups = dat$size)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-46-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;{ggplot2}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qplot(
  sample = Sepal.Length, data = dat,
  col = size, shape = size
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-47-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It is also possible to differentiate groups by only shape or color. For this, remove one of the argument &lt;code&gt;col&lt;/code&gt; or &lt;code&gt;shape&lt;/code&gt; in the &lt;code&gt;qplot()&lt;/code&gt; function above.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;density-plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Density plot&lt;/h1&gt;
&lt;p&gt;Density plot is a smoothed version of the histogram and is used in the same concept, that is, to represent the distribution of a numeric variable. The functions &lt;code&gt;plot()&lt;/code&gt; and &lt;code&gt;density()&lt;/code&gt; are used together to draw a density plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(density(dat$Sepal.Length))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-48-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;{ggplot2}&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dat) +
  aes(x = Sepal.Length) +
  geom_density()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-in-r_files/figure-html/unnamed-chunk-49-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Correlation plot&lt;/h1&gt;
&lt;p&gt;The last type of descriptive plot is a correlation plot, also called a correlogram. This type of graph is more complex than the ones presented above, so it is detailed in a separate article. See &lt;a href=&#34;/blog/correlogram-in-r-how-to-highlight-the-most-correlated-variables-in-a-dataset/&#34;&gt;how to draw a correlogram to highlight the most correlated variables in a dataset&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;advanced-descriptive-statistics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Advanced descriptive statistics&lt;/h1&gt;
&lt;p&gt;We covered the main functions to compute the most common and basic descriptive statistics. There are, however, many more functions and packages to perform more advanced descriptive statistics in R. In this section, I present some of them with applications to our dataset.&lt;/p&gt;
&lt;div id=&#34;summarytools-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;{summarytools}&lt;/code&gt; package&lt;/h2&gt;
&lt;p&gt;One package for descriptive statistics I often use for my projects in R is the &lt;a href=&#34;https://cran.r-project.org/web/packages/summarytools/index.html&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;{summarytools}&lt;/code&gt;&lt;/a&gt; package. The package is centered around 4 functions:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;code&gt;freq()&lt;/code&gt; for frequencies tables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ctable()&lt;/code&gt; for cross-tabulations&lt;/li&gt;
&lt;li&gt;&lt;code&gt;descr()&lt;/code&gt; for descriptive statistics&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dfSummary()&lt;/code&gt; for dataframe summaries&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A combination of these 4 functions is usually more than enough for most descriptive analyses. Moreover, the package has been built with &lt;a href=&#34;/blog/getting-started-in-r-markdown/&#34;&gt;R Markdown&lt;/a&gt; in mind, meaning that outputs render well in HTML reports. And for non-English speakers, built-in translations exist for French, Portuguese, Spanish, Russian and Turkish.&lt;/p&gt;
&lt;p&gt;I illustrate each of the 4 functions in the following sections. Outputs that follow display much better in R Markdown reports, but in this article I limit myself to the raw outputs as the goal is to show how the functions work, not how to make them render well. See the setup settings in the &lt;a href=&#34;https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html&#34; target=&#34;_blank&#34;&gt;vignette&lt;/a&gt; of the package if you want to print the outputs in a nice way in R Markdown.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;frequency-tables-with-freq&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Frequency tables with &lt;code&gt;freq()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;freq()&lt;/code&gt; function produces frequency tables with frequencies, proportions, as well as missing data information.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(summarytools)
freq(dat$Species)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Frequencies  
## dat$Species  
## Type: Factor  
## 
##                    Freq   % Valid   % Valid Cum.   % Total   % Total Cum.
## ---------------- ------ --------- -------------- --------- --------------
##           setosa     50     33.33          33.33     33.33          33.33
##       versicolor     50     33.33          66.67     33.33          66.67
##        virginica     50     33.33         100.00     33.33         100.00
##             &amp;lt;NA&amp;gt;      0                               0.00         100.00
##            Total    150    100.00         100.00    100.00         100.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not need information about missing values, add the &lt;code&gt;report.nas = FALSE&lt;/code&gt; argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;freq(dat$Species,
     report.nas = FALSE) # remove NA information&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Frequencies  
## dat$Species  
## Type: Factor  
## 
##                    Freq        %   % Cum.
## ---------------- ------ -------- --------
##           setosa     50    33.33    33.33
##       versicolor     50    33.33    66.67
##        virginica     50    33.33   100.00
##            Total    150   100.00   100.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And for a minimalist output with only counts and proportions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;freq(dat$Species,
     report.nas = FALSE, # remove NA information
     totals = FALSE, # remove totals
     cumul = FALSE, # remove cumuls
     headings = FALSE) # remove headings&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##                    Freq       %
## ---------------- ------ -------
##           setosa     50   33.33
##       versicolor     50   33.33
##        virginica     50   33.33&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;cross-tabulations-with-ctable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cross-tabulations with &lt;code&gt;ctable()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ctable()&lt;/code&gt; produces cross-tabulations (contingency tables) for pairs of categorical variables. Using the two categorical variables in our dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ctable(x = dat$Species,
       y = dat$size)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Cross-Tabulation, Row Proportions  
## Species * size  
## Data Frame: dat  
## 
## ------------ ------ ------------ ------------ --------------
##                size          big        small          Total
##      Species                                                
##       setosa           1 ( 2.0%)   49 (98.0%)    50 (100.0%)
##   versicolor          29 (58.0%)   21 (42.0%)    50 (100.0%)
##    virginica          47 (94.0%)    3 ( 6.0%)    50 (100.0%)
##        Total          77 (51.3%)   73 (48.7%)   150 (100.0%)
## ------------ ------ ------------ ------------ --------------&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Row proportions are shown by default. To display column or total proportions, add the &lt;code&gt;prop = &amp;quot;c&amp;quot;&lt;/code&gt; or &lt;code&gt;prop = &amp;quot;t&amp;quot;&lt;/code&gt; arguments, respectively:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ctable(x = dat$Species,
       y = dat$size,
       prop = &amp;quot;t&amp;quot;) # total proportions&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Cross-Tabulation, Total Proportions  
## Species * size  
## Data Frame: dat  
## 
## ------------ ------ ------------ ------------ --------------
##                size          big        small          Total
##      Species                                                
##       setosa           1 ( 0.7%)   49 (32.7%)    50 ( 33.3%)
##   versicolor          29 (19.3%)   21 (14.0%)    50 ( 33.3%)
##    virginica          47 (31.3%)    3 ( 2.0%)    50 ( 33.3%)
##        Total          77 (51.3%)   73 (48.7%)   150 (100.0%)
## ------------ ------ ------------ ------------ --------------&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To remove proportions altogether, add the argument &lt;code&gt;prop = &amp;quot;n&amp;quot;&lt;/code&gt;. To display only the bare minimum, add the &lt;code&gt;totals = FALSE&lt;/code&gt; and &lt;code&gt;headings = FALSE&lt;/code&gt; arguments:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ctable(x = dat$Species,
       y = dat$size,
       prop = &amp;quot;n&amp;quot;, # remove proportions
       totals = FALSE, # remove totals
       headings = FALSE) # remove headings&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ------------ ------ ----- -------
##                size   big   small
##      Species                     
##       setosa            1      49
##   versicolor           29      21
##    virginica           47       3
## ------------ ------ ----- -------&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is equivalent than &lt;code&gt;table(dat$Species, dat$size)&lt;/code&gt; and &lt;code&gt;xtabs(~ dat$Species + dat$size)&lt;/code&gt; performed in the section about &lt;a href=&#34;/blog/descriptive-statistics-in-r/#contingency-table&#34;&gt;contingency tables&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To display results of the &lt;a href=&#34;/blog/chi-square-test-of-independence-in-r/&#34;&gt;Chi-square test of independence&lt;/a&gt;, add the &lt;code&gt;chisq = TRUE&lt;/code&gt; argument:&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ctable(x = dat$Species,
       y = dat$size,
       chisq = TRUE, # display results of Chi-square test
       headings = FALSE) # remove headings&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ------------ ------ ------------ ------------ --------------
##                size          big        small          Total
##      Species                                                
##       setosa           1 ( 2.0%)   49 (98.0%)    50 (100.0%)
##   versicolor          29 (58.0%)   21 (42.0%)    50 (100.0%)
##    virginica          47 (94.0%)    3 ( 6.0%)    50 (100.0%)
##        Total          77 (51.3%)   73 (48.7%)   150 (100.0%)
## ------------ ------ ------------ ------------ --------------
## 
## ----------------------------
##  Chi.squared   df   p.value 
## ------------- ---- ---------
##     86.03      2       0    
## ----------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;em&gt;p&lt;/em&gt;-value is close to 0 so we reject the null hypothesis of independence between the two variables. In our context, this indicates that there is a significant relationship between the species and the size.&lt;/p&gt;
&lt;p&gt;It is also possible to create a contingency table for each level of a third categorical variable thanks to the combination of the &lt;code&gt;stby()&lt;/code&gt; and &lt;code&gt;ctable()&lt;/code&gt; functions. There are only 2 categorical variables in our dataset, so let’s use the &lt;code&gt;tabacco&lt;/code&gt; dataset which has 4 categorical variables (i.e., gender, age group, smoker, diseased). For this example, we would like to create a contingency table of the variables &lt;code&gt;smoker&lt;/code&gt; and &lt;code&gt;diseased&lt;/code&gt;, and for each &lt;code&gt;gender&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stby(list(x = tobacco$smoker,
          y = tobacco$diseased), 
     INDICES = tobacco$gender,
     FUN = ctable)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Cross-Tabulation, Row Proportions  
## smoker * diseased  
## Data Frame: tobacco  
## Group: gender = F  
## 
## -------- ---------- ------------- ------------- --------------
##            diseased           Yes            No          Total
##   smoker                                                      
##      Yes               62 (42.2%)    85 (57.8%)   147 (100.0%)
##       No               49 (14.3%)   293 (85.7%)   342 (100.0%)
##    Total              111 (22.7%)   378 (77.3%)   489 (100.0%)
## -------- ---------- ------------- ------------- --------------
## 
## Group: gender = M  
## 
## -------- ---------- ------------- ------------- --------------
##            diseased           Yes            No          Total
##   smoker                                                      
##      Yes               63 (44.1%)    80 (55.9%)   143 (100.0%)
##       No               47 (13.6%)   299 (86.4%)   346 (100.0%)
##    Total              110 (22.5%)   379 (77.5%)   489 (100.0%)
## -------- ---------- ------------- ------------- --------------&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;descriptive-statistics-with-descr&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Descriptive statistics with &lt;code&gt;descr()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;descr()&lt;/code&gt; produces descriptive (univariate) statistics with common central tendency statistics and measures of dispersion. (See the &lt;a href=&#34;/blog/descriptive-statistics-by-hand/#location-versus-dispersion-measures&#34;&gt;difference between a measure of central tendency and dispersion&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;A major advantage of this function is that it accepts single vectors as well as data frames. If a data frame is provided, all non-numerical columns are ignored so you do not have to remove them yourself.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;descr()&lt;/code&gt; allows to display:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;only a selection of descriptive statistics, with the &lt;code&gt;stats = c(&amp;quot;mean&amp;quot;, &amp;quot;sd&amp;quot;)&lt;/code&gt; argument for mean and standard deviation for example&lt;/li&gt;
&lt;li&gt;the minimum, first quartile, median, third quartile and maximum with &lt;code&gt;stats = &amp;quot;fivenum&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;the most common descriptive statistics (mean, standard deviation, minimum, median, maximum, number and percentage of valid observations), with &lt;code&gt;stats = &amp;quot;common&amp;quot;&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;descr(dat,
      headings = FALSE, # remove headings
      stats = &amp;quot;common&amp;quot;) # most common descriptive statistics)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##                   Petal.Length   Petal.Width   Sepal.Length   Sepal.Width
## --------------- -------------- ------------- -------------- -------------
##            Mean           3.76          1.20           5.84          3.06
##         Std.Dev           1.77          0.76           0.83          0.44
##             Min           1.00          0.10           4.30          2.00
##          Median           4.35          1.30           5.80          3.00
##             Max           6.90          2.50           7.90          4.40
##         N.Valid         150.00        150.00         150.00        150.00
##       Pct.Valid         100.00        100.00         100.00        100.00&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tip: if you have a large number of variables, add the &lt;code&gt;transpose = TRUE&lt;/code&gt; argument for a better display.&lt;/p&gt;
&lt;p&gt;In order to compute these descriptive statistics by group (e.g., &lt;code&gt;Species&lt;/code&gt; in our dataset), use the &lt;code&gt;stby()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stby(data = dat,
     INDICES = dat$Species, # descr. stats by Species
     FUN = descr,
     stats = &amp;quot;common&amp;quot;) # most common descr. stats&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Descriptive Statistics  
## dat  
## Group: Species = setosa  
## N: 50  
## 
##                   Petal.Length   Petal.Width   Sepal.Length   Sepal.Width
## --------------- -------------- ------------- -------------- -------------
##            Mean           1.46          0.25           5.01          3.43
##         Std.Dev           0.17          0.11           0.35          0.38
##             Min           1.00          0.10           4.30          2.30
##          Median           1.50          0.20           5.00          3.40
##             Max           1.90          0.60           5.80          4.40
##         N.Valid          50.00         50.00          50.00         50.00
##       Pct.Valid         100.00        100.00         100.00        100.00
## 
## Group: Species = versicolor  
## N: 50  
## 
##                   Petal.Length   Petal.Width   Sepal.Length   Sepal.Width
## --------------- -------------- ------------- -------------- -------------
##            Mean           4.26          1.33           5.94          2.77
##         Std.Dev           0.47          0.20           0.52          0.31
##             Min           3.00          1.00           4.90          2.00
##          Median           4.35          1.30           5.90          2.80
##             Max           5.10          1.80           7.00          3.40
##         N.Valid          50.00         50.00          50.00         50.00
##       Pct.Valid         100.00        100.00         100.00        100.00
## 
## Group: Species = virginica  
## N: 50  
## 
##                   Petal.Length   Petal.Width   Sepal.Length   Sepal.Width
## --------------- -------------- ------------- -------------- -------------
##            Mean           5.55          2.03           6.59          2.97
##         Std.Dev           0.55          0.27           0.64          0.32
##             Min           4.50          1.40           4.90          2.20
##          Median           5.55          2.00           6.50          3.00
##             Max           6.90          2.50           7.90          3.80
##         N.Valid          50.00         50.00          50.00         50.00
##       Pct.Valid         100.00        100.00         100.00        100.00&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-frame-summaries-with-dfsummary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data frame summaries with &lt;code&gt;dfSummary()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;dfSummary()&lt;/code&gt; generates a summary table with statistics, frequencies and graphs for all variables in a dataset. The information shown depend on the type of the variables (character, factor, numeric, date) and also varies according to the number of distinct values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dfSummary(dat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Data Frame Summary  
## dat  
## Dimensions: 150 x 6  
## Duplicates: 1  
## 
## ----------------------------------------------------------------------------------------------------------------------
## No   Variable        Stats / Values           Freqs (% of Valid)   Graph                            Valid    Missing  
## ---- --------------- ------------------------ -------------------- -------------------------------- -------- ---------
## 1    Sepal.Length    Mean (sd) : 5.8 (0.8)    35 distinct values     . . : :                        150      0        
##      [numeric]       min &amp;lt; med &amp;lt; max:                                : : : :                        (100%)   (0%)     
##                      4.3 &amp;lt; 5.8 &amp;lt; 7.9                                 : : : : :                                        
##                      IQR (CV) : 1.3 (0.1)                            : : : : :                                        
##                                                                    : : : : : : : :                                    
## 
## 2    Sepal.Width     Mean (sd) : 3.1 (0.4)    23 distinct values           :                        150      0        
##      [numeric]       min &amp;lt; med &amp;lt; max:                                      :                        (100%)   (0%)     
##                      2 &amp;lt; 3 &amp;lt; 4.4                                         . :                                          
##                      IQR (CV) : 0.5 (0.1)                              : : : :                                        
##                                                                    . . : : : : : :                                    
## 
## 3    Petal.Length    Mean (sd) : 3.8 (1.8)    43 distinct values   :                                150      0        
##      [numeric]       min &amp;lt; med &amp;lt; max:                              :         . :                    (100%)   (0%)     
##                      1 &amp;lt; 4.3 &amp;lt; 6.9                                 :         : : .                                    
##                      IQR (CV) : 3.5 (0.5)                          : :       : : : .                                  
##                                                                    : :   . : : : : : .                                
## 
## 4    Petal.Width     Mean (sd) : 1.2 (0.8)    22 distinct values   :                                150      0        
##      [numeric]       min &amp;lt; med &amp;lt; max:                              :                                (100%)   (0%)     
##                      0.1 &amp;lt; 1.3 &amp;lt; 2.5                               :       . .   :                                    
##                      IQR (CV) : 1.5 (0.6)                          :       : :   :   .                                
##                                                                    : :   : : : . : : :                                
## 
## 5    Species         1. setosa                50 (33.3%)           IIIIII                           150      0        
##      [factor]        2. versicolor            50 (33.3%)           IIIIII                           (100%)   (0%)     
##                      3. virginica             50 (33.3%)           IIIIII                                             
## 
## 6    size            1. big                   77 (51.3%)           IIIIIIIIII                       150      0        
##      [character]     2. small                 73 (48.7%)           IIIIIIIII                        (100%)   (0%)     
## ----------------------------------------------------------------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;describeby-from-the-psych-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;describeBy()&lt;/code&gt; from the &lt;code&gt;{psych}&lt;/code&gt; package&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;describeBy()&lt;/code&gt; funtion from the &lt;code&gt;{psych}&lt;/code&gt; package allows to report several summary statistics (i.e., number of valid cases, mean, standard deviation, median, mad: median absolute deviation (from the median), minimum, maximum, skewness and kurtosis) by a grouping variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(psych)
describeBy(dat,
           dat$Species) # grouping variable&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Descriptive statistics by group 
## group: setosa
##              vars  n mean   sd median trimmed  mad min  max range skew kurtosis
## Sepal.Length    1 50 5.01 0.35    5.0    5.00 0.30 4.3  5.8   1.5 0.11    -0.45
## Sepal.Width     2 50 3.43 0.38    3.4    3.42 0.37 2.3  4.4   2.1 0.04     0.60
## Petal.Length    3 50 1.46 0.17    1.5    1.46 0.15 1.0  1.9   0.9 0.10     0.65
## Petal.Width     4 50 0.25 0.11    0.2    0.24 0.00 0.1  0.6   0.5 1.18     1.26
## Species*        5 50 1.00 0.00    1.0    1.00 0.00 1.0  1.0   0.0  NaN      NaN
## size*           6 50  NaN   NA     NA     NaN   NA Inf -Inf  -Inf   NA       NA
##                se
## Sepal.Length 0.05
## Sepal.Width  0.05
## Petal.Length 0.02
## Petal.Width  0.01
## Species*     0.00
## size*          NA
## ------------------------------------------------------------ 
## group: versicolor
##              vars  n mean   sd median trimmed  mad min  max range  skew
## Sepal.Length    1 50 5.94 0.52   5.90    5.94 0.52 4.9  7.0   2.1  0.10
## Sepal.Width     2 50 2.77 0.31   2.80    2.78 0.30 2.0  3.4   1.4 -0.34
## Petal.Length    3 50 4.26 0.47   4.35    4.29 0.52 3.0  5.1   2.1 -0.57
## Petal.Width     4 50 1.33 0.20   1.30    1.32 0.22 1.0  1.8   0.8 -0.03
## Species*        5 50 2.00 0.00   2.00    2.00 0.00 2.0  2.0   0.0   NaN
## size*           6 50  NaN   NA     NA     NaN   NA Inf -Inf  -Inf    NA
##              kurtosis   se
## Sepal.Length    -0.69 0.07
## Sepal.Width     -0.55 0.04
## Petal.Length    -0.19 0.07
## Petal.Width     -0.59 0.03
## Species*          NaN 0.00
## size*              NA   NA
## ------------------------------------------------------------ 
## group: virginica
##              vars  n mean   sd median trimmed  mad min  max range  skew
## Sepal.Length    1 50 6.59 0.64   6.50    6.57 0.59 4.9  7.9   3.0  0.11
## Sepal.Width     2 50 2.97 0.32   3.00    2.96 0.30 2.2  3.8   1.6  0.34
## Petal.Length    3 50 5.55 0.55   5.55    5.51 0.67 4.5  6.9   2.4  0.52
## Petal.Width     4 50 2.03 0.27   2.00    2.03 0.30 1.4  2.5   1.1 -0.12
## Species*        5 50 3.00 0.00   3.00    3.00 0.00 3.0  3.0   0.0   NaN
## size*           6 50  NaN   NA     NA     NaN   NA Inf -Inf  -Inf    NA
##              kurtosis   se
## Sepal.Length    -0.20 0.09
## Sepal.Width      0.38 0.05
## Petal.Length    -0.37 0.08
## Petal.Width     -0.75 0.04
## Species*          NaN 0.00
## size*              NA   NA&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;aggregate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;aggregate()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;aggregate()&lt;/code&gt; function allows to split the data into subsets and to compute summary statistics for each. For instance, if we want to compute the mean for the variables &lt;code&gt;Sepal.Length&lt;/code&gt; and &lt;code&gt;Sepal.Width&lt;/code&gt; by &lt;code&gt;Species&lt;/code&gt; and &lt;code&gt;Size&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aggregate(cbind(Sepal.Length, Sepal.Width) ~ Species + size,
          data = dat,
          mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Species  size Sepal.Length Sepal.Width
## 1     setosa   big     5.800000    4.000000
## 2 versicolor   big     6.282759    2.868966
## 3  virginica   big     6.663830    2.997872
## 4     setosa small     4.989796    3.416327
## 5 versicolor small     5.457143    2.633333
## 6  virginica small     5.400000    2.600000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks for reading. I hope this article helped you to do descriptive statistics in R. If you would like to do the same by hand or understand what these statistics represent, read the article “&lt;a href=&#34;/blog/descriptive-statistics-by-hand/&#34;&gt;Descriptive statistics by hand&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by &lt;a href=&#34;https://github.com/AntoineSoetewey/statsandr/issues&#34; target=&#34;_blank&#34;&gt;raising an issue on GitHub&lt;/a&gt;. For all other requests, you can &lt;a href=&#34;/contact/&#34;&gt;contact me&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by &lt;a href=&#34;/subscribe/&#34;&gt;subscribing to this blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related articles:&lt;/strong&gt;&lt;/p&gt;
&lt;script src=&#34;//rss.bloople.net/?url=https%3A%2F%2Fwww.statsandr.com%2Ftags%2Fr%2Findex.xml&amp;detail=-1&amp;limit=5&amp;showtitle=false&amp;type=js&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Normality tests such as Shapiro-Wilk or Kolmogorov-Smirnov tests can also be used to test whether the data follow a normal distribution or not. However, in practice, normality tests are often considered as too conservative in the sense that for large sample size, a small deviation from the normality may cause the normality condition to be violated. For this reason, it is often the case that the normality condition is verified based on a combination of visual inspections (with histograms and QQ-plots) and formal test (Shapiro-Wilk test for instance).&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Note that the &lt;code&gt;plain.ascii&lt;/code&gt; and &lt;code&gt;style&lt;/code&gt; arguments are needed for this package. In our examples, these arguments are added in the settings of each chunk so they are not visible.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Note that it is also possible to compute odds ratio and risk ratio. See the vignette of the package for more information on this matter.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Descriptive statistics by hand</title>
      <link>/blog/descriptive-statistics-by-hand/</link>
      <pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/blog/descriptive-statistics-by-hand/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#location-versus-dispersion-measures&#34;&gt;Location versus dispersion measures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#location&#34;&gt;Location&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#minimum-and-maximum&#34;&gt;Minimum and maximum&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mean&#34;&gt;Mean&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#median&#34;&gt;Median&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#odd-number-of-observations&#34;&gt;Odd number of observations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#even-number-of-observations&#34;&gt;Even number of observations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mean-vs.median&#34;&gt;Mean vs. median&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#st-and-3rd-quartiles&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(1^{st}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3^{rd}\)&lt;/span&gt; quartiles&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#q_0.25-q_0.75-and-q_0.5&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(q_{0.25}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(q_{0.75}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(q_{0.5}\)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-note-on-deciles-and-percentiles&#34;&gt;A note on deciles and percentiles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mode&#34;&gt;Mode&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#mode-for-qualitative-variables&#34;&gt;Mode for qualitative variables&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#dispersion&#34;&gt;Dispersion&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#range&#34;&gt;Range&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#standard-deviation&#34;&gt;Standard deviation&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#standard-deviation-for-a-population&#34;&gt;Standard deviation for a population&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#standard-deviation-for-a-sample&#34;&gt;Standard deviation for a sample&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#variance&#34;&gt;Variance&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#variance-for-a-population&#34;&gt;Variance for a population&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#variance-for-a-sample&#34;&gt;Variance for a sample&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#standard-deviation-vs.variance&#34;&gt;Standard deviation vs. variance&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#notations&#34;&gt;Notations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#interquartile-range&#34;&gt;Interquartile range&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#coefficient-of-variation&#34;&gt;Coefficient of variation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#coefficient-of-variation-vs.standard-deviation&#34;&gt;Coefficient of variation vs. standard deviation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/descriptive-statistics-by-hand_files/descriptive-statistics-by-hand.jpeg&#34; alt=&#34;Photo by Pop &amp;amp; Zebra&#34; style=&#34;width:100.0%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Photo by Pop &amp;amp; Zebra&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This article explains how to compute the main descriptive statistics by hand and how to interpret them. To learn how to compute these measures in R, read the article “&lt;a href=&#34;/blog/descriptive-statistics-in-r/&#34;&gt;Descriptive statistics in R&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;Descriptive statistics (in the broad sense of the term) is a branch of statistics aiming at summarizing, describing and presenting a series of values or a dataset. Long series of values without any preparation or without any summary measures are often not informative due to the difficulty of recognizing any pattern in the data. Below an example with the height (in cm) of a population of 100 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;188.7&lt;/em&gt;, &lt;em&gt;169.4&lt;/em&gt;, &lt;em&gt;178.6&lt;/em&gt;, &lt;em&gt;181.3&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt;, &lt;em&gt;173.9&lt;/em&gt;, &lt;em&gt;190.1&lt;/em&gt;, &lt;em&gt;174.1&lt;/em&gt;, &lt;em&gt;195.2&lt;/em&gt;, &lt;em&gt;174.4&lt;/em&gt;, &lt;em&gt;188&lt;/em&gt;, &lt;em&gt;197.9&lt;/em&gt;, &lt;em&gt;161.1&lt;/em&gt;, &lt;em&gt;172.2&lt;/em&gt;, &lt;em&gt;173.7&lt;/em&gt;, &lt;em&gt;181.4&lt;/em&gt;, &lt;em&gt;172.2&lt;/em&gt;, &lt;em&gt;148.4&lt;/em&gt;, &lt;em&gt;150.6&lt;/em&gt;, &lt;em&gt;188.2&lt;/em&gt;, &lt;em&gt;171.9&lt;/em&gt;, &lt;em&gt;157.2&lt;/em&gt;, &lt;em&gt;173.3&lt;/em&gt;, &lt;em&gt;187.1&lt;/em&gt;, &lt;em&gt;194&lt;/em&gt;, &lt;em&gt;170.7&lt;/em&gt;, &lt;em&gt;172.4&lt;/em&gt;, &lt;em&gt;157.4&lt;/em&gt;, &lt;em&gt;179.6&lt;/em&gt;, &lt;em&gt;168.6&lt;/em&gt;, &lt;em&gt;179.6&lt;/em&gt;, &lt;em&gt;182&lt;/em&gt;, &lt;em&gt;185.4&lt;/em&gt;, &lt;em&gt;168.9&lt;/em&gt;, &lt;em&gt;180&lt;/em&gt;, &lt;em&gt;157.8&lt;/em&gt;, &lt;em&gt;167.2&lt;/em&gt;, &lt;em&gt;166.5&lt;/em&gt;, &lt;em&gt;150.9&lt;/em&gt;, &lt;em&gt;175.4&lt;/em&gt;, &lt;em&gt;177.1&lt;/em&gt;, &lt;em&gt;171.4&lt;/em&gt;, &lt;em&gt;182.6&lt;/em&gt;, &lt;em&gt;167.7&lt;/em&gt;, &lt;em&gt;161.3&lt;/em&gt;, &lt;em&gt;179.3&lt;/em&gt;, &lt;em&gt;166.9&lt;/em&gt;, &lt;em&gt;189.4&lt;/em&gt;, &lt;em&gt;170.7&lt;/em&gt;, &lt;em&gt;181.6&lt;/em&gt;, &lt;em&gt;178.2&lt;/em&gt;, &lt;em&gt;167.2&lt;/em&gt;, &lt;em&gt;190.8&lt;/em&gt;, &lt;em&gt;181.4&lt;/em&gt;, &lt;em&gt;175.9&lt;/em&gt;, &lt;em&gt;177.8&lt;/em&gt;, &lt;em&gt;181.8&lt;/em&gt;, &lt;em&gt;175.9&lt;/em&gt;, &lt;em&gt;145.1&lt;/em&gt;, &lt;em&gt;177.8&lt;/em&gt;, &lt;em&gt;171.3&lt;/em&gt;, &lt;em&gt;176.9&lt;/em&gt;, &lt;em&gt;180.8&lt;/em&gt;, &lt;em&gt;189&lt;/em&gt;, &lt;em&gt;167.7&lt;/em&gt;, &lt;em&gt;188&lt;/em&gt;, &lt;em&gt;178.4&lt;/em&gt;, &lt;em&gt;185.4&lt;/em&gt;, &lt;em&gt;184.2&lt;/em&gt;, &lt;em&gt;182.2&lt;/em&gt;, &lt;em&gt;164.6&lt;/em&gt;, &lt;em&gt;174.1&lt;/em&gt;, &lt;em&gt;181.2&lt;/em&gt;, &lt;em&gt;165.5&lt;/em&gt;, &lt;em&gt;169.6&lt;/em&gt;, &lt;em&gt;180.8&lt;/em&gt;, &lt;em&gt;182.7&lt;/em&gt;, &lt;em&gt;179.6&lt;/em&gt;, &lt;em&gt;166.1&lt;/em&gt;, &lt;em&gt;164&lt;/em&gt;, &lt;em&gt;190.1&lt;/em&gt;, &lt;em&gt;177.6&lt;/em&gt;, &lt;em&gt;175.9&lt;/em&gt;, &lt;em&gt;173.8&lt;/em&gt;, &lt;em&gt;163.1&lt;/em&gt;, &lt;em&gt;181.1&lt;/em&gt;, &lt;em&gt;172.8&lt;/em&gt;, &lt;em&gt;173.2&lt;/em&gt;, &lt;em&gt;184.3&lt;/em&gt;, &lt;em&gt;183.2&lt;/em&gt;, &lt;em&gt;188.9&lt;/em&gt;, &lt;em&gt;170.2&lt;/em&gt;, &lt;em&gt;181.5&lt;/em&gt;, &lt;em&gt;188.9&lt;/em&gt;, &lt;em&gt;163.9&lt;/em&gt;, &lt;em&gt;166.4&lt;/em&gt;, &lt;em&gt;163.7&lt;/em&gt;, &lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Facing this series, it is hard (not to say impossible) for anyone to understand the data and have a clear view of the size of these adults in a reasonable amount of time. Descriptive statistics allow to summarize, and thus have a better overview of the data. Of course, by summarizing data through one or several measures, some information will inevitably be lost. However, in many cases it is generally better to lose some information but in return gain an overview.&lt;/p&gt;
&lt;p&gt;Descriptive statistics is often the first step and an important part in any statistical analysis. It allows to check the quality of the data by detecting potential outliers (i.e., data points that appear to be separated from the rest of the data), collection or encoding errors. It also helps to “understand” the data and if well presented, descriptive statistics is already a good starting point for further analyses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;location-versus-dispersion-measures&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Location versus dispersion measures&lt;/h1&gt;
&lt;p&gt;Several different measures (called statistics if we are analyzing a sample) are used to summarize the data. Some of them give an understanding about the location of the data, others give and understanding about the dispersion of the data. In practice, both types of measures are often used together in order to summarize the data in the most concise but complete way. We illustrate this point with the graph below, representing the height (in cm) of 100 persons divided into two groups (50 persons in each group):&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/blog/descriptive-statistics-by-hand_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;100%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The black line corresponds to the mean. The mean height (in cm) is similar in both groups. However, it is clear that the dispersion of heights are very different in the two groups. For this reason, location or dispersion measures are often not enough if presented individually and it is a good practice to present several statistics from both types of measures.&lt;/p&gt;
&lt;p&gt;In the following sections, we detail the most common location and dispersion measures and illustrate them with examples.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;location&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Location&lt;/h1&gt;
&lt;p&gt;Location measures allow to see “where” the data are located, around which values. In other words, location measures give an understanding on what is the central tendency, the “position” of the data as a whole. It includes the following statistics (others exist but we focus on the most common ones):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;minimum&lt;/li&gt;
&lt;li&gt;maximum&lt;/li&gt;
&lt;li&gt;mean&lt;/li&gt;
&lt;li&gt;median&lt;/li&gt;
&lt;li&gt;first quartile&lt;/li&gt;
&lt;li&gt;third quartile&lt;/li&gt;
&lt;li&gt;mode&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We detail and compute by hand each of them in the following sections.&lt;/p&gt;
&lt;div id=&#34;minimum-and-maximum&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Minimum and maximum&lt;/h2&gt;
&lt;p&gt;Minimum (&lt;span class=&#34;math inline&#34;&gt;\(min\)&lt;/span&gt;) and maximum (&lt;span class=&#34;math inline&#34;&gt;\(max\)&lt;/span&gt;) are simply the lowest and largest values, respectively. Given the height (in cm) of a sample of 6 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;188.7&lt;/em&gt;, &lt;em&gt;169.4&lt;/em&gt;, &lt;em&gt;178.6&lt;/em&gt;, &lt;em&gt;181.3&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt; and &lt;em&gt;173.9&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The minimum is 169.4 cm and the maximum is 188.7 cm. These two basic statistics give a clear idea about the size of the smallest and tallest of these 6 adults.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mean&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mean&lt;/h2&gt;
&lt;p&gt;The mean, also known as average, is probably the most common statistics. It gives an idea on what is the average value, that is, the central value of the data or in other words the center of gravity. The mean is found by summing all values and dividing this sum by the number of observations (denoted &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[mean = \bar{x} = \frac{\text{sum of all values}}{\text{number of values}} = \frac{1}{n}\sum^{n}_{i = 1} x_i\]&lt;/span&gt;
Below a visual representation of the mean:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/descriptive-statistics-by-hand_files/mean.png&#34; alt=&#34;Mean. Source: LFSAB1105 at UCLouvain&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Mean. Source: LFSAB1105 at UCLouvain&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Given our sample of 6 adults presented above, the mean is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\bar{x} = \frac{188.7 + 169.4 + 178.6 + 181.3 + 179 + 173.9}{6}\\ = 178.4833\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, the mean size, that is, the average size of our sample of 6 adults is 178.48 cm (rounded to 2 decimals).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;median&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Median&lt;/h2&gt;
&lt;p&gt;The median is another measure of location so it also gives an idea about the central tendency of the data. The interpretation of the median is that there are as many observations below as above the median. In other words, 50% of the observations lie below the median, and 50% of the observations lie above the median. Below a visual representation of the median:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/descriptive-statistics-by-hand_files/median.png&#34; alt=&#34;Median. Source: LFSAB1105 at UCLouvain&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Median. Source: LFSAB1105 at UCLouvain&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The easiest way to compute the median is by first sorting the data from lowest to highest (i.e., in ascending order) then take the middle point as the median. From the sorted values, for an odd number of observations, the middle point is easy to find: it is the value with as many observations below as above. Still from the sorted values, for an even number of observations, the middle point is exactly between the two middle values. Formally, after sorting, the median is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; (number of observations) is odd: &lt;span class=&#34;math display&#34;&gt;\[med(x) = x_{\frac{n+1}{2}}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;if &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is even: &lt;span class=&#34;math display&#34;&gt;\[med(x) = \frac{1}{2}\big(x_{\frac{n}{2}} + x_{\frac{n}{2} + 1}\big)\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;where the subscript of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; denotes the numbering of the sorted data. The formulas look harder than they really are, so let’s see with two concrete examples.&lt;/p&gt;
&lt;div id=&#34;odd-number-of-observations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Odd number of observations&lt;/h3&gt;
&lt;p&gt;Given the height of a sample of 7 adults taken from the 100 adults presented in the introduction:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;188.9&lt;/em&gt;, &lt;em&gt;163.9&lt;/em&gt;, &lt;em&gt;166.4&lt;/em&gt;, &lt;em&gt;163.7&lt;/em&gt;, &lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We first sort the order from lowest to highest:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;163.7&lt;/em&gt;, &lt;em&gt;163.9&lt;/em&gt;, &lt;em&gt;166.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt;, &lt;em&gt;181.5&lt;/em&gt; and &lt;em&gt;188.9&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Given that the number of observations &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is odd (since &lt;span class=&#34;math inline&#34;&gt;\(n = 7\)&lt;/span&gt;), the median is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[med(x) = x_\frac{7 + 1}{2} = x_4\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So we take the fourth value from the sorted values, which corresponds to 166.4. In conclusion, the median size of these 7 adults is 166.4 cm. As you can see, there are 3 observations below 166.4 and 3 observations above 166.4 cm.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;even-number-of-observations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Even number of observations&lt;/h3&gt;
&lt;p&gt;Now let’s see when the number of observations is even, which is slightly more complicated than when the number of observations is odd. Given the height of a sample of 6 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;188.7&lt;/em&gt;, &lt;em&gt;169.4&lt;/em&gt;, &lt;em&gt;178.6&lt;/em&gt;, &lt;em&gt;181.3&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt; and &lt;em&gt;173.9&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We sort the values in ascending order:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;169.4&lt;/em&gt;, &lt;em&gt;173.9&lt;/em&gt;, &lt;em&gt;178.6&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt;, &lt;em&gt;181.3&lt;/em&gt; and &lt;em&gt;188.7&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Given that the number of observations &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is even (since &lt;span class=&#34;math inline&#34;&gt;\(n = 6\)&lt;/span&gt;), the median is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[med(x) = \frac{1}{2}\big(x_{\frac{6}{2}} + x_{\frac{6}{2} + 1}\big) = \frac{1}{2}\big(x_{3} + x_{4}\big)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So we sum the third and fourth values from the sorted values and divide this sum by 2 (which is equivalent than taking the mean of these two middle values):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{1}{2}(178.6 + 179) = 178.8\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, the median size of these 6 adults is 178.8 cm. Again, remark that there are as many observations below as above 178.8 cm.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mean-vs.median&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mean vs. median&lt;/h2&gt;
&lt;p&gt;Although the mean and median are often relatively close to each other they should not be confused since they both have advantages and disadvantages in different contexts. Besides the fact that almost everyone knows (or at least have heard about) the mean, it has the advantage that it gives a unique picture for each different series of data. However, it has the disadvantage that the mean is sensible to outliers (i.e., extreme values). On the other hand, the advantage of the median is that it is resistant to outliers and the inconvenient is that it may be the exact same value for very different series of data (so not unique to the data).&lt;/p&gt;
&lt;p&gt;To illustrate the “sensible to outlier” argument, consider 3 friends in a bar comparing their salaries. Their salaries are &lt;em&gt;1800&lt;/em&gt;, &lt;em&gt;2000&lt;/em&gt; and &lt;em&gt;2100&lt;/em&gt;€, for an average (mean) salary of &lt;em&gt;1967&lt;/em&gt;€. A friend of them (who happens to be friend with Bill Gates as well) joins them in the bar. Their salaries are now &lt;em&gt;1800&lt;/em&gt;, &lt;em&gt;2000&lt;/em&gt;, &lt;em&gt;2100&lt;/em&gt; and &lt;em&gt;1000000&lt;/em&gt;€. The average salary of the 4 friends is now &lt;em&gt;251475&lt;/em&gt;€, compared to &lt;em&gt;1967&lt;/em&gt;€ without the rich friend. Although it is statistically correct to say that the average salary of the 4 friends is &lt;em&gt;251475&lt;/em&gt;€, you will concede that this measure does not represent a fair image of the salaries of the 4 friends, as 3 of them earn much less than the average salary. As we have just seen, the mean is sensible to outliers. On the other hand, if we report the medians, we see that the median salary of the 3 first friends is &lt;em&gt;2000&lt;/em&gt;€, and the median salary of the 4 friends is &lt;em&gt;2050&lt;/em&gt;€. As you can see with this example, the median is not sensible to outliers and for series with such extreme value(s), the median is more appropriate compared to the mean as it often gives a better representation of the data. (&lt;em&gt;Note:&lt;/em&gt; this example also shows how a large majority of people earn less than the average salary reported in the news. This is however beyond the scope of the article.)&lt;/p&gt;
&lt;p&gt;Given the previous example, one may then choose to always use the median instead of the mean. However, the median has it own inconvenient which the mean does not have: the median is less unique and less specific to its underlying data than the mean. Consider the following data, representing the grades of 5 students taking a statistics and economics exam:&lt;/p&gt;
&lt;table style=&#34;width:51%;&#34;&gt;
&lt;colgroup&gt;
&lt;col width=&#34;16%&#34; /&gt;
&lt;col width=&#34;16%&#34; /&gt;
&lt;col width=&#34;18%&#34; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;studentID&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;economics&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;statistics&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;20&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The median of the grades is the same in economics and statistics (median = &lt;em&gt;10&lt;/em&gt;). Therefore, had we computed only the medians, we could have concluded that the students performed as well in economics as in statistics. However, although the medians are exactly the same for both classes, it is clear that students performed better in economics than in statistics. In fact, the mean of the grades in economics is &lt;em&gt;13.6&lt;/em&gt; and the mean of the grades in statistics is &lt;em&gt;8.6&lt;/em&gt;. What we have just shown here is that the median is based only on one single value, the middle value, or on the two middle values if there are an even number of observations, while the mean is based on all values (and thus includes more information). The median is therefore not sensible to outliers, but it is also not unique (i.e., not specific) to different series of data, whereas the mean is much more likely to be different and unique for different series of data. This difference in terms of specificity and uniqueness between the two measures may make the mean more useful for data with no outlier.&lt;/p&gt;
&lt;p&gt;In conclusion, depending on the context and the data, it is often more interesting to report the mean or the median, or both. As a last remark regarding the comparison between the two most important location measures, note that when the mean and median are equal, the distribution of your data can often be considered to follow a normal distribution (also referred as Gaussian distribution).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;st-and-3rd-quartiles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;math inline&#34;&gt;\(1^{st}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(3^{rd}\)&lt;/span&gt; quartiles&lt;/h2&gt;
&lt;p&gt;The first and third quartiles are similar to the median in the sense that they also divide the observations into two parts, except that these parts are not equal. Remind that the median divides the data into two equal parts (with 50% of the observations below and 50% above the median). The first quartile cuts the observations such that there are 25% of the observations &lt;strong&gt;below&lt;/strong&gt; and thus 75% &lt;strong&gt;above&lt;/strong&gt; the first quartile. The third quartile, as you have guessed by now, represents the value with 75% of the observations below it and thus 25% of the observations above it. There exists several methods to compute the first and third quartile (which sometimes give slight differences, R for instance uses a different method), but here is I believe the easiest one when computing these statistics by hand:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;sort the data in ascending order&lt;/li&gt;
&lt;li&gt;compute &lt;span class=&#34;math inline&#34;&gt;\(0.25 \cdot n\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(0.75 \cdot n\)&lt;/span&gt; (i.e., 0.25 and 0.75 times the number of observations)&lt;/li&gt;
&lt;li&gt;round up these two numbers to the next whole number&lt;/li&gt;
&lt;li&gt;these two numbers represent the rank of the first and third quartile (in the sorted series), respectively&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The steps are the same for both an odd and even number of observations. Here is an example with the following series, representing the height in cm of 9 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;170.2&lt;/em&gt;, &lt;em&gt;181.5&lt;/em&gt;, &lt;em&gt;188.9&lt;/em&gt;, &lt;em&gt;163.9&lt;/em&gt;, &lt;em&gt;166.4&lt;/em&gt;, &lt;em&gt;163.7&lt;/em&gt;, &lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We first order from lowest to highest:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;163.7&lt;/em&gt;, &lt;em&gt;163.9&lt;/em&gt;, &lt;em&gt;166.4&lt;/em&gt;, &lt;em&gt;170.2&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt;, &lt;em&gt;181.5&lt;/em&gt;, &lt;em&gt;181.5&lt;/em&gt; and &lt;em&gt;188.9&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There are 9 observations so &lt;span class=&#34;math display&#34;&gt;\[0.25 \cdot 9 = 2.25\]&lt;/span&gt; and &lt;span class=&#34;math display&#34;&gt;\[0.75 \cdot 9 = 6.75\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Rounding up to the whole number gives 3 and 7, which represent the rank of the first and third quartiles, respectively. Therefore, the first quartile is 163.9 cm and the third quartile is 181.5 cm.&lt;/p&gt;
&lt;p&gt;In conclusion, 25% of adults are less than 163.9 cm tall (and thus 75% of them are more than 163.9 cm tall), while 75% of adults are less than 181.5 cm tall (and thus 25% of them are more than 181.5 cm tall).&lt;/p&gt;
&lt;div id=&#34;q_0.25-q_0.75-and-q_0.5&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(q_{0.25}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(q_{0.75}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(q_{0.5}\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Note that the first quartile is denoted &lt;span class=&#34;math inline&#34;&gt;\(q_{0.25}\)&lt;/span&gt; and the third quartile is denoted &lt;span class=&#34;math inline&#34;&gt;\(q_{0.75}\)&lt;/span&gt; (where &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt; stands for quartile). As you can see, the median is actually the second quartile and for this reason it is also sometimes denoted &lt;span class=&#34;math inline&#34;&gt;\(q_{0.5}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-note-on-deciles-and-percentiles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A note on deciles and percentiles&lt;/h3&gt;
&lt;p&gt;Deciles and percentiles are similar to quartiles except that they cuts the data in 10 and 100 equal parts. For instance, the &lt;span class=&#34;math inline&#34;&gt;\(4^{th}\)&lt;/span&gt; decile (&lt;span class=&#34;math inline&#34;&gt;\(q_{0.4}\)&lt;/span&gt;) is the value such that there are 40% of the observations below it and thus 60% of the observations above it. Furthermore, the &lt;span class=&#34;math inline&#34;&gt;\(98^{th}\)&lt;/span&gt; percentile (&lt;span class=&#34;math inline&#34;&gt;\(q_{0.98}\)&lt;/span&gt;, also sometimes denoted &lt;span class=&#34;math inline&#34;&gt;\(P98\)&lt;/span&gt;) is the value such that there are 98% of the observations below it and thus 2% of the observations above it. Percentiles are often used for the weight and height of babies, giving precise information to the parents about where their child stands compared to other children of the same age.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mode&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mode&lt;/h2&gt;
&lt;p&gt;The mode of a series is the value that appears most often. In other words, it is the value that has the highest number of occurrences. Given the height of 9 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;170&lt;/em&gt;, &lt;em&gt;168&lt;/em&gt;, &lt;em&gt;171&lt;/em&gt;, &lt;em&gt;170&lt;/em&gt;, &lt;em&gt;182&lt;/em&gt;, &lt;em&gt;165&lt;/em&gt;, &lt;em&gt;170&lt;/em&gt;, &lt;em&gt;189&lt;/em&gt; and &lt;em&gt;167&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The mode is 170 because it is the most common value with 3 occurrences. All other values appear only once. In conclusion, most adults of this sample are 170 cm tall. Note that it is possible that a series has no mode (e.g., &lt;em&gt;4&lt;/em&gt;, &lt;em&gt;7&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt; and &lt;em&gt;10&lt;/em&gt;) or more than one mode (e.g., &lt;em&gt;4&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;, &lt;em&gt;2&lt;/em&gt;, &lt;em&gt;8&lt;/em&gt;, &lt;em&gt;11&lt;/em&gt; and &lt;em&gt;11&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Data with two modes are often called bimodal and data with more than two modes are often called multimodal, as opposed to series with one mode which are referred as unimodal.&lt;/p&gt;
&lt;div id=&#34;mode-for-qualitative-variables&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mode for qualitative variables&lt;/h3&gt;
&lt;p&gt;Unlike the previous descriptive statistics (i.e., min, max, mean, median, first and third quartile) that can only be computed for quantitative variables, the mode can be computed for quantitative &lt;strong&gt;and&lt;/strong&gt; qualitative variables (see a recap of the different &lt;a href=&#34;/blog/variable-types-and-examples/&#34;&gt;types of variables&lt;/a&gt; if you do not remember the difference). Given the eye color of the 9 adults presented above:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;brown&lt;/em&gt;, &lt;em&gt;brown&lt;/em&gt;, &lt;em&gt;brown&lt;/em&gt;, &lt;em&gt;brown&lt;/em&gt;, &lt;em&gt;blue&lt;/em&gt;, &lt;em&gt;blue&lt;/em&gt;, &lt;em&gt;blue&lt;/em&gt;, &lt;em&gt;brown&lt;/em&gt; and &lt;em&gt;green&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The mode is brown, so most adults of this sample have brown eyes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;dispersion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dispersion&lt;/h1&gt;
&lt;p&gt;All previous descriptive statistics helps to get a sense of the location and position of the data. We now present the most common dispersion measures, which help to get a sense of the dispersion and the variability of the data (to which extent a distribution is squeezed or stretched):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;range&lt;/li&gt;
&lt;li&gt;standard deviation&lt;/li&gt;
&lt;li&gt;variance&lt;/li&gt;
&lt;li&gt;interquartile range&lt;/li&gt;
&lt;li&gt;coefficient of variation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As for location measures, we detail and compute by hand each of these statistics one by one.&lt;/p&gt;
&lt;div id=&#34;range&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Range&lt;/h2&gt;
&lt;p&gt;The range is the difference between the maximum and the minimum value:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[range = max - min\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given the height (in cm) of our sample of 6 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;188.7&lt;/em&gt;, &lt;em&gt;169.4&lt;/em&gt;, &lt;em&gt;178.6&lt;/em&gt;, &lt;em&gt;181.3&lt;/em&gt;, &lt;em&gt;179&lt;/em&gt; and &lt;em&gt;173.9&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The range is 188.7 &lt;span class=&#34;math inline&#34;&gt;\(-\)&lt;/span&gt; 169.4 &lt;span class=&#34;math inline&#34;&gt;\(=\)&lt;/span&gt; 19.3 cm. The advantage of the range is that it is extremely easy to compute it and it gives a precise idea on what are the possible values in the data. The disadvantage is that it relies on the two most extreme values only.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-deviation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Standard deviation&lt;/h2&gt;
&lt;p&gt;The standard deviation is the most common dispersion measure in statistics. Like the mean for the location measures, if we have to present one statistics which summarizes the spread of the data, it is usually the standard deviation. As its name suggests, the standard deviation tells what is the “normal” deviation of the data. It actually computes the average deviation from the &lt;strong&gt;mean&lt;/strong&gt;. The larger the standard deviation, the more scattered the data are. On the contrary, the smaller the standard deviation, the more the data are centred around the mean. Below a visual representation of the standard deviation:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/descriptive-statistics-by-hand_files/standard-deviation.png&#34; alt=&#34;Standard deviation. Source: LFSAB1105 at UCLouvain&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Standard deviation. Source: LFSAB1105 at UCLouvain&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The standard deviation is a bit more complex than the previous statistics in the sense that there are two formulas depending on whether we face a sample or a population. A population includes all members from a specified group, all possible outcomes or measurements that are of interest. A sample consists of some observations drawn from the population, so a part or a subset of the population. For instance, the population may be “&lt;strong&gt;all&lt;/strong&gt; people living in Belgium” and the sample may be “&lt;strong&gt;some&lt;/strong&gt; people living in Belgium”. Read this article on &lt;a href=&#34;/blog/what-is-the-difference-between-population-and-sample/&#34;&gt;the difference between population and sample&lt;/a&gt; if you want to learn more.&lt;/p&gt;
&lt;div id=&#34;standard-deviation-for-a-population&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Standard deviation for a population&lt;/h3&gt;
&lt;p&gt;The standard deviation for a population, denoted &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma = \sqrt{\frac{1}{n}\sum^n_{i = 1}(x_i - \mu)^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As you can see from the formula, the standard deviation is actually the average deviation of the data from their mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. Note the square for the difference between the observations and the mean to avoid that negative differences are compensated by positive differences.&lt;/p&gt;
&lt;p&gt;For the sake of easiness, imagine a population of only 3 adults (the steps are the same with a large population, the computation is just longer). Below their heights (in cm):&lt;/p&gt;
&lt;p&gt;&lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The mean is 172.6 (rounded to 1 decimal). The standard deviation is thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma = \sqrt{\frac{1}{3} \big[(160.4 - 172.6)^2 + (175.8 - 172.6)^2 \\ + (181.5 - 172.6)^2 \big]}\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\sigma = 8.91\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, the standard deviation for the heights of these 3 adults is 8.91 cm. This means that, on average, the height of the adults in this population deviates from the mean by 8.91 cm.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-deviation-for-a-sample&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Standard deviation for a sample&lt;/h3&gt;
&lt;p&gt;The standard deviation for a sample is similar to the standard deviation for a population except that we divide by &lt;span class=&#34;math inline&#34;&gt;\(n -1\)&lt;/span&gt; instead of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; and it is denoted &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s = \sqrt{\frac{1}{n-1}\sum^n_{i = 1}(x_i - \bar{x})^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Imagine now that the 3 adults presented in the previous section is a sample instead of a population:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The mean is still 172.6 (rounded to 1 decimal) since the mean is the same whether it is a population or a sample. The standard deviation is now:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s = \sqrt{\frac{1}{3 - 1} \big[(160.4 - 172.6)^2 + (175.8 - 172.6)^2 \\ + (181.5 - 172.6)^2 \big]}\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[s = 10.92\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, the standard deviation for the heights of these 3 adults is 10.92 cm. The interpretation is the same than for a population.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variance&lt;/h2&gt;
&lt;p&gt;The variance is simply the square of the standard deviation. Put it another way, the standard deviation is the square root of the variance. We also distinguish between the variance for a population and for a sample.&lt;/p&gt;
&lt;div id=&#34;variance-for-a-population&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variance for a population&lt;/h3&gt;
&lt;p&gt;The variance for a population, denoted &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;, is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma^2 = \frac{1}{n}\sum^n_{i = 1}(x_i - \mu)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As you can see, the formula for variance is the same than for standard deviation, except that the square root is removed for the variance. Remember the heights of our population of 3 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The standard deviation was 8.91 cm, so the variance of the height of these adults is &lt;span class=&#34;math inline&#34;&gt;\(8.91^2 = 79.39\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(cm^2\)&lt;/span&gt; (see below why the unit of a variance is &lt;span class=&#34;math inline&#34;&gt;\(unit^2\)&lt;/span&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-for-a-sample&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variance for a sample&lt;/h3&gt;
&lt;p&gt;Again, the variance for a sample is similar to the variance for a population except that we divide by &lt;span class=&#34;math inline&#34;&gt;\(n -1\)&lt;/span&gt; instead of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; and it is denoted &lt;span class=&#34;math inline&#34;&gt;\(s^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[s^2 = \frac{1}{n-1}\sum^n_{i = 1}(x_i - \bar{x})^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Imagine again that the 3 adults in the previous section is a sample instead of a population:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The standard deviation for this sample was 10.92 cm, so the variance of the height of these adults is 119.14 &lt;span class=&#34;math inline&#34;&gt;\(cm^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;standard-deviation-vs.variance&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Standard deviation vs. variance&lt;/h2&gt;
&lt;p&gt;Standard deviation and variance are often used interchangeably and both quantify the spread of a given dataset by measuring how far the observations are from their mean. However, the standard deviation can be more easily interpreted because the unit for the standard deviation is the same than the unit of measurement of the data (while it is the &lt;span class=&#34;math inline&#34;&gt;\(unit^2\)&lt;/span&gt; for the variance). Following our example of adult heights in cm, the standard deviation is measured in cm while the variance is measured in &lt;span class=&#34;math inline&#34;&gt;\(cm^2\)&lt;/span&gt;. The fact that the standard deviation keeps the same unit than the initial unit of measurement makes it more interpretable and thus often more used in practice.&lt;/p&gt;
&lt;div id=&#34;notations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Notations&lt;/h3&gt;
&lt;p&gt;For completeness, below a table showing the different notations for variance and standard deviation in case of population and sample:&lt;/p&gt;
&lt;center&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Population&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Sample&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Standard deviation&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Variance&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(s^2\)&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;interquartile-range&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interquartile range&lt;/h2&gt;
&lt;p&gt;Remember the first &lt;span class=&#34;math inline&#34;&gt;\(q_{0.25}\)&lt;/span&gt; and third quartile &lt;span class=&#34;math inline&#34;&gt;\(q_{0.75}\)&lt;/span&gt; presented earlier. The interquartile range is another measure of dispersion of the data, using the quartiles. It is the difference between the third and first quartile:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[IQR = q_{0.75} - q_{0.25}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Considering the height of the 9 adults presented in the section about the first and third quartile:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;170.2&lt;/em&gt;, &lt;em&gt;181.5&lt;/em&gt;, &lt;em&gt;188.9&lt;/em&gt;, &lt;em&gt;163.9&lt;/em&gt;, &lt;em&gt;166.4&lt;/em&gt;, &lt;em&gt;163.7&lt;/em&gt;, &lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The first quartile was 163.9 cm and the third quartile was 181.5 cm. The IQR is thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[IQR = 181.5 - 163.9 = 17.6\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, the interquartile range is 17.6 cm. The interquartile range is actually the range (since it is the difference between a higher and a lower value) of the middle data. The graph below may help to understand better the IQR and the quartiles:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/blog/descriptive-statistics-by-hand_files/IQR-quartiles.png&#34; alt=&#34;IQR, first and third quartile. Source: LFSAB1105 at UCLouvain&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;IQR, first and third quartile. Source: LFSAB1105 at UCLouvain&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;coefficient-of-variation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Coefficient of variation&lt;/h2&gt;
&lt;p&gt;The last dispersion measure is the coefficient of variation. The coefficient of variation, denoted &lt;span class=&#34;math inline&#34;&gt;\(CV\)&lt;/span&gt;, is the standard deviation divided by the mean. Formally:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[CV = \frac{s}{\bar{x}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Consider the height of a sample of 4 adults:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;163.7&lt;/em&gt;, &lt;em&gt;160.4&lt;/em&gt;, &lt;em&gt;175.8&lt;/em&gt; and &lt;em&gt;181.5&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The mean is &lt;span class=&#34;math inline&#34;&gt;\(\bar{x} =\)&lt;/span&gt; 170.35 cm and the standard deviation is &lt;span class=&#34;math inline&#34;&gt;\(s =\)&lt;/span&gt; 9.95 cm. (Find the same values as an exercise!) The coefficient of variation is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[CV = \frac{9.95 \text{ cm}}{170.35 \text{ cm}} = 0.058 = 5.8\%\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, the coefficient of variation is 5.8%. Note that, as a rule of thumb, a coefficient of variation greater than 15% usually means that the data are heterogeneous while a coefficient of variation equal to or less than 15% means that the data are homogeneous. Given that the coefficient of variation equals 5.8% in this case, we can conclude that these 4 adults are homogeneous in terms of height.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;coefficient-of-variation-vs.standard-deviation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Coefficient of variation vs. standard deviation&lt;/h2&gt;
&lt;p&gt;Although the coefficient of variation is rather unknown to the public, it is, in fact, worth presenting when making descriptive statistics.&lt;/p&gt;
&lt;p&gt;The standard deviation should always be understood in the context of the mean of the data and is dependent on its unit. The standard deviation has the advantage that it tells by how far on average the data is from the mean in terms of unit in which the data has been measured. Standard deviation is useful when considering variables with same units and approximately same means. However, standard deviation becomes less useful when comparing variables with different units or widely different means. For instance, a variable with a standard deviation of 10 cm cannot be compared to a variable with a standard deviation of 10€ to conclude which one is the most dispersed.&lt;/p&gt;
&lt;p&gt;The coefficient of variation is a ratio of two statistics with the same units. It has thus no unit and is independent of the unit in which the data has been measured. Being unit-free, coefficients of variation computed on datasets or variables with different units or widely different means can be compared to conclude, in fine, which data or variables is more (or less) dispersed. For instance, consider a sample of 10 women with their heights in cm and their salaries in €. The coefficients of variation are 0.032 and 0.061 respectively for the height and the salary. We can conclude that, relative to their respective average, their salaries vary more than their heights for these women (since the coefficient of variation is larger for the salary compared to the coefficient variation for the height).&lt;/p&gt;
&lt;p&gt;This concludes a relatively long article, thanks for reading! I hope the article helped you to understand and compute the different descriptive statistics by hand. If you would like to learn how to compute these measures in R, read the article “&lt;a href=&#34;/blog/descriptive-statistics-in-r/&#34;&gt;Descriptive statistics in R&lt;/a&gt;”.&lt;/p&gt;
&lt;p&gt;As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by &lt;a href=&#34;https://github.com/AntoineSoetewey/statsandr/issues&#34; target=&#34;_blank&#34;&gt;raising an issue on GitHub&lt;/a&gt;. For all other requests, you can &lt;a href=&#34;/contact/&#34;&gt;contact me&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Get updates every time a new article is published by &lt;a href=&#34;/subscribe/&#34;&gt;subscribing to this blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related articles:&lt;/strong&gt;&lt;/p&gt;
&lt;script src=&#34;//rss.bloople.net/?url=https%3A%2F%2Fwww.statsandr.com%2Ftags%2Fstatistics%2Findex.xml&amp;detail=-1&amp;limit=5&amp;showtitle=false&amp;type=js&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>