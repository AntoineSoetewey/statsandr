---
title: Data manipulation in RStudio
author: Antoine Soetewey
date: '2019-12-24'
slug: data-manipulation-in-rstudio
categories: []
tags:
  - R
meta_img: image/image.png
# description: Description for the page.
output:
  blogdown::html_page:
    toc: true
# draft: true
---

# Introduction

Not all datasets are as clean and tidy as you would expect. Therefore, after [importing your dataset into RStudio](/blog/how-to-import-an-excel-file-in-rstudio/), most of the time you will need to prepare it before performing any statistical analyses. Data manipulation can even sometimes take longer than the actual analyses when the quality of the data is poor. Data manipulation include a broad range of tools and techniques. We present here in details the manipulations that you will most likely need for your projects. Do not hesitate to let me know (as a comment for example) if you find other data manipulations essential.

# Dataset

In this article, we use the dataset `cars` to illustrate the different data manipulation techniques. Note that the dataset is imported by default in RStudio (so you do not need to import it) and I use the generic name `dat` for the name of the dataset (see [here](/blog/how-to-import-an-excel-file-in-rstudio/#user-friendly-way) why I always use a generic name instead of more specific names for dataset names). Here is a table of the dataset:

```{r}
dat <- cars # rename the dataset with a generic name
dat # display the entire dataset
```

This dataset has `r nrow(dat)` observations with `r ncol(dat)` variables (speed and distance). You can check the number of observations and variables with `nrow(dat)` and `ncol(dat)`, or `dim(dat)`:

```{r}
nrow(dat) # number of rows
ncol(dat) # number of columns
dim(dat) # dimension: number of rows and columns
```

<!-- library(pander) -->
<!-- pander(dat) -->
<!-- Note that the `pander()` command is only used for aesthetic reasons. You do not necessarily have to use them when you work in R Studio. -->

# Subset a dataset

## First or last observations

* To keep only the first 10 observations:
```{r}
head(dat, n = 10)
```

* To keep only the last 5 observations:
```{r}
tail(dat, n = 5)
```

## Random sample of observations

* To draw a sample of 4 observations without replacement:
```{r, message = FALSE}
library(dplyr)
sample_n(dat, 4, replace = FALSE)
```

## Based on row or column number

If you know what observation(s) or column(s) you want to keep, you can use the row or column number(s) to subset your dataset. We illustrate this with several examples:

* keep all the variables for the $3^{rd}$ observation:
```{r, eval = FALSE}
dat[3, ]
```
* keep the $2^{nd}$ variable for all observations:
```{r, eval = FALSE}
dat[, 2]
```
* You can mix the two above methods to keep only the $2^{nd}$ variable of the $3^{rd}$ observation:
```{r}
dat[3, 2]
```
* keep several observations, for example the first 5, the $10^{th}$ and the $15^{th}$ observation for all variables:
```{r}
dat[c(1:5, 10, 15), ] # do not forget c()
```
* remove observations 5 to 45:
```{r}
dat[-c(5:45), ]
```
* tip: to keep only the last observation, use `nrow()` instead of the row number:
```{r}
dat[nrow(dat), ] # nrow() gives the number of rows
```

This way, no matter the number of observations, you will always select the last one. This technique of using a piece of code instead of a specific value is to avoid "hard coding". Hard coding is generally not recommended (unless you want to specify a parameter that you are sure will never change) because if your dataset changes, you will need to manually edit your code. 

As you probably figured out by now, you can select observations and/or variables of a dataset by running `dataset_name[row_number, column_number]`. When the row or column number is left empty, the entire row/column is selected. Note that all examples presented above also works for matrices:

```{r}
mat <- matrix(c(-1, 2, 0, 3), ncol = 2, nrow = 2)
mat[1, 2]
```

## Based on variable names

To select one variable of the dataset based on its name rather than on its column number, use `dataset_name$variable_name`:

```{r}
dat$speed
```

Accessing variables inside a dataset with this second method is strongly recommended compared to the first if you intend to modify the structure of your database. Indeed, if a column is added or removed in the dataset, the numbering will change. Therefore, variables are generally referred to by its name rather than by its position (column number). In addition, it is always easier to understand and interpret code with the name of the variable written. There is only one reason why I would still use the column number; if the variables names are expected to change while the structure of the dataset do not change.

To select variables, it is also possible to use the `select()` command from the powerful `dplyr` package (for compactness only the first 6 observations are displayed thanks to the `head()` command):

```{r}
head(select(dat, speed))
```

This is equivalent than removing the distance variable:

```{r}
head(select(dat, -dist))
```


## Based on one or multiple criterion

Instead of subsetting a dataset based on row/column numbers or variable names, you can also subset it based on one or multiple criterion:

* keep only observations with speed larger than 20. The first argument refers to the name of the dataset, while the second argument refers to the subset criteria:
```{r}
subset(dat, dat$speed > 20)
```
* keep only observations with distance smaller than or equal to 50 __and__ speed equal to 10. Note the `==` (and not `=`) for the equal criteria:
```{r}
subset(dat, dat$dist <= 50 & dat$speed == 10)
```
* use `|` to keep only observations with distance smaller than 20 __or__ speed equal to 10:
```{r}
subset(dat, dat$dist < 20 | dat$speed == 10)
```
* to filter out some observations, use `!=`. For instance, to keep observations with speed not equal to 24 and distance not equal to 120 (for compactness only the last 6 observations are displayed thanks to the `tail()` command):
```{r}
tail(subset(dat, dat$speed != 24 & dat$dist != 120))
```

# Create a new variable

Often your dataset can be enhanced by creating new variables and then add them to your dataset. In this example, we create two new variables; one being the speed times the distance (which we call `speed_dist`) and the other being a categorization of the speed (which we call `speed_cat`). We then display the first 6 observations of this new dataset with the 4 variables:

```{r}
# create new variable speed_dist:
dat$speed_dist <- dat$speed * dat$dist

# create new variable speed_cat
# the function ifelse() means that if dat$speed > 7, then speed_cat is "high speed", otherwise it is "low_speed"
dat$speed_cat <- ifelse(dat$speed > 7,
  "high speed", "low speed"
)

# display first 6 observations
head(dat) # 6 is the default in head()
```

Note than in programming, a character string is generally surrounded by quotes (`"character string"`).

# Categorical variables and labels management

For categorical variables, it is a good practice to use the factor format and to name the different levels of the variables.

* for this example, let's create another new variable called `dist_cat` based on the distance and then change its format from numeric to factor (while also specifying the labels of the levels):

```{r}
# create new variable dist_cat
dat$dist_cat <- ifelse(dat$dist < 15,
  1, 2
)

# change from numeric to factor and specify the labels
dat$dist_cat <- factor(dat$dist_cat,
  levels = c(1, 2),
  labels = c("small distance", "big distance") # follow the order of the levels
)

head(dat)
```

* to check the format of a variable:

```{r}
class(dat$dist_cat)
# or
str(dat$dist_cat)
```

## Recode categorical variables

It is possible to recode labels of a categorical variable if you are not satisfied with the current labels. In this example, we change the labels as follows:

* "small distance" $\rightarrow$ "short distance"
* "big distance" $\rightarrow$ "large distance"

```{r}
dat$dist_cat <- recode(dat$dist_cat,
  "small distance" = "short distance",
  "big distance" = "large distance"
)
head(dat)
```

## Change reference level

For some analyses, you might want to change the order of the levels. For example, if you analyze data about a control group and a treatment group, you may want to set the control group as the reference group. By default, levels are ordered by alphabetical order or by its numeric value if it was change from numeric to factor.

* to check the current order of the levels (the first level being the reference):

```{r}
levels(dat$dist_cat)
```

In this case, "short distance" being the first level it is the reference level. It is the first level because it was initially set with a value equal to 1 when creating the variable.

* to change the reference level:

```{r}
dat$dist_cat <- relevel(dat$dist_cat, ref = "large distance")
levels(dat$dist_cat)
```

Large distance is now the first and thus the reference level.

# Rename variable names

To rename variable names, use the `rename()` command from the `dplyr` package as follows:

* dist $\rightarrow$ distance
* dist_cat $\rightarrow$ distance_cat

```{r}
dat <- rename(dat,
  distance = dist,
  speed_distance = speed_dist,
  distance_cat = dist_cat
)
names(dat) # display variable names
```





Thanks for reading. I hope this article helped you to manipulate your data in RStudio. As always, if you find a mistake/bug or if you have any questions do not hesitate to let me know in the comment section below, <a href="https://github.com/AntoineSoetewey/statsandr/issues" target="_blank" rel="noopener">raise an issue on GitHub</a> or [contact me](/contact/).

