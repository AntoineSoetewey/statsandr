---
title: Data manipulation in R
author: Antoine Soetewey
date: '2019-12-24'
slug: data-manipulation-in-r
categories: []
tags:
  - R
  - Basics
meta_img: blog/data-manipulation-in-rstudio_files/0_voEJp2o-Z2k4-uUd.jpeg
description: See how to subset a dataset, create a new variable, recode categorical variables or labels, rename a variable, create a dataframe and deal with missing values.
output:
  blogdown::html_page:
    toc: true
# draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.align = "center",
  out.width='100%'
)
```

![Photo by Campaign Creators](/blog/data-manipulation-in-rstudio_files/0_voEJp2o-Z2k4-uUd.jpeg){width=100%}

# Introduction

Not all datasets are as clean and tidy as you would expect. Therefore, after [importing your dataset into RStudio](/blog/how-to-import-an-excel-file-in-rstudio/), most of the time you will need to prepare it before performing any statistical analyses. Data manipulation can even sometimes take longer than the actual analyses when the quality of the data is poor. Data manipulation include a broad range of tools and techniques. We present here in details the manipulations that you will most likely need for your projects. Do not hesitate to let me know (as a comment at the end of this article for example) if you find other data manipulations essential so that I can add them.

# Dataset

In this article, we use the dataset `cars` to illustrate the different data manipulation techniques. Note that the dataset is installed by default in RStudio (so you do not need to import it) and I use the generic name `dat` as the name of the dataset throughout the article (see [here](/blog/how-to-import-an-excel-file-in-rstudio/#user-friendly-way) why I always use a generic name instead of more specific names). Here is a table of the whole dataset:

```{r}
dat <- cars # rename the cars dataset with a generic name
dat # display the entire dataset
```

This dataset has `r nrow(dat)` observations with `r ncol(dat)` variables (speed and distance). You can check the number of observations and variables with `nrow(dat)` and `ncol(dat)`, or `dim(dat)`:

```{r}
nrow(dat) # number of rows/observations
ncol(dat) # number of columns/variables
dim(dat) # dimension: number of rows/observations and columns/variables
```

<!-- library(pander) -->
<!-- pander(dat) -->
<!-- Note that the `pander()` command is only used for aesthetic reasons. You do not necessarily have to use them when you work in R Studio. -->

# Subset a dataset

## First or last observations

* To keep only the first 10 observations:
```{r}
head(dat, n = 10)
```

* To keep only the last 5 observations:
```{r}
tail(dat, n = 5)
```

## Random sample of observations

* To draw a sample of 4 observations without replacement:
```{r, message = FALSE}
library(dplyr)
sample_n(dat, 4, replace = FALSE)
```

## Based on row or column numbers

If you know what observation(s) or column(s) you want to keep, you can use the row or column number(s) to subset your dataset. We illustrate this with several examples:

* keep all the variables for the $3^{rd}$ observation:
```{r, eval = FALSE}
dat[3, ]
```
* keep the $2^{nd}$ variable for all observations:
```{r, eval = FALSE}
dat[, 2]
```
* You can mix the two above methods to keep only the $2^{nd}$ variable of the $3^{rd}$ observation:
```{r}
dat[3, 2]
```
* keep several observations; for example observations $1$ to $5$, the $10^{th}$ and the $15^{th}$ observation for all variables:
```{r}
dat[c(1:5, 10, 15), ] # do not forget c()
```
* remove observations 5 to 45:
```{r}
dat[-c(5:45), ]
```
* tip: to keep only the last observation, use `nrow()` instead of the row number:
```{r}
dat[nrow(dat), ] # nrow() gives the number of rows
```

This way, no matter the number of observations, you will always select the last one. This technique of using a piece of code instead of a specific value is to avoid "hard coding". Hard coding is generally not recommended (unless you want to specify a parameter that you are sure will never change) because if your dataset changes, you will need to manually edit your code. 

As you probably figured out by now, you can select observations and/or variables of a dataset by running `dataset_name[row_number, column_number]`. When the row or column number is left empty, the entire row/column is selected. Note that all examples presented above also works for matrices:

```{r}
mat <- matrix(c(-1, 2, 0, 3), ncol = 2, nrow = 2)
mat
mat[1, 2]
```

## Based on variable names

To select one variable of the dataset based on its name rather than on its column number, use `dataset_name$variable_name`:

```{r}
dat$speed
```

Accessing variables inside a dataset with this second method is strongly recommended compared to the first if you intend to modify the structure of your database. Indeed, if a column is added or removed in the dataset, the numbering will change. Therefore, variables are generally referred to by its name rather than by its position (column number). In addition, it is easier to understand and interpret code with the name of the variable written (another reason to call variables with a concise but clear name). There is only one reason why I would still use the column number; if the variables names are expected to change while the structure of the dataset do not change.

To select variables, it is also possible to use the `select()` command from the powerful `dplyr` package (for compactness only the first 6 observations are displayed thanks to the `head()` command):

```{r}
head(select(dat, speed))
```

This is equivalent than removing the distance variable:

```{r}
head(select(dat, -dist))
```

## Based on one or multiple criterion

Instead of subsetting a dataset based on row/column numbers or variable names, you can also subset it based on one or multiple criterion:

* keep only observations with speed larger than 20. The first argument refers to the name of the dataset, while the second argument refers to the subset criteria:
```{r}
subset(dat, dat$speed > 20)
```
* keep only observations with distance smaller than or equal to 50 __and__ speed equal to 10. Note the `==` (and not `=`) for the equal criteria:
```{r}
subset(dat, dat$dist <= 50 & dat$speed == 10)
```
* use `|` to keep only observations with distance smaller than 20 __or__ speed equal to 10:
```{r}
subset(dat, dat$dist < 20 | dat$speed == 10)
```
* to filter out some observations, use `!=`. For instance, to keep observations with speed not equal to 24 and distance not equal to 120 (for compactness only the last 6 observations are displayed thanks to the `tail()` command):
```{r}
tail(subset(dat, dat$speed != 24 & dat$dist != 120))
```

# Create a new variable

Often a dataset can be enhanced by creating new variables based on other variables from the initial dataset. In this example, we create two new variables; one being the speed times the distance (which we call `speed_dist`) and the other being a categorization of the speed (which we call `speed_cat`). We then display the first 6 observations of this new dataset with the 4 variables:

```{r}
# create new variable speed_dist
dat$speed_dist <- dat$speed * dat$dist

# create new variable speed_cat
# the function ifelse() below means that if dat$speed > 7, then speed_cat is "high speed", otherwise it is "low_speed"
dat$speed_cat <- ifelse(dat$speed > 7,
  "high speed", "low speed"
)

# display first 6 observations
head(dat) # 6 is the default in head()
```

Note than in programming, a character string is generally surrounded by quotes (`"character string"`).

## Transform a continuous variable into a categorical variable

To transform a continuous variable into a categorical variable (also known as qualitative variable):

```{r}
dat$speed_quali <- cut(dat$speed,
  breaks = c(0, 12, 15, 19, 26), # cut points
  right = FALSE # closed on the left, open on the right
)
dat[c(1:2, 23:24, 49:50), ] # display some observations
```

This transformation is often done on age, when the age (a continuous variable) is transformed into a qualitative variable representing different age groups.

## Sum and mean in rows

In survey with Likert scale (used in psychology, among others), it is often the case that we need to compute a score for each respondents based on multiple questions. The score is usually the mean or the sum of all the questions of interest. This can be done with `rowMeans()` and `rowSums()`. For instance, let's compute the mean and the sum of the variables `speed`, `dist` and `speed_dist` (variables must be numeric of course as sum and mean cannot be computed on qualitative variables!) for each row and store them under the variables `mean_score` and `total_score`:

```{r}
dat$mean_score <- rowMeans(dat[, 1:3]) # variables speed, dist and speed_dist correspond to variables 1 to 3
dat$total_score <- rowSums(dat[, 1:3])
head(dat)
```

## Sum and mean in column

It is also possible to compute the mean and sum by column with `colMeans()` and `colSums()`:

```{r}
colMeans(dat[, 1:3])
colSums(dat[, 1:3])
```

# Categorical variables and labels management

For categorical variables, it is a good practice to use the factor format and to name the different levels of the variables.

* for this example, let's create another new variable called `dist_cat` based on the distance and then change its format from numeric to factor (while also specifying the labels of the levels):

```{r}
# create new variable dist_cat
dat$dist_cat <- ifelse(dat$dist < 15,
  1, 2
)

# change from numeric to factor and specify the labels
dat$dist_cat <- factor(dat$dist_cat,
  levels = c(1, 2),
  labels = c("small distance", "big distance") # follow the order of the levels
)

head(dat)
```

* to check the format of a variable:

```{r}
class(dat$dist_cat)
# or
str(dat$dist_cat)
```

This will be sufficient if you need to format only a limited number of variables. However, if you need to do it for a large amount of categorical variables, it quickly becomes time consuming to write the same code many times. As you can imagine, it possible to format many variables without having to write the entire code for each variable one by one by using the `within()` command:

```{r}
dat <- within(dat, {
  speed_cat <- factor(speed_cat, labels = c(
    "high speed",
    "low speed"
  ))
  dist_cat <- factor(dist_cat, labels = c(
    "small distance",
    "big distance"
  ))
})
head(dat)
str(dat)
```



## Recode categorical variables

It is possible to recode labels of a categorical variable if you are not satisfied with the current labels. In this example, we change the labels as follows:

* "small distance" $\rightarrow$ "short distance"
* "big distance" $\rightarrow$ "large distance"

```{r}
dat$dist_cat <- recode(dat$dist_cat,
  "small distance" = "short distance",
  "big distance" = "large distance"
)
head(dat)
```

<!-- This will be sufficient if you need to recode only one variable. However, if you need to recode more than one variables without having to recode them one by one, another piece of code is necessary: -->

<!-- ```{r} -->
<!-- dat2 <- select(dat, c(speed_cat, dist_cat)) -->
<!-- dat2$speed_cat <- as.factor(dat$speed_cat) -->
<!-- dat2 <- apply(dat2, 2, function(x) { -->
<!--   x <- recode( -->
<!--     x, -->
<!--     "'small distance' = 'short distance'; -->
<!--     'big distance' = 'large distance'; -->
<!--     'low speed' = 'slow'; -->
<!--     'high speed' = 'fast'" -->
<!--   ) -->
<!--   x -->
<!-- }) -->
<!-- ``` -->

## Change reference level

For some analyses, you might want to change the order of the levels. For example, if you are analyzing data about a control group and a treatment group, you may want to set the control group as the reference group. By default, levels are ordered by alphabetical order or by its numeric value if it was change from numeric to factor.

* to check the current order of the levels (the first level being the reference):

```{r}
levels(dat$dist_cat)
```

In this case, "short distance" being the first level it is the reference level. It is the first level because it was initially set with a value equal to 1 when creating the variable.

* to change the reference level:

```{r}
dat$dist_cat <- relevel(dat$dist_cat, ref = "large distance")
levels(dat$dist_cat)
```

Large distance is now the first and thus the reference level.

# Rename variable names

To rename variable names, use the `rename()` command from the `dplyr` package as follows:

* dist $\rightarrow$ distance
* speed_dist $\rightarrow$ speed_distance
* dist_cat $\rightarrow$ distance_cat

```{r}
dat <- rename(dat,
  distance = dist,
  speed_distance = speed_dist,
  distance_cat = dist_cat
)
names(dat) # display variable names
```

# Create a dataframe manually

Although most analyses are performed on an imported dataset, it is also possible to create a dataframe directly in R:

```{r}
# Create the data frame named dat
dat <- data.frame(
  "variable1" = c(6, 12, NA, 3), # presence of 1 missing value
  "variable2" = c(3, 7, 9, 1),
  stringsAsFactors = FALSE
)
# Print the data frame
dat
```

# Missing values

Missing values (represented by NA in RStudio, for "Not Applicable") are often problematic for many analyses. For instance, the mean of a series or variable with at least one NA will give a NA (the dataframe created in the previous section is used for this example):

```{r}
mean(dat$variable1)
```

It is however possible to compute most measures for variables including at least one NA thanks to the argument `na.rm = TRUE`:

```{r}
mean(dat$variable1, na.rm = TRUE)
```

Nonetheless, datasets with NAs are still problematic for some types of analysis. Several alternatives exist to remove or impute missing values.

## Remove NAs

A simple solution is to remove all observations (i.e., rows) containing at least one missing value. This is done by keeping observations with complete cases:

```{r}
dat_complete <- dat[complete.cases(dat), ]
dat_complete
```

Be careful before removing observations with missing values, especially if missing values are not "missing at random". This is, however, beyond the scope of the present article.

## Impute NAs

Instead of removing observations with at least one NA, it is possible to impute them, that is, replace them by some values such as the median or the mode of the variable. This can be done easily with the command `impute()` from the package `imputeMissings`:

```{r, message = FALSE}
library(imputeMissings)
dat_imputed <- impute(dat) # default method is median/mode
dat_imputed
```

When the median/mode method is used (the default), character vectors and factors are imputed with the mode. Numeric and integer vectors are imputed with the median. Again, use imputations carefully. Other packages offer more advanced imputation techniques. However, we keep it simple and straightforward for this article as advanced imputations is beyond the scope of introductory data manipulations in R.

# Scale

Scaling (i.e., standardizing) a variable is often used before a Principal Component Analysis (PCA)^[Principal Component Analysis (PCA) is a useful technique for exploratory data analysis, allowing a better visualization of the variation present in a dataset with a large number of variables. When there are many variables, the data cannot easily be illustrated in their raw format. To counter this, the PCA takes a dataset with many variables and simplifies it by transforming the original variables into a smaller number of "principal components". The first dimension contains the most variance in the dataset and so on, and the dimensions are uncorrelated. Note that PCA is done on quantitative variables.] when variables of a dataset have different units. Remember that scaling a variable means that it will compute the mean and the standard deviation of that variable. Then each value (so each row) of that variable is "scaled" by subtracting the mean and dividing by the standard deviation of that variable. Formally:

$$z = \frac{x - \bar{x}}{s}$$

where $\bar{x}$ and $s$ are the mean and the standard deviation of the variable, respectively.

To scale one or more variables in R use `scale()`:

```{r}
dat_scaled <- scale(dat_imputed)
head(dat_scaled)
```

Thanks for reading. I hope this article helped you to manipulate your data in RStudio.

As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by <a href="https://github.com/AntoineSoetewey/statsandr/issues" target="_blank" rel="noopener">raising an issue on GitHub</a>. For all other requests, you can contact me [here](/contact/).

Get updates every time a new article is published by [subscribing to this blog](/subscribe/).

**Related articles:**

<script src="//rss.bloople.net/?url=https%3A%2F%2Fwww.statsandr.com%2Ftags%2Fr%2Findex.xml&detail=-1&limit=5&showtitle=false&type=js"></script>