---
title: COVID-19 in Belgium
author: Antoine Soetewey
date: '2020-03-30'
slug: covid-19-in-belgium
categories: []
tags:
  - R
  - Coronavirus
meta_img: blog/top-r-resources-on-coronavirus_files/top-r-resources-on-coronavirus-covid-19.jpeg
description: This article presents an analysis of the Novel COVID-19 Coronavirus in Belgium using R and it also illustrates how you can apply it to your own country.
output:
  blogdown::html_page:
    toc: true
    toc_depth: 6
draft: true
bibliography: bibliography.bib
---

xxx add image and meta image

# Introduction

The Novel COVID-19 Coronavirus is still spreading quickly in several countries and it does not seem like it is going to stop anytime soon as the peak has not yet been reached in many countries.

Since the beginning of its expansion, a large number of scientists across the world have been analyzing this Coronavirus from different perspectives and with different technologies with the hope of coming up with a cure in order to stop its expansion and limit its impact on citizens.

# Top R resources on Coronavirus

In the meantime, epidemiologists, statisticians and data scientists are working towards a better understanding of the spread of the virus in order to help governments and health agencies in taking the most optimal decisions. This led to a great deal of online resources about the virus, which I published in an article covering the [top R resources on Coronavirus](/blog/top-r-resources-on-covid-19-coronavirus/). This article is a collection of the best resources I've had the chance to discover, with a brief summary for each of them. It includes Shiny apps, dashboards, R packages, blog posts and datasets.

Publishing this collection led many readers to submit their piece of work, which made the article even more complete and more insightful for anyone interested in analyzing the virus from a quantitative perspective. Thanks to everyone who has helped me in collecting and summarizing these resources about COVID-19!

Given my field of expertise, I am not able to help in this fight against the virus from a medical point of view. However, I still wanted to contribute as much as I could. From understanding better the disease to bringing scientists and doctors together to build something bigger and more impactful, I truly hope that this collection will, to a small extent, help to fight the pandemic.

# Coronavirus dashboard for your own country

Besides receiving analyses, blog posts, R code and Shiny apps from people across the world, I realized that many people were trying to create a dashboard tracking Coronavirus for their own country. So in addition to the collection of top R resources, I also published an article detailing the steps to follow to create a dashboard specific to a country. See how to create such dashboard in this [article](/blog/how-to-create-a-simple-coronavirus-dashboard-specific-to-your-country-in-r) and an [example with Belgium](https://www.antoinesoetewey.com/files/coronavirus-dashboard.html){target="_blank"}.

The code has been made available and is open source so everyone can copy it and adapt it to their own country. The dashboard was intentionally kept simple so anyone with a minimum knowledge in R could easily replicate it and advanced users could enhance it according to their needs.

# Motivations and limitations

By seeing and organizing many [R resources about COVID-19](/blog/top-r-resources-on-covid-19-coronavirus/), I am fortunate enough to have read a lot of excellent analyses on the disease outbreak, the impact of different health measures, forecasts of the number of cases, projections about the length of the pandemic, hospitals capacity, etc.

Furthermore, I must admit that some countries such as China, South Korea, Italy, Spain, UK and Germany received a lot of attention as shown by the number of analyses done on these countries. However, to my knowledge and at the date of publication of this article, I am not aware of any analysis of the spread of the Coronavirus specifically for Belgium.^[Feel free to let me know in the comments or by [contacting me](/contact/) if you performed some analyses specifically for Belgium and which I could include in my article covering the [top R resources on the Coronavirus](/blog/top-r-resources-on-covid-19-coronavirus/).] The present article aims at filling that gap.

Throughout my PhD thesis in statistics, my main research interest is about survival analysis applied to cancer patients (more information in the research section of my [personal website](https://www.antoinesoetewey.com/research/){target="_blank"}). I am not an epidiemologist and I have no extensive knowledge in modeling disease outbreaks via epidiemological models.

I am used to write articles only about things I consider myself familiar with, mainly [statistics](/tags/statistics/) and its applications in [R](/tags/r/). At the time of writing this article, I was however curious where Belgium stands regarding the spread of this virus, I wanted to play with this kind of data in R (which is new to me) and see what comes out.

In order to satisfy my curiosity while not being an expert, in this article I am going to replicate analyses done by more knowledgeable people and apply them to my country, that is, Belgium. From all the analyses I have read so far, I decided to replicate the analyses done by Prof. Dr. Holger K. von Jouanne-Diedrich from Learning Machines. His [article](https://blog.ephorie.de/epidemiology-how-contagious-is-novel-coronavirus-2019-ncov){target="_blank"} presents a concise but informative analysis on how to model the outbreak of the coronavirus and also shows how contagious it is. I also gained an understanding of the topic and in particular an understanding of the most common epidemiological model by reading this [article](https://timchurches.github.io/blog/posts/2020-02-18-analysing-covid-19-2019-ncov-outbreak-data-with-r-part-1/){target="_blank"} by Tim Churches.

Other more complex analyses are possible and even preferable, but I leave this to experts in this field. Note also that the analyses take into account only the data until the date of publication of this article so the results should not be viewed, by default, as current findings.

# Analysis of Coronavirus in Belgium

## A classic epidemiological model: the SIR model

There are many epidemiological models but we will use one of the simplest, the **SIR model**. Tim Churches' explanation of this model and how to fit it using R is so nice, I will reproduce it here with a few minor changes.

The basic idea behind the SIR model (**S**usceptible - **I**nfectious - **R**ecovered) of communicable disease outbreaks is that there are three groups (also called compartments) of people:

* those who are healthy but susceptible to the disease: *S*
* the infectious (and thus, infected) people: *I*
* people who have recovered: *R*

![SIR model. Source: Wikipedia](/blog/2020-03-30-covid-19-in-belgium_files/SIR model.png){width=100%}

To model the dynamics of the outbreak we need three differential equations to describe the rates of change in each group, parameterised by:

* $\beta$ which controls the transition between *S* and *I*
* $\gamma$ which controls the transition between *I* and *R*

Formally, this gives:

$$\frac{dS}{dt} = - \frac{\beta IS}{N}$$

$$\frac{dI}{dt} = \frac{\beta IS}{N} - \gamma I$$

$$\frac{dR}{dt} = \gamma I$$

The first step is to express these differential equations as an R function, with respect to time *t*.

```{r}
SIR <- function(time, state, parameters) {
  par <- as.list(c(state, parameters))
  with(par, {
    dS <- -beta * I * S / N
    dI <- beta * I * S / N - gamma * I
    dR <- gamma * I
    list(c(dS, dI, dR))
  })
}
```

## Fitting an SIR model to the Belgium data

To fit the model to the data we need two things:

1. a solver for these differential equations
1. an optimiser to find the optimal values for our two unknown parameters, $\beta$ and $\gamma$

The function `ode()` (for ordinary differential equations) from the `{deSolve}` R package makes solving the system of equations easy, and to find the optimal values for the parameters we wish to estimate, we can just use the `optim()` function built into base R.

Specifically what we need to do is minimise the sum of the squared differences between *I(t)*, which is the number of people in the infectious compartment *I* at time *t*, and the corresponding number of cases as predicted by our model $\hat{I}(t)$. This quantity is known as the residual sum of squares (*RSS*):

$$RSS(\beta, \gamma) = \sum_t \big(I(t) - \hat{I}(t) \big)^2$$

In order to fit a model to the incidence data for Belgium, we need a value *N* for the initial uninfected population. The population of Belgium in November 2019 was 11,515,793 people, according to [Wikipedia](https://en.wikipedia.org/wiki/Belgium){target="_blank"}. We will thus use *N = 11515793* as the initial uninfected population.

Next, we need to create a vector with the daily cumulative incidence for Belgium, from 29th February (when our daily incidence data starts), through to 29th March (last available date at the time of publication of this article). We will then compare the predicted incidence from the *SIR* model fitted to these data with the actual incidence since 30th January. We also need to initialise the values for *S*, *I* and *R*. Note that the daily cumulative incidence for Belgium is extracted from the [`{coronavirus}` package](https://www.statsandr.com/blog/top-r-resources-on-covid-19-coronavirus/#coronavirus) developed by Rami Krispin.

```{r, message = FALSE}
# devtools::install_github("RamiKrispin/coronavirus")
library(coronavirus)
data(coronavirus)

`%>%` <- magrittr::`%>%`

# extract the cumulative incidence
df <- coronavirus %>%
  dplyr::filter(Country.Region == "Belgium") %>%
  dplyr::group_by(date, type) %>%
  dplyr::summarise(total = sum(cases, na.rm = TRUE)) %>%
  tidyr::pivot_wider(
    names_from = type,
    values_from = total
  ) %>%
  dplyr::arrange(date) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(active = confirmed - death - recovered) %>%
  dplyr::mutate(
    confirmed_cum = cumsum(confirmed),
    death_cum = cumsum(death),
    recovered_cum = cumsum(recovered),
    active_cum = cumsum(active)
  )

# put the daily cumulative incidence numbers for Belgium from
# 22nd Jan to 29th March into a vector called Infected
library(lubridate)
Infected <- subset(df, date >= ymd("2020-02-29"))$confirmed_cum

# Create an incrementing Day vector the same length as our
# cases vector
Day <- 1:(length(Infected))

# now specify initial values for N, S, I and R
N <- 11515793
init <- c(
  S = N - Infected[1],
  I = Infected[1],
  R = 0
)
```

Then we need to define a function to calculate the *RSS*, given a set of values for $\beta$ and $\gamma$.

```{r}
# define a function to calculate the residual sum of squares
# (RSS), passing in parameters beta and gamma that are to be
# optimised for the best fit to the incidence data
RSS <- function(parameters) {
  names(parameters) <- c("beta", "gamma")
  out <- ode(y = init, times = Day, func = SIR, parms = parameters)
  fit <- out[, 3]
  sum((Infected - fit)^2)
}
```

Finally, we can fit the SIR model to our data by finding the values for $\beta$ and $\gamma$ that minimise the residual sum of squares between the observed cumulative incidence and the predicted cumulative incidence. We also need to check that our model has converged, as indicated by the message shown below:

```{r}
# now find the values of beta and gamma that give the
# smallest RSS, which represents the best fit to the data.
# Start with values of 0.5 for each, and constrain them to
# the interval 0 to 1.0

# install.packages("deSolve")
library(deSolve)

Opt <- optim(c(0.5, 0.5),
  RSS,
  method = "L-BFGS-B",
  lower = c(0, 0),
  upper = c(1, 1)
)

# check for convergence
Opt$message
```

Convergence is confirmed. Now we can examine the fitted values for $\beta$ and $\gamma$:

```{r}
Opt_par <- setNames(Opt$par, c("beta", "gamma"))
Opt_par
```

Remember that $\beta$ controls the transition between *S* and *I* and $\gamma$ controls the transition between *I* and *R*. However, those values do not mean a lot but we use them to get the fitted numbers of people in each compartment of our SIR model for the dates up to 29th March that were used to fit the model, and compare those fitted values with the observed data.

```{r, eval = TRUE, message = FALSE}
sir_start_date <- "2020-02-29"

# time in days for predictions
t <- 1:as.integer(today() - ymd(sir_start_date))

# get the fitted values from our SIR model
fitted_cumulative_incidence <- data.frame(ode(
  y = init, times = t,
  func = SIR, parms = Opt_par
))

# add a Date column and the observed incidence data
library(dplyr)
fitted_cumulative_incidence <- fitted_cumulative_incidence %>%
  mutate(
    Date = ymd(sir_start_date) + days(t - 1),
    Country = "Belgium",
    cumulative_incident_cases = Infected
  )

# plot the data
library(ggplot2)
fitted_cumulative_incidence %>%
  ggplot(aes(x = Date)) +
  geom_line(aes(y = I), colour = "red") +
  geom_point(aes(y = cumulative_incident_cases), colour = "blue") +
  labs(
    y = "Cumulative incidence",
    title = "COVID-19 fitted vs observed cumulative incidence, Belgium",
    subtitle = "(Red = fitted incidence from SIR model, blue = observed incidence)"
  ) +
  theme_minimal()
```

There were more confirmed cases than expected before March 28th, and the rate of incidence seems to decrease for a week (perhaps thanks to the new containment measures?).

## Reproduction number $R_0$

The fit to the observed cumulative incidence data is far from perfect but it is still reasonable, so we can now use our fitted model to calculate the basic reproduction number $R_0$ which gives the average number of susceptible people who are infected by each infectious person:

$$R_0 = \frac{\beta}{\gamma}$$

xxx Add a note about its interpretation from article on medium, and interpretation about a $R_0$ above and below 0.

We can compute it in R:

```{r}
Opt_par

R0 <- Opt_par[1] / Opt_par[2]
as.numeric(R0)
```

An $R_0$ of 1.97 is consistent with the values calculated by others for COVID-19, and is also consistent with the $R_0$ for SARS and MERS, which are similar diseases also cause by coronavirus.

## Using our model to analyze the outbreak if there was no intervention

It is instructive to use our model fitted to the first 30 days of available data on confirmed cases in Belgium, to see what would happen if the outbreak were left to run its course, without public health interventions.

```{r, warning = FALSE}
# time in days for predictions
t <- 1:70

# get the fitted values from our SIR model
fitted_cumulative_incidence <- data.frame(ode(
  y = init, times = t,
  func = SIR, parms = Opt_par
))

# add a Date column and join the observed incidence data
fitted_cumulative_incidence <- fitted_cumulative_incidence %>%
  mutate(
    Date = ymd(sir_start_date) + days(t - 1),
    Country = "Belgium",
    cumulative_incident_cases = I
  )

# plot the data
fitted_cumulative_incidence %>%
  ggplot(aes(x = Date)) +
  geom_line(aes(y = I), colour = "red") +
  geom_line(aes(y = S), colour = "black") +
  geom_line(aes(y = R), colour = "green") +
  geom_point(aes(y = c(Infected, rep(NA, length(t) - length(Infected)))),
    colour = "blue"
  ) +
  scale_y_continuous(labels = scales::comma) +
  labs(y = "Persons", title = "COVID-19 fitted vs observed cumulative incidence, Belgium") +
  scale_colour_manual(name = "", values = c(
    red = "red", black = "black",
    green = "green", blue = "blue"
  ), labels = c(
    "Susceptible",
    "Recovered", "Observed incidence", "Infectious"
  )) +
  theme_minimal()
```

The same graph in log-scale:

```{r, warning = FALSE, tidy = TRUE}
# plot the data
fitted_cumulative_incidence %>%
  ggplot(aes(x = Date)) +
  geom_line(aes(y = I, colour = "red")) +
  geom_line(aes(y = S, colour = "black")) +
  geom_line(aes(y = R, colour = "green")) +
  geom_point(aes(y = c(Infected, rep(NA, length(t) - length(Infected))), colour = "blue")) +
  scale_y_log10(labels = scales::comma) +
  labs(
    y = "Persons (log-scale)",
    title = "COVID-19 fitted vs observed cumulative incidence, Belgium"
  ) +
  scale_colour_manual(
    name = "",
    values = c(red = "red", black = "black", green = "green", blue = "blue"),
    labels = c("Susceptible", "Observed incidence", "Recovered", "Infectious")
  ) +
  theme_minimal()
```

Given this prediction, with the exact same setting and no intervention at all to limit the spread of the pandemic, the peak would be on April 18th 2020, with around 1.7 million infected persons. With a mortality rate of 2%, this would mean that our model predicts that more than 30,000 people would die. At this point, we understand why such containment measures and regulations are taken within Belgium!

Note that those predictions should be taken with caution. As mentioned above, they are based on rather unrealistic assumptions (for examle, no publich health interventions, fixed reproduction number $R_0$, etc.). More advanced projections are possible with the `{projections}` package, among others (see this [section](/blog/covid-19-in-belgium/#more-sophisticated-projections/) for more information on this matter).

# Additional considerations

As previously mentioned, the SIR model and the analyses done above are rather simplistic and may not give a true representation of the reality. In the following sections, we highlight xxx improvements that could be done to enhance theses analyses and lead to a better overview of the reality.

## Ascertainment rates

In the previous analyses and graphs, it is assumed that the number of confirmed cases represent all the cases that are infectious. This is far from reality as only a proportion of all cases are screened, detected and counted in the official figures. This proportion is known as the ascertainment rate.

The ascertainment rate is likely to vary during the course of an outbreak, in particular if testing and screening efforts are increased, or if detections methods are changed. Such changing ascertainment rates can be easily incorporated into the model by using a weighting function for the incidence cases.

## More sophisticated models

More sophisticated models could also be used to better reflect real-life transmission processes. For instance, another classical model in disease outbreak is the *SEIR* model. This extended model is similar to the *SIR* model, where **S** stands for **S**usceptible and **R** stands for **R**ecovered, but the infected people are divided into two compartments:

1. **E** for the **E**xposed/infected but asymptomatic
1. **I** for the **I**nfected and symptomatic

These models belong to the continuous-time dynamic models that assume fixed transition rates. There are other, stochastic models that allow for varying transition rates depending on attributes of individuals, social networking, etc.

## Modelling the epidemic trajectory using log-linear models

As noted above, the initial exponential phase of an outbreak, when shown in a log-linear plot (the y-axis on a log-scale and the x-axis without transformation), appears (somewhat) linear. This suggests that we can model epidemic growth, and decay, using a simple log-linear model of the form:

$$log(y)=rt+b$$

where *y* is the incidence, *r* is the growth rate, *t* is the number of days since a specific point in time (typically the start of the outbreak), and *b* is the intercept. In this context, two log-linear models, one to the growth phase before the peak, and one to the decay phase after the peak are fitted to the epidemic (incidence cases) curve.

The doubling and halving time estimates which you very often hear in the news can be estimated from these log-linear models. Furthermore, these log-linear models can also be used on the epidemic trajectory to estimate the reproduction number  $R_0$ in the growth and decay phases of the epidemic.

The `{incidence}` package in R, part of the [R Epidemics Consortium (RECON)](https://www.repidemicsconsortium.org/){target="_blank"} suite of packages for epidemic modelling and control, makes the fitting of this kind of models very convenient. 

## Estimating changes in the effective reproduction number $R_e$

In our model, we set a reproduction number $R_0$ and kept it constant. It would nonetheless be useful to estimate the current effective reproduction number $R_e$ on a day-by-day basis so as to track the effectiveness of public health interventions, and possibly predict when an incidence curve will start to decrease.

The `{EpiEstim}` package in R can be used to estimate $R_e$ and allow to take into consideration human travel from other geographical regions in addition to local transmission [@cori2013new; @thompson2019improved].

## More sophisticated projections

In addition to naïve predictions based on a simple SIR model, more advanced and complex projections are also possible, notably, with the `{projections}` package. This packages uses data on daily incidence, the serial interval and the reproduction number to simulate plausible epidemic trajectories and project future incidence.

# Conclusion

This article started with mentioning a couple of R resources on the Coronavirus pandemic that can be used as background materials. We then detailed the most common epidemiological model, the *SIR* model before actually applying it on Belgium data.

This resulted in a visual comparison of the fitted and observed cumulative incidence in Belgium. It showed that the observed confirmed cases were higher than expected by the model until a few days ago, and it seems that the rate at which people are infected is decreasing. More data is however necessary to confirm this downard trend.

We then explained what is the reproduction number and how to compute it in R. Finally, our model was used to analyze the outbreak of the Coronavirus if there was no intervention at all. 

Under this simplistic and unreal scenario of no public health intervention, the peak of the COVID-19 would be on April 18, 2020, with around 1.7 million infected people and several thousands deaths. These very alarmist naïve predictions highlight the importance of restrictive public health actions taken by governments to mitigate the spread of the virus (or at least slow it enough to allow health care systems to cope with it).

xxx to continue by finish reading conclusion of Tim and reading 2 other articles (medium and holger).

# References






