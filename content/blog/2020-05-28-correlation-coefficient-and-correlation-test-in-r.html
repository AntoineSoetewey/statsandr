---
title: Correlation coefficient and correlation test in R
author: Antoine Soetewey
date: '2020-05-28'
slug: correlation-coefficient-and-correlation-test-in-r
categories: []
tags:
  - Basics
  - Descriptive statistics
  - R
  - Statistics
meta_img: blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/correlation-coefficient-and-correlation-test-in-r.jpeg
description: Learn how to compute a correlation coefficient (Pearson and Spearman) and perform a correlation test in R
output:
  blogdown::html_page:
    toc: true
    toc_depth: 6
# draft: true
bibliography: bibliography.bib
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#correlation-coefficient">Correlation coefficient</a>
<ul>
<li><a href="#between-two-variables">Between two variables</a></li>
<li><a href="#correlation-matrix-correlations-for-all-variables">Correlation matrix: correlations for all variables</a></li>
<li><a href="#interpretation-of-a-correlation-coefficient">Interpretation of a correlation coefficient</a></li>
</ul></li>
<li><a href="#visualizations">Visualizations</a>
<ul>
<li><a href="#a-scatterplot-for-2-variables">A scatterplot for 2 variables</a></li>
<li><a href="#scatterplots-for-several-pairs-of-variables">Scatterplots for several pairs of variables</a></li>
<li><a href="#another-simple-correlation-matrix">Another simple correlation matrix</a></li>
</ul></li>
<li><a href="#correlation-test">Correlation test</a>
<ul>
<li><a href="#for-2-variables">For 2 variables</a></li>
<li><a href="#for-several-pairs-of-variables">For several pairs of variables</a></li>
</ul></li>
<li><a href="#combination-of-correlation-coefficients-and-correlation-tests">Combination of correlation coefficients and correlation tests</a>
<ul>
<li><a href="#correlograms">Correlograms</a></li>
</ul></li>
<li><a href="#correlation-does-not-imply-causation">Correlation does not imply causation</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/correlation-coefficient-and-correlation-test-in-r.jpeg" style="width:100.0%" /></p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Correlations between variables play an important role in a <a href="/tags/descriptive-statistics/">descriptive analysis</a>. A correlation measures the <strong>relationship between two variables</strong>, that is, how they are linked to each other. In this sense, a correlation allows to know which variables evolve in the same direction, which ones evolve in the opposite direction, and which ones are independent.</p>
<p>In this article, I show how to compute <strong>correlation coefficients</strong>, how to perform <strong>correlation tests</strong> and how to <strong>visualize relationships</strong> between variables in R.</p>
<p>Correlation is usually computed on two <a href="/blog/variable-types-and-examples/#quantitative">quantitative</a> variables, but it can also be computed on two <a href="/blog/variable-types-and-examples/#ordinal">qualitative ordinal</a> variables. See the <a href="/blog/chi-square-test-of-independence-in-r/">Chi-square test of independence</a> if you need to study the relationship between two <a href="/blog/variable-types-and-examples/#nominal">qualitative nominal</a> variables.</p>
<p>If you need to <em>quantify</em> the relationship between two variables, I refer you to the article about <a href="/blog/multiple-linear-regression-made-simple/">linear regression</a>.</p>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<p>In this article, we use the <code>mtcars</code> dataset (loaded by default in R):</p>
<pre class="r"><code># display first 5 observations
head(mtcars, 5)</code></pre>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2</code></pre>
<p>The variables <code>vs</code> and <code>am</code> are categorical variables, so they are removed for this article:</p>
<pre class="r"><code># remove vs and am variables
library(tidyverse)
dat &lt;- mtcars %&gt;%
  select(-vs, -am)

# display 5 first obs. of new dataset
head(dat, 5)</code></pre>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02    3    2</code></pre>
</div>
<div id="correlation-coefficient" class="section level1">
<h1>Correlation coefficient</h1>
<div id="between-two-variables" class="section level2">
<h2>Between two variables</h2>
<p>The correlation between 2 variables is found with the <code>cor()</code> function.</p>
<p>Suppose we want to compute the correlation between horsepower (<code>hp</code>) and miles per gallon (<code>mpg</code>):</p>
<pre class="r"><code># Pearson correlation between 2 variables
cor(dat$hp, dat$mpg)</code></pre>
<pre><code>## [1] -0.7761684</code></pre>
<p>Note that the correlation between variables <em>X</em> and <em>Y</em> is equal to the correlation between variables <em>Y</em> and <em>X</em> so the order of the variables in the <code>cor()</code> function does not matter.</p>
<p>The Pearson correlation is computed by default with the <code>cor()</code> function. If you want to compute the Spearman correlation, add the argument <code>method = "spearman"</code> to the <code>cor()</code> function:</p>
<pre class="r"><code># Spearman correlation between 2 variables
cor(dat$hp, dat$mpg,
  method = &quot;spearman&quot;
)</code></pre>
<pre><code>## [1] -0.8946646</code></pre>
<p>There are several correlation methods (Run <code>?cor</code> for more information about the different methods available in the <code>cor()</code> function):</p>
<ul>
<li><strong>Pearson</strong> correlation is often used for <a href="/blog/variable-types-and-examples/#continuous">quantitative continuous</a> variables that have a linear relationship</li>
<li><strong>Spearman</strong> correlation (which is actually similar to Pearson but based on the ranked values for each variable rather than on the raw data) is often used to evaluate relationships involving at least one <a href="/blog/variable-types-and-examples/#ordinal">qualitative ordinal</a> variable or two quantitative variables if the link is partially linear</li>
<li><strong>Kendall’s tau-b</strong> which is computed from the number of concordant and discordant pairs is often used for qualitative ordinal variables</li>
</ul>
</div>
<div id="correlation-matrix-correlations-for-all-variables" class="section level2">
<h2>Correlation matrix: correlations for all variables</h2>
<p>Suppose now that we want to compute correlations for several pairs of variables. We can easily do so for all possible pairs of variables in the dataset, again with the <code>cor()</code> function:</p>
<pre class="r"><code># correlation for all variables
round(cor(dat),
  digits = 2 # rounded to 2 decimals
)</code></pre>
<pre><code>##        mpg   cyl  disp    hp  drat    wt  qsec  gear  carb
## mpg   1.00 -0.85 -0.85 -0.78  0.68 -0.87  0.42  0.48 -0.55
## cyl  -0.85  1.00  0.90  0.83 -0.70  0.78 -0.59 -0.49  0.53
## disp -0.85  0.90  1.00  0.79 -0.71  0.89 -0.43 -0.56  0.39
## hp   -0.78  0.83  0.79  1.00 -0.45  0.66 -0.71 -0.13  0.75
## drat  0.68 -0.70 -0.71 -0.45  1.00 -0.71  0.09  0.70 -0.09
## wt   -0.87  0.78  0.89  0.66 -0.71  1.00 -0.17 -0.58  0.43
## qsec  0.42 -0.59 -0.43 -0.71  0.09 -0.17  1.00 -0.21 -0.66
## gear  0.48 -0.49 -0.56 -0.13  0.70 -0.58 -0.21  1.00  0.27
## carb -0.55  0.53  0.39  0.75 -0.09  0.43 -0.66  0.27  1.00</code></pre>
<p>This correlation matrix gives an overview of the correlations for all combinations of two variables.</p>
</div>
<div id="interpretation-of-a-correlation-coefficient" class="section level2">
<h2>Interpretation of a correlation coefficient</h2>
<p>First of all, correlation ranges from <strong>-1 to 1</strong>. It gives us an indication on two things:</p>
<ol style="list-style-type: decimal">
<li>The direction of the relationship between the 2 variables</li>
<li>The strength of the relationship between the 2 variables</li>
</ol>
<p>Regarding the direction of the relationship: On the one hand, a <strong>negative correlation</strong> implies that the two variables under consideration vary in <strong>opposite directions</strong>, that is, if a variable increases the other decreases and vice versa. On the other hand, a <strong>positive correlation</strong> implies that the two variables under consideration vary in the <strong>same direction</strong>, i.e., if a variable increases the other one increases and if one decreases the other one decreases as well.</p>
<p>Regarding the strength of the relationship: The <strong>more extreme</strong> the correlation coefficient (the closer to -1 or 1), the <strong>stronger the relationship</strong>. This also means that a <strong>correlation close to 0</strong> indicates that the two variables are <strong>independent</strong>, that is, as one variable increases, there is no tendency in the other variable to either decrease or increase.</p>
<p>As an illustration, the Pearson correlation between horsepower (<code>hp</code>) and miles per gallon (<code>mpg</code>) found above is -0.78, meaning that the 2 variables vary in opposite direction. This makes sense, cars with more horsepower tend to consume more fuel (and thus have a lower millage par gallon). On the contrary, from the correlation matrix we see that the correlation between miles per gallon (<code>mpg</code>) and the time to drive 1/4 of a mile (<code>qsec</code>) is 0.42, meaning that fast cars (low <code>qsec</code>) tend to have a worse millage per gallon (low <code>mpg</code>). This again make sense as fast cars tend to consume more fuel.</p>
<p>Note that it is a good practice to visualize the type of the relationship between the two variables <em>before</em> interpreting the correlation coefficients. The reason is that the correlation coefficient could be biased due to an <a href="/blog/outliers-detection-in-r/">outlier</a> or due to the type of link between the two variables.</p>
<p>For instance, see the two Pearson correlation coefficients (denoted by <code>R</code> in the following plots) when the outlier is excluded and included:</p>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The Pearson correlation coefficient changes drastically due to a single point, and thus the interpretation. It goes from a negative correlation coefficient, indicating a negative relationship between the 2 variables, to a positive coefficient, indicating a positive relationship. We would have missed this insight if we had not visualized the data in a scatterplot (see how to draw a scatterplot in this <a href="/blog/correlation-coefficient-and-correlation-test-in-r/#visualizations">section</a>).</p>
<p>A correlation coefficient may also miss a non-linear link between two variables:</p>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-7-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The Pearson correlation coefficient is equal to 0, indicating no relationship between the two variables, because it measures the <strong>linear</strong> relationship and it is clear from the plot that the link is non-linear.</p>
<p>So to recap, it is a good practice to visualize the data via a scatterplot before interpreting a correlation coefficient (it does not tell the whole story) and see how the correlation coefficient changes when using the parametric (Pearson) or nonparametric version (Spearman or Kendall’s tau-b).</p>
</div>
</div>
<div id="visualizations" class="section level1">
<h1>Visualizations</h1>
<p>The correlation matrix presented above is not easily interpretable, especially when the dataset is composed of many variables. In the following sections, we present some alternatives to the correlation matrix for better readability.</p>
<div id="a-scatterplot-for-2-variables" class="section level2">
<h2>A scatterplot for 2 variables</h2>
<p>A good way to visualize a correlation between 2 variables is to draw a scatterplot of the two variables of interest. Suppose we want to examine the relationship between horsepower (<code>hp</code>) and miles per gallon (<code>mpg</code>):</p>
<pre class="r"><code># scatterplot
library(ggplot2)

ggplot(dat) +
  aes(x = hp, y = mpg) +
  geom_point(colour = &quot;#0c4c8a&quot;) +
  theme_minimal()</code></pre>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>If you are unfamiliar with the <a href="/blog/graphics-in-r-with-ggplot2/"><code>{ggplot2}</code> package</a>, you can draw the scatterplot using the <code>plot()</code> function from R base graphics:</p>
<pre class="r"><code>plot(dat$hp, dat$mpg)</code></pre>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-9-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>or use the <a href="/blog/rstudio-addins-or-how-to-make-your-coding-life-easier/#esquisse">esquisse addin</a> to easily draw plots using the <code>{ggplot2}</code> package.</p>
</div>
<div id="scatterplots-for-several-pairs-of-variables" class="section level2">
<h2>Scatterplots for several pairs of variables</h2>
<p>Suppose that instead of visualizing the relationship between only 2 variables, we want to visualize the relationship for several pairs of variables. This is possible thanks to the <code>pair()</code> function.</p>
<p>For this illustration, we focus only on miles per gallon (<code>mpg</code>), horsepower (<code>hp</code>) and weight (<code>wt</code>):</p>
<pre class="r"><code># multiple scatterplots
pairs(dat[, c(&quot;mpg&quot;, &quot;hp&quot;, &quot;wt&quot;)])</code></pre>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The figure indicates that weight (<code>wt</code>) and horsepower (<code>hp</code>) are positively correlated, whereas miles per gallon (<code>mpg</code>) seems to be negatively correlated with horsepower (<code>hp</code>) and weight (<code>wt</code>).</p>
</div>
<div id="another-simple-correlation-matrix" class="section level2">
<h2>Another simple correlation matrix</h2>
<p>This version of the correlation matrix presents the correlation coefficients in a slightly more readable way, i.e., by coloring the coefficients based on their sign. Applied to our dataset, we have:</p>
<pre class="r"><code># improved correlation matrix
library(corrplot)

corrplot(cor(dat),
  method = &quot;number&quot;,
  type = &quot;upper&quot; # show only upper side
)</code></pre>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-11-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="correlation-test" class="section level1">
<h1>Correlation test</h1>
<div id="for-2-variables" class="section level2">
<h2>For 2 variables</h2>
<p>Unlike a correlation matrix which indicates the correlation coefficients between some pairs of variables in the <a href="/blog/what-is-the-difference-between-population-and-sample/">sample</a>, a correlation test is used to test whether the correlation (denoted <span class="math inline">\(\rho\)</span>) between 2 variables is significantly different from 0 or not in the <a href="/blog/what-is-the-difference-between-population-and-sample/">population</a>.</p>
<p>Actually, a correlation coefficient different from 0 in the sample does not mean that the correlation is <strong>significantly</strong> different from 0 in the population. This needs to be tested with a <a href="/blog/hypothesis-test-by-hand/">hypothesis test</a>—and known as the correlation test.</p>
<p>The null and alternative hypothesis for the correlation test are as follows:</p>
<ul>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\rho = 0\)</span> (meaning that there is no linear relationship between the two variables)</li>
<li><span class="math inline">\(H_1\)</span>: <span class="math inline">\(\rho \ne 0\)</span> (meaning that there is a linear relationship between the two variables)</li>
</ul>
<p>Via this correlation test, what we are actually testing is whether:</p>
<ul>
<li>the sample contains sufficient evidence to reject the null hypothesis and conclude that the correlation coefficient does not equal 0, so the relationship exists in the population.</li>
<li>or on the contrary, the sample does not contain enough evidence that the correlation coefficient does not equal 0, so in this case we do not reject the null hypothesis of no relationship between the variables in the population.</li>
</ul>
<p>Note that, for small sample sizes (usually <span class="math inline">\(n &lt; 30\)</span>), the two variables should follow a <a href="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r/">normal distribution</a> if you want to do a correlation test or estimate the confidence interval.</p>
<p>Suppose that we want to test whether the rear axle ratio (<code>drat</code>) is correlated with the time to drive a quarter of a mile (<code>qsec</code>):</p>
<pre class="r"><code># Pearson correlation test
test &lt;- cor.test(dat$drat, dat$qsec)
test</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  dat$drat and dat$qsec
## t = 0.50164, df = 30, p-value = 0.6196
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.265947  0.426340
## sample estimates:
##        cor 
## 0.09120476</code></pre>
<p>The <em>p</em>-value of the correlation test between these 2 variables is 0.62. At the 5% significance level, we do not reject the null hypothesis of no correlation. We therefore conclude that we do not reject the hypothesis that there is no linear relationship between the 2 variables.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>This test proves that even if the correlation coefficient is different from 0 (the correlation is 0.09 in the sample), it is actually not significantly different from 0 in the population.</p>
<p>Note that the <em>p</em>-value of a correlation test is based on the correlation coefficient <strong>and</strong> the sample size. The larger the sample size and the more extreme the correlation (closer to -1 or 1), the more likely the null hypothesis of no correlation will be rejected. With a small sample size, it is thus possible to obtain a <em>relatively</em> large correlation in the sample (based on the correlation coefficient), but still find a correlation not significantly different from 0 in the population (based on the correlation test). For this reason, it is recommended to always perform a correlation test before interpreting a correlation coefficient to avoid flawed conclusions.</p>
<!-- A nice and easy way to report results of a correlation test in R is with the `report()` function from the `{report}` package: -->
<!-- As you can see, the function interprets the test (together with the correlation coefficient and the *p*-value) for you. -->
<!-- Note that the `report()` function can be used for other analyses. See more examples in the package's [documentation](https://easystats.github.io/report/){target="_blank"}. See also more [tips and tricks in R](/blog/tips-and-tricks-in-rstudio-and-r-markdown/) if you find this one useful. -->
</div>
<div id="for-several-pairs-of-variables" class="section level2">
<h2>For several pairs of variables</h2>
<p>Similar to the correlation matrix used to compute correlation for several pairs of variables, the <code>rcorr()</code> function (from the <code>{Hmisc}</code> package) allows to compute <em>p</em>-values of the correlation test for several pairs of variables at once. Applied to our dataset, we have:</p>
<pre class="r"><code># correlation tests for whole dataset
library(Hmisc)
res &lt;- rcorr(as.matrix(dat)) # rcorr() accepts matrices only

# display p-values (rounded to 3 decimals)
round(res$P, 3)</code></pre>
<pre><code>##        mpg   cyl  disp    hp  drat    wt  qsec  gear  carb
## mpg     NA 0.000 0.000 0.000 0.000 0.000 0.017 0.005 0.001
## cyl  0.000    NA 0.000 0.000 0.000 0.000 0.000 0.004 0.002
## disp 0.000 0.000    NA 0.000 0.000 0.000 0.013 0.001 0.025
## hp   0.000 0.000 0.000    NA 0.010 0.000 0.000 0.493 0.000
## drat 0.000 0.000 0.000 0.010    NA 0.000 0.620 0.000 0.621
## wt   0.000 0.000 0.000 0.000 0.000    NA 0.339 0.000 0.015
## qsec 0.017 0.000 0.013 0.000 0.620 0.339    NA 0.243 0.000
## gear 0.005 0.004 0.001 0.493 0.000 0.000 0.243    NA 0.129
## carb 0.001 0.002 0.025 0.000 0.621 0.015 0.000 0.129    NA</code></pre>
<p>Only correlations with <em>p</em>-values smaller than the significance level (usually <span class="math inline">\(\alpha = 0.05\)</span>) should be interpreted.</p>
</div>
</div>
<div id="combination-of-correlation-coefficients-and-correlation-tests" class="section level1">
<h1>Combination of correlation coefficients and correlation tests</h1>
<p>Now that we covered the concepts of correlation coefficients and correlation tests, let see if we can combine the two concepts.</p>
<p>The <code>correlation</code> function from the <a href="https://easystats.github.io/correlation/" target="_blank">easystats <code>{correlation}</code> package</a> allows to combine correlation coefficients and correlation tests in a single table (thanks to <a href="https://github.com/AntoineSoetewey/statsandr/issues/8" target="_blank">krzysiektr</a> for pointing it out to me):</p>
<pre class="r"><code>library(correlation)

correlation::correlation(dat,
  include_factors = TRUE, method = &quot;auto&quot;
)</code></pre>
<pre><code>## # Correlation Matrix (auto-method)
## 
## Parameter1 | Parameter2 |     r |         95% CI | t(30) |         p
## --------------------------------------------------------------------
## mpg        |        cyl | -0.85 | [-0.93, -0.72] | -8.92 | &lt; .001***
## mpg        |       disp | -0.85 | [-0.92, -0.71] | -8.75 | &lt; .001***
## mpg        |         hp | -0.78 | [-0.89, -0.59] | -6.74 | &lt; .001***
## mpg        |       drat |  0.68 | [ 0.44,  0.83] |  5.10 | &lt; .001***
## mpg        |         wt | -0.87 | [-0.93, -0.74] | -9.56 | &lt; .001***
## mpg        |       qsec |  0.42 | [ 0.08,  0.67] |  2.53 | 0.137    
## mpg        |       gear |  0.48 | [ 0.16,  0.71] |  3.00 | 0.065    
## mpg        |       carb | -0.55 | [-0.75, -0.25] | -3.62 | 0.016*   
## cyl        |       disp |  0.90 | [ 0.81,  0.95] | 11.45 | &lt; .001***
## cyl        |         hp |  0.83 | [ 0.68,  0.92] |  8.23 | &lt; .001***
## cyl        |       drat | -0.70 | [-0.84, -0.46] | -5.37 | &lt; .001***
## cyl        |         wt |  0.78 | [ 0.60,  0.89] |  6.88 | &lt; .001***
## cyl        |       qsec | -0.59 | [-0.78, -0.31] | -4.02 | 0.007**  
## cyl        |       gear | -0.49 | [-0.72, -0.17] | -3.10 | 0.054    
## cyl        |       carb |  0.53 | [ 0.22,  0.74] |  3.40 | 0.027*   
## disp       |         hp |  0.79 | [ 0.61,  0.89] |  7.08 | &lt; .001***
## disp       |       drat | -0.71 | [-0.85, -0.48] | -5.53 | &lt; .001***
## disp       |         wt |  0.89 | [ 0.78,  0.94] | 10.58 | &lt; .001***
## disp       |       qsec | -0.43 | [-0.68, -0.10] | -2.64 | 0.131    
## disp       |       gear | -0.56 | [-0.76, -0.26] | -3.66 | 0.015*   
## disp       |       carb |  0.39 | [ 0.05,  0.65] |  2.35 | 0.177    
## hp         |       drat | -0.45 | [-0.69, -0.12] | -2.75 | 0.110    
## hp         |         wt |  0.66 | [ 0.40,  0.82] |  4.80 | &lt; .001***
## hp         |       qsec | -0.71 | [-0.85, -0.48] | -5.49 | &lt; .001***
## hp         |       gear | -0.13 | [-0.45,  0.23] | -0.69 | &gt; .999   
## hp         |       carb |  0.75 | [ 0.54,  0.87] |  6.21 | &lt; .001***
## drat       |         wt | -0.71 | [-0.85, -0.48] | -5.56 | &lt; .001***
## drat       |       qsec |  0.09 | [-0.27,  0.43] |  0.50 | &gt; .999   
## drat       |       gear |  0.70 | [ 0.46,  0.84] |  5.36 | &lt; .001***
## drat       |       carb | -0.09 | [-0.43,  0.27] | -0.50 | &gt; .999   
## wt         |       qsec | -0.17 | [-0.49,  0.19] | -0.97 | &gt; .999   
## wt         |       gear | -0.58 | [-0.77, -0.29] | -3.93 | 0.008**  
## wt         |       carb |  0.43 | [ 0.09,  0.68] |  2.59 | 0.132    
## qsec       |       gear | -0.21 | [-0.52,  0.15] | -1.19 | &gt; .999   
## qsec       |       carb | -0.66 | [-0.82, -0.40] | -4.76 | &lt; .001***
## gear       |       carb |  0.27 | [-0.08,  0.57] |  1.56 | 0.774    
## 
## p-value adjustment method: Holm (1979)
## Observations: 32</code></pre>
<p>As you can see, it gives, among other useful information, the correlation coefficients (column <code>r</code>) and the result of the correlation test (column <code>95% CI</code> for the confidence interval or <code>p</code> for the <span class="math inline">\(p\)</span>-value) for all pairs of variables.</p>
<div id="correlograms" class="section level2">
<h2>Correlograms</h2>
<p>The table above is very useful and informative, but let see if it is possible to combine the concepts of correlation coefficients and correlations test in one single visualization. A visualization that would be easy to read and interpret.</p>
<p>Ideally, we would like to have a concise overview of correlations between all possible pairs of variables present in a dataset, with a clear distinction for correlations that are significantly different from 0.</p>
<p>The figure below, known as a <a href="/blog/correlogram-in-r-how-to-highlight-the-most-correlated-variables-in-a-dataset/#correlogram">correlogram</a> and adapted from the <code>corrplot()</code> function, does precisely this:</p>
<pre class="r"><code># do not edit
corrplot2 &lt;- function(data,
                      method = &quot;pearson&quot;,
                      sig.level = 0.05,
                      order = &quot;original&quot;,
                      diag = FALSE,
                      type = &quot;upper&quot;,
                      tl.srt = 90,
                      number.font = 1,
                      number.cex = 1,
                      mar = c(0, 0, 0, 0)) {
  library(corrplot)
  data_incomplete &lt;- data
  data &lt;- data[complete.cases(data), ]
  mat &lt;- cor(data, method = method)
  cor.mtest &lt;- function(mat, method) {
    mat &lt;- as.matrix(mat)
    n &lt;- ncol(mat)
    p.mat &lt;- matrix(NA, n, n)
    diag(p.mat) &lt;- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp &lt;- cor.test(mat[, i], mat[, j], method = method)
        p.mat[i, j] &lt;- p.mat[j, i] &lt;- tmp$p.value
      }
    }
    colnames(p.mat) &lt;- rownames(p.mat) &lt;- colnames(mat)
    p.mat
  }
  p.mat &lt;- cor.mtest(data, method = method)
  col &lt;- colorRampPalette(c(&quot;#BB4444&quot;, &quot;#EE9988&quot;, &quot;#FFFFFF&quot;, &quot;#77AADD&quot;, &quot;#4477AA&quot;))
  corrplot(mat,
    method = &quot;color&quot;, col = col(200), number.font = number.font,
    mar = mar, number.cex = number.cex,
    type = type, order = order,
    addCoef.col = &quot;black&quot;, # add correlation coefficient
    tl.col = &quot;black&quot;, tl.srt = tl.srt, # rotation of text labels
    # combine with significance level
    p.mat = p.mat, sig.level = sig.level, insig = &quot;blank&quot;,
    # hide correlation coefficients on the diagonal
    diag = diag
  )
}

# edit from here
corrplot2(
  data = dat,
  method = &quot;pearson&quot;,
  sig.level = 0.05,
  order = &quot;original&quot;,
  diag = FALSE,
  type = &quot;upper&quot;,
  tl.srt = 75
)</code></pre>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-16-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The correlogram shows correlation coefficients for all pairs of variables (with more intense colors for more extreme correlations), and correlations not significantly different from 0 are represented by a white box.</p>
<p>To learn more about this plot and the code used, I invite you to read the article entitled “<a href="/blog/correlogram-in-r-how-to-highlight-the-most-correlated-variables-in-a-dataset/">Correlogram in R: how to highlight the most correlated variables in a dataset</a>.”</p>
<p>For those of you who are still not completely satisfied, I recently found two alternatives—one with the <code>ggpairs()</code> function from the <code>{GGally}</code> package and one with the <code>ggcormat()</code> function from the <code>{ggstatsplot}</code> package.</p>
<p>The two functions are illustrated with the variables <code>mpg</code>, <code>hp</code> and <code>wt</code>:</p>
<pre class="r"><code>library(GGally)

ggpairs(dat[, c(&quot;mpg&quot;, &quot;hp&quot;, &quot;wt&quot;)])</code></pre>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-17-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The plot above combines correlation coefficients, correlation tests (via the asterisks next to the coefficients<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>) and scatterplots for all possible pairs of variables present in a dataset.</p>
<pre class="r"><code>library(ggstatsplot)

ggcorrmat(
  data = dat[, c(&quot;mpg&quot;, &quot;hp&quot;, &quot;wt&quot;)],
  type = &quot;parametric&quot;, # parametric for Pearson, nonparametric for Spearman&#39;s correlation
  colors = c(&quot;darkred&quot;, &quot;white&quot;, &quot;steelblue&quot;) # change default colors
)</code></pre>
<p><img src="/blog/2020-05-28-correlation-coefficient-and-correlation-test-in-r_files/figure-html/unnamed-chunk-18-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The plot above also shows the correlation coefficients and if any, the non-significant correlations (by default at the 5% significance level with the Holm adjustment method) are shown by a big cross on the correlation coefficients.</p>
<p>The advantage of these two alternatives compared to the first one is that it is directly available within a package, so you do not need to run the code of the function first in order to draw the correlogram.</p>
</div>
</div>
<div id="correlation-does-not-imply-causation" class="section level1">
<h1>Correlation does not imply causation</h1>
<p>I am pretty sure you have already heard the statement “Correlation does not imply causation” in statistics. An article about correlation would not be complete without discussing about causation.</p>
<p>A non-zero correlation between two variables does not necessarily mean that there is a cause and effect relationship between these two variables!</p>
<p>Indeed, a significant correlation between two variables means that changes in one variable are associated (positively or negatively) with changes in the other variable. Nonetheless, a significant correlation <em>does not</em> indicates that variations in one variable <em>cause</em> the variations in the other variable.</p>
<p>A non-zero correlation between X and Y can appear in several cases:</p>
<ul>
<li>X causes Y</li>
<li>Y causes X</li>
<li>a third variable cause X and Y</li>
<li>a combination of these three reasons</li>
</ul>
<p>Sometimes it is quite clear that there is a causal relationship between two variables. Take for example the correlation between the price of a consumer product such as milk and its consumption. It is quite obvious that there is a causal link between the two: if the price of milk increases, it is expected that its consumption will decrease.</p>
<p>However, this causal link is not always present even if the correlation is significant. <span class="citation"><a href="#ref-maurage2013does" role="doc-biblioref">Maurage, Heeren, and Pesenti</a> (<a href="#ref-maurage2013does" role="doc-biblioref">2013</a>)</span> showed that, although there is a positive and significant correlation between chocolate consumption and the number of Nobel laureates, this correlation comes from the fact that a third variable, Gross Domestic Product (GDP), causes chocolate consumption and the number of Nobel laureates. They found that countries with higher GDP tend to have a higher level of chocolate consumption and scientific research (leading to more Nobel laureates).</p>
<p>This example shows that one must be very cautious when interpreting correlations and avoid over-interpreting a correlation as a causal relationship.</p>
<p>Thanks for reading. I hope this article helped you to compute correlations and perform correlation tests in R.</p>
<p>As always, if you have a question or a suggestion related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-maurage2013does" class="csl-entry">
Maurage, Pierre, Alexandre Heeren, and Mauro Pesenti. 2013. <span>“Does Chocolate Consumption Really Boost Nobel Award Chances? The Peril of over-Interpreting Correlations in Health Studies.”</span> <em>The Journal of Nutrition</em> 143 (6): 931–33.
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>It is important to remember that we tested for a <em>linear</em> relationship between the two variables since we used the Pearson’s correlation. It may be the case that there is a relationship between the two variables in the population, but this relation may not be linear.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>3 asterisks means that the coefficient is significant at the 5% level, 2 is at the 1% significance level, and 3 is at the 0.1% significance level.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
