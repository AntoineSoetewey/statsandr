---
title: Do my data follow a normal distribution ? A note on the most widely used distribution
  and how to test for normality in R
author: Antoine Soetewey
date: '2020-01-29'
slug: do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r
categories: []
tags:
  - R
  - Statistics
meta_img: image/image.png
# description: Description for the page.
output:
  blogdown::html_page:
    toc: true
    toc_depth: 6
draft: true
bibliography: bibliography.bib
---


<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#empirical-rule">Empirical rule</a></li>
<li><a href="#parameters">Parameters</a></li>
<li><a href="#characteristics">Characteristics</a></li>
<li><a href="#probabilities-and-quantiles">Probabilities and quantiles</a><ul>
<li><a href="#examples-in-r-and-by-hand">Examples in R and by hand</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>Many natural phenomena in real life can be approximated by a bell-shaped frequency distribution known as a normal distribution or the Gaussian distribution.</p>
</div>
<div id="empirical-rule" class="section level1">
<h1>Empirical rule</h1>
<p>Data possessing an approximately normal distribution have a definite variation, as expressed by the following empirical rule:</p>
<ul>
<li><span class="math inline">\(\mu \pm \sigma\)</span> includes approximately 68% of the observations</li>
<li><span class="math inline">\(\mu \pm 2 \cdot \sigma\)</span> includes approximately 95% of the observations</li>
<li><span class="math inline">\(\mu \pm 3 \cdot \sigma\)</span> includes almost all of the observations (99.7% to be more precise)</li>
</ul>
<center>
<embed src="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r_files/Empirical_Rule-normal-distribution.webp" />
</center>
<p>where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> correspond to the population mean and population standard deviation, respectively.</p>
<p>The empirical rule is illustred by the following 2 examples. Suppose that the scores of an exam in statistics given to all students in a Belgian university are known to have, approximately, a normal distribution with mean <span class="math inline">\(\mu = 67\)</span> and standard deviation <span class="math inline">\(\sigma = 9\)</span>. It can then be deduced that approximately 68% of the scores are between 58 and 76, that approximately 95% of the scores are between 49 and 85, and that almost all of the scores (99.7%) are between 40 and 94. Thus, knowing the mean and the standard deviation gives us a fairly good picture of the distribution of scores. Now suppose that a single university student is randomly selected from those who took the exam. What is the probability that her score will be between 49 and 85? Based on the empirical rule, we find that 0.95 is a reasonable answer to this probability question.</p>
<p>The utility and value of the empirical rule are due to the common occurrence of approximately normal distributions of measurements in nature. For example, IQ, shoe size, height, birth weight, etc. are approximately normally-distributed. You will find that approximately 95% of these measurements will be within <span class="math inline">\(2\sigma\)</span> of their mean <span class="citation">(Wackerly, Mendenhall, and Scheaffer 2014)</span>.</p>
</div>
<div id="parameters" class="section level1">
<h1>Parameters</h1>
<p>The normal distribution has two parameters: (i) the mean <span class="math inline">\(\mu\)</span> and (ii) the variance <span class="math inline">\(\sigma^2\)</span> (the square of the standard deviation <span class="math inline">\(\sigma\)</span>). The mean <span class="math inline">\(\mu\)</span> locates the center of the distribution and the variance <span class="math inline">\(\sigma^2\)</span> measures its spread.</p>
<p>The mean <span class="math inline">\(\mu\)</span> can take on any finite value, whereas the variance <span class="math inline">\(\sigma^2\)</span> can assume any positive finite value (i.e., <span class="math inline">\(\sigma^2 &gt; 0\)</span>).</p>
<p>A random variable <span class="math inline">\(X\)</span> which follows a normal distribution with a mean of 430 and a variance of 17 is denoted <span class="math inline">\(X ~ \sim \mathcal{N}(\mu = 430, \sigma^2 = 17)\)</span>.</p>
</div>
<div id="characteristics" class="section level1">
<h1>Characteristics</h1>
<p>A normal distribution is mount-shaped, unimodal and symmetric around the mean.</p>
</div>
<div id="probabilities-and-quantiles" class="section level1">
<h1>Probabilities and quantiles</h1>
<p>Probabilities and quantiles for random variables with normal distributions are easily found using R via the functions <code>pnorm()</code> and <code>qnorm()</code>. Probabilities associated with a normal distribution can also be found using this <a href="https://antoinesoetewey.shinyapps.io/statistics-101/" target="_blank" rel="noopener">Shiny app</a> (select the normal distribution).</p>
<p>Although there are infinitely many normal distributions (since there is a normal distribution for every combination of mean and variance), we need only one table: the <strong>standard normal distribution</strong>. A normal random variable <span class="math inline">\(X\)</span> can always be transformed to a standard normal random variable <span class="math inline">\(Z\)</span>, a process known as “scaling”, by using the formula:</p>
<p><span class="math display">\[Z = \frac{X - \mu}{\sigma}\]</span></p>
<p>From this formula, we see that <span class="math inline">\(Z\)</span> allows to see how far away is one single observation from the mean of all observations, with the distance expressed in standard deviations. The mean of the standard normal distribution is 0, and its standard deviation is 1, <span class="math inline">\(Z ~ \sim \mathcal{N}(\mu = 0, \sigma^2 = 1)\)</span>.</p>
<div id="examples-in-r-and-by-hand" class="section level2">
<h2>Examples in R and by hand</h2>
<p>Let <span class="math inline">\(Z\)</span> denote a normal random variable with mean 0 and standard deviation 1.</p>
<ol style="list-style-type: decimal">
<li>Find <span class="math inline">\(P(Z &gt; 1)\)</span></li>
</ol>
<p>We actually look for the shaded area in the following figure:</p>
<center>
<img src="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r_files/Screenshot%202020-01-30%20at%2014.18.54.png" alt="Standard normal distribution: P(Z &gt; 1)" style="width:100.0%" />
</center>
<p><strong>In R:</strong></p>
<pre class="r"><code>pnorm(1,
      mean = 0,
      sd = 1, # sd stands for standard deviation
      lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.1586553</code></pre>
<p>We look for the probability of <span class="math inline">\(Z\)</span> being larger than 1 so we set the argument <code>lower.tail = FALSE</code>. The default <code>lower.tail = TRUE</code> would give the result for <span class="math inline">\(P(Z &lt; 1)\)</span>. Note that <span class="math inline">\(P(Z = 1) = 0\)</span> so writing <span class="math inline">\(P(Z &gt; 1)\)</span> or <span class="math inline">\(P(Z \ge 1)\)</span> is equivalent.</p>
<ol start="2" style="list-style-type: decimal">
<li>Find <span class="math inline">\(P(−1 \le Z \le 1)\)</span></li>
</ol>
<p>We are looking for the shaded area in the following figure:</p>
<center>
<img src="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r_files/Screenshot%202020-01-30%20at%2014.19.14.png" alt="Standard normal distribution: P(−1 \le Z \le 1)" style="width:100.0%" />
</center>
<p><strong>In R:</strong></p>
<pre class="r"><code>pnorm(1, lower.tail = TRUE) - pnorm(-1, lower.tail = TRUE)</code></pre>
<pre><code>## [1] 0.6826895</code></pre>
<p>Note that the arguments by default for the mean and the standard deviation are <code>mean = 0</code> and <code>sd = 1</code>. Since this is what we need, we can omit them.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<ol start="3" style="list-style-type: decimal">
<li>Find <span class="math inline">\(P(0 \le Z \le 1.37)\)</span></li>
</ol>
<p>We are looking for the shaded area in the following figure:</p>
<center>
<img src="/blog/do-my-data-follow-a-normal-distribution-a-note-on-the-most-widely-used-distribution-and-how-to-test-for-normality-in-r_files/Screenshot%202020-01-30%20at%2014.19.46.png" alt="Standard normal distribution: P(0 \le Z \le 1.37)" style="width:100.0%" />
</center>
<p><strong>In R:</strong></p>
<pre class="r"><code>pnorm(0, lower.tail = FALSE) - pnorm(1.37, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.4146565</code></pre>
<p>Thanks for reading. I hope the article helped you to learn more about the normal distribution and how to test for normality in R. See other articles in <a href="/tag/statistics">statistics</a>.</p>
<p>As always, if you have a statistical question related to the topic covered in this article, please add it as a comment so other readers can benefit from the discussion. If you find a mistake or bug, you can inform me by <a href="https://github.com/AntoineSoetewey/statsandr/issues" target="_blank" rel="noopener">raising an issue on GitHub</a>. For all other requests, you can contact me <a href="/contact/">here</a>.</p>
<p>Get updates every time a new article is published by <a href="/subscribe/">subscribing to this blog</a>.</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-wackerly2014mathematical">
<p>Wackerly, Dennis, William Mendenhall, and Richard L Scheaffer. 2014. <em>Mathematical Statistics with Applications</em>. Cengage Learning.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The argument <code>lower.tail = TRUE</code> is also the default so we could omit it as well. However, for clarity and to make sure I compute the propabilities in the correct side of the curve, I used to keep this argument explicit by writing it.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
